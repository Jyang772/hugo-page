<!doctype html><html lang=en-us><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-WBN59M8Y5S"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WBN59M8Y5S")</script><script type=text/javascript>(function(e,t,n,s,o,i,a){e[o]=e[o]||function(){(e[o].a=e[o].a||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym"),ym(53961409,"init",{clickmap:!0,trackLinks:!0,accurateTrackBounce:!0,webvisor:!0})</script><noscript><div><img src=https://mc.yandex.ru/watch/53961409 style=position:absolute;left:-9999px alt></div></noscript><meta charset=utf-8><link rel=stylesheet href=/hugo-page/style.min.a3a4a7a8e8602aaa85b7cb3d655edde028ac80d73f2a97389e2cbcf995dd672d.css integrity="sha256-o6SnqOhgKqqFt8s9ZV7d4CisgNc/Kpc4niy8+ZXdZy0="><link rel=stylesheet href=/syntax.css id=syntax-theme><link rel=stylesheet type=text/css href=https://tikzjax.com/v1/fonts.css><script src=https://tikzjax.com/v1/tikzjax.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js></script><script src=/hugo-page/scripts/lunr.stemmer.support.min.js></script><script src=/hugo-page/scripts/lunr.ru.min.js></script><script src=/hugo-page/scripts/lunr.multi.min.js></script><link rel=stylesheet id=theme><script>function toggleSidebar(){console.log("Toggling sidebar visibility");var e=document.getElementById("sidebar"),t=document.getElementById("wrapper");(e.classList.contains("sidebar-toggled")||window.getComputedStyle(e).display=="block")&&(e.classList.toggle("sidebar-hidden"),t.classList.toggle("sidebar-hidden")),e.classList.add("sidebar-toggled"),t.classList.add("sidebar-toggled")}function switchTheme(e){console.log("Changing theme:",e),document.getElementById("theme").href=e=="dark"?"/hugo-page/dark.min.b3ae1169831434b11b48de5b3e3210547eea6b7884c295ab0030cb973ea0dc49.css":"",document.getElementById("syntax-theme").href=e=="dark"?"/syntax-dark.css":"/syntax.css",localStorage.setItem("theme",e)}async function toggleSearch(){console.log("Toggling search");var e=document.getElementById("search");if(window.getComputedStyle(e).display=="none"?(e.style.display="block",window.scrollTo({top:0}),document.getElementById("search-bar").focus()):e.style.display="none",!index){console.log("Fetching index");const e=await fetch("/hugo-page/searchindex.json"),t=await e.json();index=lunr(function(){this.use(lunr.multiLanguage("en","ru")),this.field("title",{boost:5}),this.field("content",{boost:1}),t.forEach(function(e){this.add(e),articles.push(e)},this)}),console.log("Ready to search")}}var articles=[],index=void 0;function search(){var n,e=document.getElementById("search-bar").value,s=document.getElementById("search-results"),o=document.getElementById("search-count");if(e==""){s.innerHTML="",o.innerHTML="";return}n=index.search(e),o.innerHTML="Found <b>"+n.length+"</b> pages";let t="";for(const a in n){const i=articles[n[a].ref];t+='<li><a href="'+i.path+'">'+i.title+"</a> <p>";const s=i.content,o=80;if(s.includes(e)){const n=s.indexOf(e);n>o&&(t+="…"),t+=s.substring(n-o,n)+"<b>"+e+"</b>"+s.substring(n+e.length,n+e.length+o)}else t+=s.substring(0,o*2);t+="…</p></li>"}s.innerHTML=t}localStorage.getItem("theme")=="dark"&&switchTheme("dark"),window.addEventListener("load",function(){var e=document.getElementById("active-element");e&&e.scrollIntoView({block:"center"})}),window.addEventListener("scroll",function(){var e=document.getElementById("menu");window.scrollY<120?e.classList.remove("scrolled"):e.classList.add("scrolled")}),window.addEventListener("keydown",function(e){if(e.altKey)return;if(document.activeElement.tagName=="INPUT")return;e.key=="ArrowLeft"?document.getElementById("prev-article").click():e.key=="ArrowRight"&&document.getElementById("next-article").click()})</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})'></script><title>Spatial and Temporal Locality - Algorithmica</title></head><body><nav id=sidebar><div class=title><a href=/>Algorithmica</a>
<span class=slash>/</span>
<a href=/hugo-page/hpc/ class=divisionAbbr>HPC</a></div><ul><li class=part>Performance Engineering</li><li><a href=/hugo-page/hpc/complexity/>Complexity Models</a></li><ol><li><a href=/hugo-page/hpc/complexity/hardware/>Modern Hardware</a></li><li><a href=/hugo-page/hpc/complexity/languages/>Programming Languages</a></li></ol><li><a href=/hugo-page/hpc/architecture/>Computer Architecture</a></li><ol><li><a href=/hugo-page/hpc/architecture/isa/>Instruction Set Architectures</a></li><li><a href=/hugo-page/hpc/architecture/assembly/>Assembly Language</a></li><li><a href=/hugo-page/hpc/architecture/loops/>Loops and Conditionals</a></li><li><a href=/hugo-page/hpc/architecture/functions/>Functions and Recursion</a></li><li><a href=/hugo-page/hpc/architecture/indirect/>Indirect Branching</a></li><li><a href=/hugo-page/hpc/architecture/layout/>Machine Code Layout</a></li></ol><li><a href=/hugo-page/hpc/pipelining/>Instruction-Level Parallelism</a></li><ol><li><a href=/hugo-page/hpc/pipelining/hazards/>Pipeline Hazards</a></li><li><a href=/hugo-page/hpc/pipelining/branching/>The Cost of Branching</a></li><li><a href=/hugo-page/hpc/pipelining/branchless/>Branchless Programming</a></li><li><a href=/hugo-page/hpc/pipelining/tables/>Instruction Tables</a></li><li><a href=/hugo-page/hpc/pipelining/throughput/>Throughput Computing</a></li></ol><li><a href=/hugo-page/hpc/compilation/>Compilation</a></li><ol><li><a href=/hugo-page/hpc/compilation/stages/>Stages of Compilation</a></li><li><a href=/hugo-page/hpc/compilation/flags/>Flags and Targets</a></li><li><a href=/hugo-page/hpc/compilation/situational/>Situational Optimizations</a></li><li><a href=/hugo-page/hpc/compilation/contracts/>Contract Programming</a></li><li><a href=/hugo-page/hpc/compilation/precalc/>Precomputation</a></li></ol><li><a href=/hugo-page/hpc/profiling/>Profiling</a></li><ol><li><a href=/hugo-page/hpc/profiling/instrumentation/>Instrumentation</a></li><li><a href=/hugo-page/hpc/profiling/events/>Statistical Profiling</a></li><li><a href=/hugo-page/hpc/profiling/simulation/>Program Simulation</a></li><li><a href=/hugo-page/hpc/profiling/mca/>Machine Code Analyzers</a></li><li><a href=/hugo-page/hpc/profiling/benchmarking/>Benchmarking</a></li><li><a href=/hugo-page/hpc/profiling/noise/>Getting Accurate Results</a></li></ol><li><a href=/hugo-page/hpc/arithmetic/>Arithmetic</a></li><ol><li><a href=/hugo-page/hpc/arithmetic/float/>Floating-Point Numbers</a></li><li><a href=/hugo-page/hpc/arithmetic/ieee-754/>IEEE 754 Floats</a></li><li><a href=/hugo-page/hpc/arithmetic/errors/>Rounding Errors</a></li><li><a href=/hugo-page/hpc/arithmetic/newton/>Newton's Method</a></li><li><a href=/hugo-page/hpc/arithmetic/rsqrt/>Fast Inverse Square Root</a></li><li><a href=/hugo-page/hpc/arithmetic/integer/>Integer Numbers</a></li><li><a href=/hugo-page/hpc/arithmetic/division/>Integer Division</a></li></ol><li><a href=/hugo-page/hpc/number-theory/>Number Theory</a></li><ol><li><a href=/hugo-page/hpc/number-theory/modular/>Modular Arithmetic</a></li><li><a href=/hugo-page/hpc/number-theory/exponentiation/>Binary Exponentiation</a></li><li><a href=/hugo-page/hpc/number-theory/euclid-extended/>Extended Euclidean Algorithm</a></li><li><a href=/hugo-page/hpc/number-theory/montgomery/>Montgomery Multiplication</a></li></ol><li><a href=/hugo-page/hpc/external-memory/>External Memory</a></li><ol><li><a href=/hugo-page/hpc/external-memory/hierarchy/>Memory Hierarchy</a></li><li><a href=/hugo-page/hpc/external-memory/virtual/>Virtual Memory</a></li><li><a href=/hugo-page/hpc/external-memory/model/>External Memory Model</a></li><li><a href=/hugo-page/hpc/external-memory/sorting/>External Sorting</a></li><li><a href=/hugo-page/hpc/external-memory/list-ranking/>List Ranking</a></li><li><a href=/hugo-page/hpc/external-memory/policies/>Eviction Policies</a></li><li><a href=/hugo-page/hpc/external-memory/oblivious/>Cache-Oblivious Algorithms</a></li><li><a href=/hugo-page/hpc/external-memory/locality/ id=active-element>Spatial and Temporal Locality</a></li></ol><li><a href=/hugo-page/hpc/cpu-cache/>RAM & CPU Caches</a></li><ol><li><a href=/hugo-page/hpc/cpu-cache/bandwidth/>Memory Bandwidth</a></li><li><a href=/hugo-page/hpc/cpu-cache/latency/>Memory Latency</a></li><li><a href=/hugo-page/hpc/cpu-cache/cache-lines/>Cache Lines</a></li><li><a href=/hugo-page/hpc/cpu-cache/sharing/>Memory Sharing</a></li><li><a href=/hugo-page/hpc/cpu-cache/mlp/>Memory-Level Parallelism</a></li><li><a href=/hugo-page/hpc/cpu-cache/prefetching/>Prefetching</a></li><li><a href=/hugo-page/hpc/cpu-cache/alignment/>Alignment and Packing</a></li><li><a href=/hugo-page/hpc/cpu-cache/pointers/>Pointer Alternatives</a></li><li><a href=/hugo-page/hpc/cpu-cache/associativity/>Cache Associativity</a></li><li><a href=/hugo-page/hpc/cpu-cache/paging/>Memory Paging</a></li><li><a href=/hugo-page/hpc/cpu-cache/aos-soa/>AoS and SoA</a></li></ol><li><a href=/hugo-page/hpc/simd/>SIMD Parallelism</a></li><ol><li><a href=/hugo-page/hpc/simd/intrinsics/>Intrinsics and Vector Types</a></li><li><a href=/hugo-page/hpc/simd/moving/>Moving Data</a></li><li><a href=/hugo-page/hpc/simd/reduction/>Reductions</a></li><li><a href=/hugo-page/hpc/simd/masking/>Masking and Blending</a></li><li><a href=/hugo-page/hpc/simd/shuffling/>In-Register Shuffles</a></li><li><a href=/hugo-page/hpc/simd/auto-vectorization/>Auto-Vectorization and SPMD</a></li></ol><li><a href=/hugo-page/hpc/algorithms/>Algorithms Case Studies</a></li><ol><li><a href=/hugo-page/hpc/algorithms/gcd/>Binary GCD</a></li><li><a href=/hugo-page/hpc/algorithms/factorization/>Integer Factorization</a></li><li><a href=/hugo-page/hpc/algorithms/argmin/>Argmin with SIMD</a></li><li><a href=/hugo-page/hpc/algorithms/prefix/>Prefix Sum with SIMD</a></li><li><a href=/hugo-page/hpc/algorithms/matmul/>Matrix Multiplication</a></li></ol><li><a href=/hugo-page/hpc/data-structures/>Data Structures Case Studies</a></li><ol><li><a href=/hugo-page/hpc/data-structures/binary-search/>Binary Search</a></li><li><a href=/hugo-page/hpc/data-structures/s-tree/>Static B-Trees</a></li><li><a href=/hugo-page/hpc/data-structures/b-tree/>Search Trees</a></li><li><a href=/hugo-page/hpc/data-structures/segment-trees/>Segment Trees</a></li></ol></ul></nav><div id=wrapper><menu id=menu><div class=left><a><img src=/icons/bars-solid.svg onclick=toggleSidebar() title='open table of contents'>
</a><a><img src=/icons/adjust-solid.svg style=position:relative;top:-1px onclick='switchTheme(localStorage.getItem("theme")=="dark"?"light":"dark")' title='dark theme'>
</a><a><img src=/icons/search-solid.svg onclick=toggleSearch() title=search></a></div><div class=title>Spatial and Temporal Locality</div><div class=right><a onclick=window.print()><img src=/icons/print-solid.svg title=print>
</a><a href=https://prose.io/#algorithmica-org/algorithmica/edit/master//hpc%2fexternal-memory%2flocality.md><img src=/icons/edit-solid.svg title=edit style=width:18px;position:relative;right:-2px;top:-1px>
</a><a href=https://github.com/algorithmica-org/algorithmica/blob/master//hpc/external-memory/locality.md class=github-main><img src=/icons/github-brands.svg title='view on github'></a></div></menu><main><div id=search><input id=search-bar type=search placeholder='Search this book…' oninput=search()><div id=search-count></div><div id=search-results></div></div><header><h1>Spatial and Temporal Locality</h1><div class=info></div></header><article><p>To precisely assess the performance of an algorithm in terms of its memory operations, we need to take into account multiple characteristics of the cache system: the number of cache layers, the <a href=../hierarchy>memory and block sizes</a> of each layer, the exact <a href=../policies>strategy</a> used for cache eviction by each layer, and sometimes even the details of the <a href=../virtual>memory paging</a> mechanism.</p><p>Abstracting away from all these minor details helps a lot in the first stages of designing algorithms. Instead of calculating theoretical cache hit rates, it often makes more sense to reason about cache performance in more qualitative terms.</p><p>In this context, we can talk about the degree of cache reuse primarily in two ways:</p><ul><li><em>Temporal locality</em> refers to the repeated access of the same data within a relatively small time period, such that the data likely remains cached between the requests.</li><li><em>Spatial locality</em> refers to the use of elements relatively close to each other in terms of their memory locations, such that they are likely fetched in the same memory block.</li></ul><p>In other words, temporal locality is when it is likely that this same memory location will soon be requested again, while spatial locality is when it is likely that a nearby location will be requested right after.</p><p>In this section, we will do some case studies to show how these high-level concepts can help in practical optimization.</p><span class=anchor id=depth-first-vs-breadth-first></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/external-memory/locality/#depth-first-vs-breadth-first>#</a>Depth-First vs. Breadth-First</h3><p>Consider a divide-and-conquer algorithm such as merge sorting. There are two approaches to implementing it:</p><ul><li>We can implement it recursively, or &ldquo;depth-first,&rdquo; the way it is normally implemented: sort the left half, sort the right half and then merge the results.</li><li>We can implement it iteratively, or &ldquo;breadth-first:&rdquo; do the lowest &ldquo;layer&rdquo; first, looping through the entire dataset and comparing odd elements with even elements, then merge the first two elements with the second two elements, the third two elements with the fourth two elements and so on.</li></ul><p>It seems like the second approach is more cumbersome, but faster — because recursion is always slow, right?</p><p>Generally, recursion is <a href=/hpc/architecture/functions>indeed slow</a>, but this is not the case for this and many similar divide-and-conquer algorithms. Although the iterative approach has the advantage of only doing sequential I/O, the recursive approach has much better temporal locality: when a segment fully fits into the cache, it stays there for all lower layers of recursion, resulting in better access times later on.</p><p>In fact, since we only need to split the array $O(\log \frac{N}{M})$ times until this happens, we would only need to read $O(\frac{N}{B} \log \frac{N}{M})$ blocks in total, while in the iterative approach the entire array will be read from scratch $O(\log N)$ times no matter what. This results in the speedup of $O(\frac{\log N}{\log N - \log M})$, which may be up to an order of magnitude.</p><p>In practice, there is still some overhead associated with the recursion, and for this reason, it makes sense to use hybrid algorithms where we don&rsquo;t go all the way down to the base case and instead switch to the iterative code on the lower levels of recursion.</p><span class=anchor id=dynamic-programming></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/external-memory/locality/#dynamic-programming>#</a>Dynamic Programming</h3><p>Similar reasoning can be applied to the implementations of dynamic programming algorithms but leading to the reverse result. Consider the classic <em>knapsack problem:</em> given $N$ items with positive integer costs $c_i$, pick a subset of items with the maximum total cost that does not exceed a given constant $W$.</p><p>The way to solve it is to introduce the <em>state</em> $f[n, w]$, which corresponds to the maximum total cost not exceeding $w$ that can be achieved using only the first $n$ items. These values can be computed in $O(1)$ time per entry if we consider either taking or not taking the $n$-th item and using the previous states of the dynamic to make the optimal decision.</p><p>Python has a handy <code>lru_cache</code> decorator which can be used for implementing it with memoized recursion:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@lru_cache</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>f</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>w</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># check if we have no items to choose</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>n</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># check if we can&#39;t pick the last item (note zero-based indexing)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>c</span><span class=p>[</span><span class=n>n</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span> <span class=o>&gt;</span> <span class=n>w</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>f</span><span class=p>(</span><span class=n>n</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>w</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># otherwise, we can either pick the last item or not</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nb>max</span><span class=p>(</span><span class=n>f</span><span class=p>(</span><span class=n>n</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>w</span><span class=p>),</span> <span class=n>c</span><span class=p>[</span><span class=n>n</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span> <span class=o>+</span> <span class=n>f</span><span class=p>(</span><span class=n>n</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>w</span> <span class=o>-</span> <span class=n>c</span><span class=p>[</span><span class=n>n</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]))</span>
</span></span></code></pre></div><p>When computing $f[N, W]$, the recursion may visit up to $O(N \cdot W)$ different states, which is asymptotically efficient, but rather slow in reality. Even after nullifying the overhead of Python recursion and all the <a href=../policies/#implementing-caching>hash table queries</a> required for the LRU cache to work, it would still be slow because it does random I/O throughout most of the execution.</p><p>What we can do instead is to create a two-dimensional array for the dynamic and replace the recursion with a nice nested loop like this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=kt>int</span> <span class=n>f</span><span class=p>[</span><span class=n>N</span> <span class=o>+</span> <span class=mi>1</span><span class=p>][</span><span class=n>W</span> <span class=o>+</span> <span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span><span class=mi>0</span><span class=p>};</span> <span class=c1>// this zero-fills the array
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>n</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span> <span class=n>n</span> <span class=o>&lt;=</span> <span class=n>N</span><span class=p>;</span> <span class=n>n</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>w</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>w</span> <span class=o>&lt;=</span> <span class=n>W</span><span class=p>;</span> <span class=n>w</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>f</span><span class=p>[</span><span class=n>n</span><span class=p>][</span><span class=n>w</span><span class=p>]</span> <span class=o>=</span> <span class=n>c</span><span class=p>[</span><span class=n>n</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span> <span class=o>&gt;</span> <span class=n>w</span> <span class=o>?</span>
</span></span><span class=line><span class=cl>                  <span class=n>f</span><span class=p>[</span><span class=n>n</span> <span class=o>-</span> <span class=mi>1</span><span class=p>][</span><span class=n>w</span><span class=p>]</span> <span class=o>:</span>
</span></span><span class=line><span class=cl>                  <span class=n>max</span><span class=p>(</span><span class=n>f</span><span class=p>[</span><span class=n>n</span> <span class=o>-</span> <span class=mi>1</span><span class=p>][</span><span class=n>k</span><span class=p>],</span> <span class=n>c</span><span class=p>[</span><span class=n>n</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span> <span class=o>+</span> <span class=n>f</span><span class=p>[</span><span class=n>n</span> <span class=o>-</span> <span class=mi>1</span><span class=p>][</span><span class=n>w</span> <span class=o>-</span> <span class=n>c</span><span class=p>[</span><span class=n>n</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]]);</span>
</span></span></code></pre></div><p>Notice that we are only using the previous layer of the dynamic to calculate the next one. This means that if we can store one layer in the cache, we would only need to write $O(\frac{N \cdot W}{B})$ blocks in external memory.</p><p>Moreover, if we only need the answer, we don&rsquo;t actually have to store the whole 2d array but only the last layer. This lets us use just $O(W)$ memory by maintaining a single array of $W$ values. To simplify the code, we can slightly change the dynamic to store a binary value: whether it is possible to get the sum of exactly $w$ using the items that we have already considered. This dynamic is even faster to compute:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=kt>bool</span> <span class=n>f</span><span class=p>[</span><span class=n>W</span> <span class=o>+</span> <span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span><span class=mi>0</span><span class=p>};</span>
</span></span><span class=line><span class=cl><span class=n>f</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>n</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>n</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>;</span> <span class=n>n</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>x</span> <span class=o>=</span> <span class=n>W</span> <span class=o>-</span> <span class=n>c</span><span class=p>[</span><span class=n>n</span><span class=p>];</span> <span class=n>x</span> <span class=o>&gt;=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>x</span><span class=o>--</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>f</span><span class=p>[</span><span class=n>x</span> <span class=o>+</span> <span class=n>c</span><span class=p>[</span><span class=n>n</span><span class=p>]]</span> <span class=o>|=</span> <span class=n>f</span><span class=p>[</span><span class=n>x</span><span class=p>];</span>
</span></span></code></pre></div><p>As a side note, now that it only uses simple bitwise operations, it can be optimized further by using a bitset:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>std</span><span class=o>::</span><span class=n>bitset</span><span class=o>&lt;</span><span class=n>W</span> <span class=o>+</span> <span class=mi>1</span><span class=o>&gt;</span> <span class=n>b</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>b</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>n</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>n</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>;</span> <span class=n>n</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>b</span> <span class=o>|=</span> <span class=n>b</span> <span class=o>&lt;&lt;</span> <span class=n>c</span><span class=p>[</span><span class=n>n</span><span class=p>];</span>
</span></span></code></pre></div><p>Surprisingly, there is still some room for improvement, and we will come back to this problem later.</p><span class=anchor id=sparse-table></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/external-memory/locality/#sparse-table>#</a>Sparse Table</h3><p><em>Sparse table</em> is a <em>static</em> data structure that is often used for solving the <em>static RMQ</em> problem and computing any similar <em>idempotent range reductions</em> in general. It can be formally defined as a two-dimensional array of size $\log n \times n$:</p>$$
t[k][i] = \min \{ a_i, a_{i+1}, \ldots, a_{i+2^k-1} \}
$$<p>In plain English: we store the minimum on each segment whose length is a power of two.</p><p>Such array can be used for calculating minima on arbitrary segments in constant time because for each segment we can always find two possibly overlapping segments whose sizes are the same power of two, the union of which gives the whole segment.</p><p><figure><img src=../img/sparse-table.png><figcaption></figcaption></figure></p><p>This means that we can just take the minimum of these two precomputed minimums as the answer:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=kt>int</span> <span class=nf>rmq</span><span class=p>(</span><span class=kt>int</span> <span class=n>l</span><span class=p>,</span> <span class=kt>int</span> <span class=n>r</span><span class=p>)</span> <span class=p>{</span> <span class=c1>// half-interval [l; r)
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>int</span> <span class=n>t</span> <span class=o>=</span> <span class=n>__lg</span><span class=p>(</span><span class=n>r</span> <span class=o>-</span> <span class=n>l</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>min</span><span class=p>(</span><span class=n>mn</span><span class=p>[</span><span class=n>t</span><span class=p>][</span><span class=n>l</span><span class=p>],</span> <span class=n>mn</span><span class=p>[</span><span class=n>t</span><span class=p>][</span><span class=n>r</span> <span class=o>-</span> <span class=p>(</span><span class=mi>1</span> <span class=o>&lt;&lt;</span> <span class=n>t</span><span class=p>)]);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>The <code>__lg</code> function is an intrinsic available in GCC that calculates the binary logarithm of a number rounded down. Internally it uses the <code>clz</code> (&ldquo;count leading zeros&rdquo;) instruction and subtracts this count from 32 (in case of a 32-bit integer), and thus takes just a few cycles.</p><p>The reason why I bring it up in this article is that there are multiple alternative ways it can be built, with different efficiencies in terms of memory operations. In general, a sparse table can be built in $O(n \log n)$ time in dynamic programming fashion by iterating in the order of increasing $i$ or $k$ and applying the following identity:</p>$$
t[k][i] = \min(t[k-1][i], t[k-1][i+2^{k-1}])
$$<p>Now, there are two design choices to make: whether the log-size $k$ should be the first or the second dimension, and whether to iterate over $k$ and then $i$ or the other way around. This means that there are $2×2=4$ ways to build it, and here is the optimal one:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=kt>int</span> <span class=n>mn</span><span class=p>[</span><span class=n>logn</span><span class=p>][</span><span class=n>maxn</span><span class=p>];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>memcpy</span><span class=p>(</span><span class=n>mn</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>a</span><span class=p>,</span> <span class=k>sizeof</span> <span class=n>a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>l</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>l</span> <span class=o>&lt;</span> <span class=n>logn</span> <span class=o>-</span> <span class=mi>1</span><span class=p>;</span> <span class=n>l</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>+</span> <span class=p>(</span><span class=mi>2</span> <span class=o>&lt;&lt;</span> <span class=n>l</span><span class=p>)</span> <span class=o>&lt;=</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>mn</span><span class=p>[</span><span class=n>l</span> <span class=o>+</span> <span class=mi>1</span><span class=p>][</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>min</span><span class=p>(</span><span class=n>mn</span><span class=p>[</span><span class=n>l</span><span class=p>][</span><span class=n>i</span><span class=p>],</span> <span class=n>mn</span><span class=p>[</span><span class=n>l</span><span class=p>][</span><span class=n>i</span> <span class=o>+</span> <span class=p>(</span><span class=mi>1</span> <span class=o>&lt;&lt;</span> <span class=n>l</span><span class=p>)]);</span>
</span></span></code></pre></div><p>This is the only combination of the memory layout and the iteration order that results in beautiful linear passes that work ~3x faster. As an exercise, consider the other three variants and think about <em>why</em> they are slower.</p><span class=anchor id=array-of-structs-vs-struct-of-arrays></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/external-memory/locality/#array-of-structs-vs-struct-of-arrays>#</a>Array-of-Structs vs. Struct-of-Arrays</h3><p>Suppose that you want to implement a binary tree and store its fields in separate arrays like this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=kt>int</span> <span class=n>left_child</span><span class=p>[</span><span class=n>maxn</span><span class=p>],</span> <span class=n>right_child</span><span class=p>[</span><span class=n>maxn</span><span class=p>],</span> <span class=n>key</span><span class=p>[</span><span class=n>maxn</span><span class=p>],</span> <span class=n>size</span><span class=p>[</span><span class=n>maxn</span><span class=p>];</span>
</span></span></code></pre></div><p>Such memory layout, when we store each field separately from others, is called <em>struct-of-arrays</em> (SoA). In most cases, when implementing tree operations, you access a node and then shortly after all or most of its internal data. If these fields are stored separately, this would mean that they are also located in different memory blocks. If some of the requested fields happen to be are cached while the others are not, you would still have to wait for the slowest of them to be fetched.</p><p>In contrast, if it was instead stored as an array-of-structs (AoS), you would need ~4 times fewer block reads as all the data of a node is stored in the same block and fetched at once:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=k>struct</span> <span class=nc>Node</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>left_child</span><span class=p>,</span> <span class=n>right_child</span><span class=p>,</span> <span class=n>key</span><span class=p>,</span> <span class=n>size</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>};</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Node</span> <span class=n>t</span><span class=p>[</span><span class=n>maxn</span><span class=p>];</span>
</span></span></code></pre></div><p>The AoS layout is usually preferred for data structures, but SoA still has good uses: while it is worse for searching, it is much better for linear scanning.</p><p>This difference in design is important in data processing applications. For example, databases can be either <em>row-</em> or <em>column-oriented</em> (also called <em>columnar</em>):</p><ul><li><em>Row-oriented</em> storage formats are used when you need to search for a limited number of objects in a large dataset and/or fetch all or most of their fields. Examples: PostgreSQL, MongoDB.</li><li><em>Columnar</em> storage formats are used for big data processing and analytics, where you need to scan through everything anyway to calculate certain statistics. Examples: ClickHouse, Hbase.</li></ul><p>Columnar formats have the additional advantage that you can only read the fields that you need, as different fields are stored in separate external memory regions.</p></article><div class=nextprev><div class=left><a href=http://jyang772.github.io/hugo-page/hpc/external-memory/oblivious/ id=prev-article>← Cache-Oblivious Algorithms</a></div><div class=right><a href=http://jyang772.github.io/hugo-page/hpc/cpu-cache/ id=next-article>../RAM & CPU Caches →</a></div></div></main><footer>Copyright 2021–2022 Sergey Slotin<br></footer></div></body></html>