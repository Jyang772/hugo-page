<!doctype html><html lang=en-us><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-WBN59M8Y5S"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WBN59M8Y5S")</script><script type=text/javascript>(function(e,t,n,s,o,i,a){e[o]=e[o]||function(){(e[o].a=e[o].a||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym"),ym(53961409,"init",{clickmap:!0,trackLinks:!0,accurateTrackBounce:!0,webvisor:!0})</script><noscript><div><img src=https://mc.yandex.ru/watch/53961409 style=position:absolute;left:-9999px alt></div></noscript><meta charset=utf-8><link rel=stylesheet href=/style.min.a3a4a7a8e8602aaa85b7cb3d655edde028ac80d73f2a97389e2cbcf995dd672d.css integrity="sha256-o6SnqOhgKqqFt8s9ZV7d4CisgNc/Kpc4niy8+ZXdZy0="><link rel=stylesheet href=/syntax.css id=syntax-theme><link rel=stylesheet type=text/css href=https://tikzjax.com/v1/fonts.css><script src=https://tikzjax.com/v1/tikzjax.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js></script><script src=/scripts/lunr.stemmer.support.min.js></script><script src=/scripts/lunr.ru.min.js></script><script src=/scripts/lunr.multi.min.js></script><link rel=stylesheet id=theme><script>function toggleSidebar(){console.log("Toggling sidebar visibility");var e=document.getElementById("sidebar"),t=document.getElementById("wrapper");(e.classList.contains("sidebar-toggled")||window.getComputedStyle(e).display=="block")&&(e.classList.toggle("sidebar-hidden"),t.classList.toggle("sidebar-hidden")),e.classList.add("sidebar-toggled"),t.classList.add("sidebar-toggled")}function switchTheme(e){console.log("Changing theme:",e),document.getElementById("theme").href=e=="dark"?"/dark.min.b3ae1169831434b11b48de5b3e3210547eea6b7884c295ab0030cb973ea0dc49.css":"",document.getElementById("syntax-theme").href=e=="dark"?"/syntax-dark.css":"/syntax.css",localStorage.setItem("theme",e)}async function toggleSearch(){console.log("Toggling search");var e=document.getElementById("search");if(window.getComputedStyle(e).display=="none"?(e.style.display="block",window.scrollTo({top:0}),document.getElementById("search-bar").focus()):e.style.display="none",!index){console.log("Fetching index");const e=await fetch("/searchindex.json"),t=await e.json();index=lunr(function(){this.use(lunr.multiLanguage("en","ru")),this.field("title",{boost:5}),this.field("content",{boost:1}),t.forEach(function(e){this.add(e),articles.push(e)},this)}),console.log("Ready to search")}}var articles=[],index=void 0;function search(){var n,e=document.getElementById("search-bar").value,s=document.getElementById("search-results"),o=document.getElementById("search-count");if(e==""){s.innerHTML="",o.innerHTML="";return}n=index.search(e),o.innerHTML="Found <b>"+n.length+"</b> pages";let t="";for(const a in n){const i=articles[n[a].ref];t+='<li><a href="'+i.path+'">'+i.title+"</a> <p>";const s=i.content,o=80;if(s.includes(e)){const n=s.indexOf(e);n>o&&(t+="…"),t+=s.substring(n-o,n)+"<b>"+e+"</b>"+s.substring(n+e.length,n+e.length+o)}else t+=s.substring(0,o*2);t+="…</p></li>"}s.innerHTML=t}localStorage.getItem("theme")=="dark"&&switchTheme("dark"),window.addEventListener("load",function(){var e=document.getElementById("active-element");e&&e.scrollIntoView({block:"center"})}),window.addEventListener("scroll",function(){var e=document.getElementById("menu");window.scrollY<120?e.classList.remove("scrolled"):e.classList.add("scrolled")}),window.addEventListener("keydown",function(e){if(e.altKey)return;if(document.activeElement.tagName=="INPUT")return;e.key=="ArrowLeft"?document.getElementById("prev-article").click():e.key=="ArrowRight"&&document.getElementById("next-article").click()})</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})'></script><title>Binary Exponentiation - Algorithmica</title></head><body><nav id=sidebar><div class=title><a href=/>Algorithmica</a>
<span class=slash>/</span>
<a href=/hpc/ class=divisionAbbr>HPC</a></div><ul><li class=part>Performance Engineering</li><li><a href=/hpc/complexity/>Complexity Models</a></li><ol><li><a href=/hpc/complexity/hardware/>Modern Hardware</a></li><li><a href=/hpc/complexity/languages/>Programming Languages</a></li></ol><li><a href=/hpc/architecture/>Computer Architecture</a></li><ol><li><a href=/hpc/architecture/isa/>Instruction Set Architectures</a></li><li><a href=/hpc/architecture/assembly/>Assembly Language</a></li><li><a href=/hpc/architecture/loops/>Loops and Conditionals</a></li><li><a href=/hpc/architecture/functions/>Functions and Recursion</a></li><li><a href=/hpc/architecture/indirect/>Indirect Branching</a></li><li><a href=/hpc/architecture/layout/>Machine Code Layout</a></li></ol><li><a href=/hpc/pipelining/>Instruction-Level Parallelism</a></li><ol><li><a href=/hpc/pipelining/hazards/>Pipeline Hazards</a></li><li><a href=/hpc/pipelining/branching/>The Cost of Branching</a></li><li><a href=/hpc/pipelining/branchless/>Branchless Programming</a></li><li><a href=/hpc/pipelining/tables/>Instruction Tables</a></li><li><a href=/hpc/pipelining/throughput/>Throughput Computing</a></li></ol><li><a href=/hpc/compilation/>Compilation</a></li><ol><li><a href=/hpc/compilation/stages/>Stages of Compilation</a></li><li><a href=/hpc/compilation/flags/>Flags and Targets</a></li><li><a href=/hpc/compilation/situational/>Situational Optimizations</a></li><li><a href=/hpc/compilation/contracts/>Contract Programming</a></li><li><a href=/hpc/compilation/precalc/>Precomputation</a></li></ol><li><a href=/hpc/profiling/>Profiling</a></li><ol><li><a href=/hpc/profiling/instrumentation/>Instrumentation</a></li><li><a href=/hpc/profiling/events/>Statistical Profiling</a></li><li><a href=/hpc/profiling/simulation/>Program Simulation</a></li><li><a href=/hpc/profiling/mca/>Machine Code Analyzers</a></li><li><a href=/hpc/profiling/benchmarking/>Benchmarking</a></li><li><a href=/hpc/profiling/noise/>Getting Accurate Results</a></li></ol><li><a href=/hpc/arithmetic/>Arithmetic</a></li><ol><li><a href=/hpc/arithmetic/float/>Floating-Point Numbers</a></li><li><a href=/hpc/arithmetic/ieee-754/>IEEE 754 Floats</a></li><li><a href=/hpc/arithmetic/errors/>Rounding Errors</a></li><li><a href=/hpc/arithmetic/newton/>Newton's Method</a></li><li><a href=/hpc/arithmetic/rsqrt/>Fast Inverse Square Root</a></li><li><a href=/hpc/arithmetic/integer/>Integer Numbers</a></li><li><a href=/hpc/arithmetic/division/>Integer Division</a></li></ol><li><a href=/hpc/number-theory/>Number Theory</a></li><ol><li><a href=/hpc/number-theory/modular/>Modular Arithmetic</a></li><li><a href=/hpc/number-theory/exponentiation/ id=active-element>Binary Exponentiation</a></li><li><a href=/hpc/number-theory/euclid-extended/>Extended Euclidean Algorithm</a></li><li><a href=/hpc/number-theory/montgomery/>Montgomery Multiplication</a></li></ol><li><a href=/hpc/external-memory/>External Memory</a></li><ol><li><a href=/hpc/external-memory/hierarchy/>Memory Hierarchy</a></li><li><a href=/hpc/external-memory/virtual/>Virtual Memory</a></li><li><a href=/hpc/external-memory/model/>External Memory Model</a></li><li><a href=/hpc/external-memory/sorting/>External Sorting</a></li><li><a href=/hpc/external-memory/list-ranking/>List Ranking</a></li><li><a href=/hpc/external-memory/policies/>Eviction Policies</a></li><li><a href=/hpc/external-memory/oblivious/>Cache-Oblivious Algorithms</a></li><li><a href=/hpc/external-memory/locality/>Spatial and Temporal Locality</a></li></ol><li><a href=/hpc/cpu-cache/>RAM & CPU Caches</a></li><ol><li><a href=/hpc/cpu-cache/bandwidth/>Memory Bandwidth</a></li><li><a href=/hpc/cpu-cache/latency/>Memory Latency</a></li><li><a href=/hpc/cpu-cache/cache-lines/>Cache Lines</a></li><li><a href=/hpc/cpu-cache/sharing/>Memory Sharing</a></li><li><a href=/hpc/cpu-cache/mlp/>Memory-Level Parallelism</a></li><li><a href=/hpc/cpu-cache/prefetching/>Prefetching</a></li><li><a href=/hpc/cpu-cache/alignment/>Alignment and Packing</a></li><li><a href=/hpc/cpu-cache/pointers/>Pointer Alternatives</a></li><li><a href=/hpc/cpu-cache/associativity/>Cache Associativity</a></li><li><a href=/hpc/cpu-cache/paging/>Memory Paging</a></li><li><a href=/hpc/cpu-cache/aos-soa/>AoS and SoA</a></li></ol><li><a href=/hpc/simd/>SIMD Parallelism</a></li><ol><li><a href=/hpc/simd/intrinsics/>Intrinsics and Vector Types</a></li><li><a href=/hpc/simd/moving/>Moving Data</a></li><li><a href=/hpc/simd/reduction/>Reductions</a></li><li><a href=/hpc/simd/masking/>Masking and Blending</a></li><li><a href=/hpc/simd/shuffling/>In-Register Shuffles</a></li><li><a href=/hpc/simd/auto-vectorization/>Auto-Vectorization and SPMD</a></li></ol><li><a href=/hpc/algorithms/>Algorithms Case Studies</a></li><ol><li><a href=/hpc/algorithms/gcd/>Binary GCD</a></li><li><a href=/hpc/algorithms/factorization/>Integer Factorization</a></li><li><a href=/hpc/algorithms/argmin/>Argmin with SIMD</a></li><li><a href=/hpc/algorithms/prefix/>Prefix Sum with SIMD</a></li><li><a href=/hpc/algorithms/matmul/>Matrix Multiplication</a></li></ol><li><a href=/hpc/data-structures/>Data Structures Case Studies</a></li><ol><li><a href=/hpc/data-structures/binary-search/>Binary Search</a></li><li><a href=/hpc/data-structures/s-tree/>Static B-Trees</a></li><li><a href=/hpc/data-structures/b-tree/>Search Trees</a></li><li><a href=/hpc/data-structures/segment-trees/>Segment Trees</a></li></ol></ul></nav><div id=wrapper><menu id=menu><div class=left><a><img src=/icons/bars-solid.svg onclick=toggleSidebar() title='open table of contents'>
</a><a><img src=/icons/adjust-solid.svg style=position:relative;top:-1px onclick='switchTheme(localStorage.getItem("theme")=="dark"?"light":"dark")' title='dark theme'>
</a><a><img src=/icons/search-solid.svg onclick=toggleSearch() title=search></a></div><div class=title>Binary Exponentiation</div><div class=right><a onclick=window.print()><img src=/icons/print-solid.svg title=print>
</a><a href=https://prose.io/#algorithmica-org/algorithmica/edit/master//hpc%2fnumber-theory%2fexponentiation.md><img src=/icons/edit-solid.svg title=edit style=width:18px;position:relative;right:-2px;top:-1px>
</a><a href=https://github.com/algorithmica-org/algorithmica/blob/master//hpc/number-theory/exponentiation.md class=github-main><img src=/icons/github-brands.svg title='view on github'></a></div></menu><main><div id=search><input id=search-bar type=search placeholder='Search this book…' oninput=search()><div id=search-count></div><div id=search-results></div></div><header><h1>Binary Exponentiation</h1><div class=info></div></header><article><p>In modular arithmetic (and computational algebra in general), you often need to raise a number to the $n$-th power — to do <a href=../modular/#modular-division>modular division</a>, perform <a href=../modular/#fermats-theorem>primality tests</a>, or compute some combinatorial values — ­and you usually want to spend fewer than $\Theta(n)$ operations calculating it.</p><p><em>Binary exponentiation</em>, also known as <em>exponentiation by squaring</em>, is a method that allows for computation of the $n$-th power using $O(\log n)$ multiplications, relying on the following observation:</p>$$
\begin{aligned}
a^{2k} &= (a^k)^2
\\  a^{2k + 1}   &= (a^k)^2 \cdot a
\end{aligned}
$$
To compute $a^n$, we can recursively compute $a^{\lfloor n / 2 \rfloor}$, square it, and then optionally multiply by $a$ if $n$ is odd, corresponding to the following recurrence:
$$
a^n = f(a, n) = \begin{cases}
1, && n = 0
\\ f(a, \frac{n}{2})^2,   && 2 \mid n
\\ f(a, n - 1) \cdot a, && 2 \nmid n
\end{cases}

    $$
 <p>Since $n$ is at least halved every two recursive transitions, the depth of this recurrence and the total number of multiplications will be at most $O(\log n)$.</p><span class=anchor id=recursive-implementation></span><h3><a class=anchor-link href=https://en.algorithmica.org/hpc/number-theory/exponentiation/#recursive-implementation>#</a>Recursive Implementation</h3><p>As we already have a recurrence, it is natural to implement the algorithm as a case matching recursive function:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>M</span> <span class=o>=</span> <span class=mf>1e9</span> <span class=o>+</span> <span class=mi>7</span><span class=p>;</span> <span class=c1>// modulo
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>typedef</span> <span class=kt>unsigned</span> <span class=kt>long</span> <span class=kt>long</span> <span class=n>u64</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>u64</span> <span class=nf>binpow</span><span class=p>(</span><span class=n>u64</span> <span class=n>a</span><span class=p>,</span> <span class=n>u64</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>n</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>n</span> <span class=o>%</span> <span class=mi>2</span> <span class=o>==</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>binpow</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>n</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>a</span> <span class=o>%</span> <span class=n>M</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>u64</span> <span class=n>b</span> <span class=o>=</span> <span class=n>binpow</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>n</span> <span class=o>/</span> <span class=mi>2</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>b</span> <span class=o>*</span> <span class=n>b</span> <span class=o>%</span> <span class=n>M</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>In our benchmark, we use $n = m - 2$ so that we compute the <a href=../modular/#modular-division>multiplicative inverse</a> of $a$ modulo $m$:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>u64</span> <span class=nf>inverse</span><span class=p>(</span><span class=n>u64</span> <span class=n>a</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>binpow</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>M</span> <span class=o>-</span> <span class=mi>2</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>We use $m = 10^9+7$, which is a modulo value commonly used in competitive programming to calculate checksums in combinatorial problems — because it is prime (allowing inverse via binary exponentiation), sufficiently large, not overflowing <code>int</code> in addition, not overflowing <code>long long</code> in multiplication, and easy to type as <code>1e9 + 7</code>.</p><p>Since we use it as compile-time constant in the code, the compiler can optimize the modulo by <a href=/hpc/arithmetic/division/>replacing it with multiplication</a> (even if it is not a compile-time constant, it is still cheaper to compute the magic constants by hand once and use them for fast reduction).</p><p>The execution path — and consequently the running time — depends on the value of $n$. For this particular $n$, the baseline implementation takes around 330ns per call. As recursion introduces some <a href=/hpc/architecture/functions/>overhead</a>, it makes sense to unroll the implementation into an iterative procedure.</p><span class=anchor id=iterative-implementation></span><h3><a class=anchor-link href=https://en.algorithmica.org/hpc/number-theory/exponentiation/#iterative-implementation>#</a>Iterative Implementation</h3><p>The result of $a^n$ can be represented as the product of $a$ to some powers of two — those that correspond to 1s in the binary representation of $n$. For example, if $n = 42 = 32 + 8 + 2$, then</p>$$
a^{42} = a^{32+8+2} = a^{32} \cdot a^8 \cdot a^2
$$<p>To calculate this product, we can iterate over the bits of $n$ maintaining two variables: the value of $a^{2^k}$ and the current product after considering $k$ lowest bits of $n$. On each step, we multiply the current product by $a^{2^k}$ if the $k$-th bit of $n$ is set, and, in either case, square $a^k$ to get $a^{2^k \cdot 2} = a^{2^{k+1}}$ that will be used on the next iteration.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>u64</span> <span class=nf>binpow</span><span class=p>(</span><span class=n>u64</span> <span class=n>a</span><span class=p>,</span> <span class=n>u64</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>u64</span> <span class=n>r</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=p>(</span><span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>n</span> <span class=o>&amp;</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>r</span> <span class=o>=</span> <span class=n>res</span> <span class=o>*</span> <span class=n>a</span> <span class=o>%</span> <span class=n>M</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>a</span> <span class=o>=</span> <span class=n>a</span> <span class=o>*</span> <span class=n>a</span> <span class=o>%</span> <span class=n>M</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>n</span> <span class=o>&gt;&gt;=</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>r</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>The iterative implementation takes about 180ns per call. The heavy calculations are the same; the improvement mainly comes from the reduced dependency chain: <code>a = a * a % M</code> needs to finish before the loop can proceed, and it can now execute concurrently with <code>r = res * a % M</code>.</p><p>The performance also benefits from $n$ being a constant, <a href=/hpc/pipelining/branching/>making all branches predictable</a> and letting the scheduler know what needs to be executed in advance. The compiler, however, does not take advantage of it and does not unroll the <code>while(n) n >>= 1</code> loop. We can rewrite it as a <code>for</code> loop that performs constant 30 iterations:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>u64</span> <span class=nf>inverse</span><span class=p>(</span><span class=n>u64</span> <span class=n>a</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>u64</span> <span class=n>r</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=cp>#pragma GCC unroll(30)
</span></span></span><span class=line><span class=cl><span class=cp></span>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>l</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>l</span> <span class=o>&lt;</span> <span class=mi>30</span><span class=p>;</span> <span class=n>l</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span> <span class=p>(</span><span class=n>M</span> <span class=o>-</span> <span class=mi>2</span><span class=p>)</span> <span class=o>&gt;&gt;</span> <span class=n>l</span> <span class=o>&amp;</span> <span class=mi>1</span> <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>r</span> <span class=o>=</span> <span class=n>r</span> <span class=o>*</span> <span class=n>a</span> <span class=o>%</span> <span class=n>M</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>a</span> <span class=o>=</span> <span class=n>a</span> <span class=o>*</span> <span class=n>a</span> <span class=o>%</span> <span class=n>M</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>r</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>This forces the compiler to generate only the instructions we need, shaving off another 10ns and making the total running time ~170ns.</p><p>Note that the performance depends not only on the binary length of $n$, but also on the number of binary 1s. If $n$ is $2^{30}$, it takes around 20ns less as we don&rsquo;t have to to perform any off-path multiplications.</p></article><div class=nextprev><div class=left><a href=https://en.algorithmica.org/hpc/number-theory/modular/ id=prev-article>← Modular Arithmetic</a></div><div class=right><a href=https://en.algorithmica.org/hpc/number-theory/euclid-extended/ id=next-article>Extended Euclidean Algorithm →</a></div></div></main><footer>Copyright 2021–2022 Sergey Slotin<br></footer></div></body></html>