<!doctype html><html lang=en-us><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-WBN59M8Y5S"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WBN59M8Y5S")</script><script type=text/javascript>(function(e,t,n,s,o,i,a){e[o]=e[o]||function(){(e[o].a=e[o].a||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym"),ym(53961409,"init",{clickmap:!0,trackLinks:!0,accurateTrackBounce:!0,webvisor:!0})</script><noscript><div><img src=https://mc.yandex.ru/watch/53961409 style=position:absolute;left:-9999px alt></div></noscript><meta charset=utf-8><link rel=stylesheet href=/hugo-page/style.min.a3a4a7a8e8602aaa85b7cb3d655edde028ac80d73f2a97389e2cbcf995dd672d.css integrity="sha256-o6SnqOhgKqqFt8s9ZV7d4CisgNc/Kpc4niy8+ZXdZy0="><link rel=stylesheet href=/syntax.css id=syntax-theme><link rel=stylesheet type=text/css href=https://tikzjax.com/v1/fonts.css><script src=https://tikzjax.com/v1/tikzjax.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js></script><script src=/scripts/lunr.stemmer.support.min.js></script><script src=/scripts/lunr.ru.min.js></script><script src=/scripts/lunr.multi.min.js></script><link rel=stylesheet id=theme><script>function toggleSidebar(){console.log("Toggling sidebar visibility");var e=document.getElementById("sidebar"),t=document.getElementById("wrapper");(e.classList.contains("sidebar-toggled")||window.getComputedStyle(e).display=="block")&&(e.classList.toggle("sidebar-hidden"),t.classList.toggle("sidebar-hidden")),e.classList.add("sidebar-toggled"),t.classList.add("sidebar-toggled")}function switchTheme(e){console.log("Changing theme:",e),document.getElementById("theme").href=e=="dark"?"/hugo-page/dark.min.b3ae1169831434b11b48de5b3e3210547eea6b7884c295ab0030cb973ea0dc49.css":"",document.getElementById("syntax-theme").href=e=="dark"?"/syntax-dark.css":"/syntax.css",localStorage.setItem("theme",e)}async function toggleSearch(){console.log("Toggling search");var e=document.getElementById("search");if(window.getComputedStyle(e).display=="none"?(e.style.display="block",window.scrollTo({top:0}),document.getElementById("search-bar").focus()):e.style.display="none",!index){console.log("Fetching index");const e=await fetch("/hugo-page/searchindex.json"),t=await e.json();index=lunr(function(){this.use(lunr.multiLanguage("en","ru")),this.field("title",{boost:5}),this.field("content",{boost:1}),t.forEach(function(e){this.add(e),articles.push(e)},this)}),console.log("Ready to search")}}var articles=[],index=void 0;function search(){var n,e=document.getElementById("search-bar").value,s=document.getElementById("search-results"),o=document.getElementById("search-count");if(e==""){s.innerHTML="",o.innerHTML="";return}n=index.search(e),o.innerHTML="Found <b>"+n.length+"</b> pages";let t="";for(const a in n){const i=articles[n[a].ref];t+='<li><a href="'+i.path+'">'+i.title+"</a> <p>";const s=i.content,o=80;if(s.includes(e)){const n=s.indexOf(e);n>o&&(t+="…"),t+=s.substring(n-o,n)+"<b>"+e+"</b>"+s.substring(n+e.length,n+e.length+o)}else t+=s.substring(0,o*2);t+="…</p></li>"}s.innerHTML=t}localStorage.getItem("theme")=="dark"&&switchTheme("dark"),window.addEventListener("load",function(){var e=document.getElementById("active-element");e&&e.scrollIntoView({block:"center"})}),window.addEventListener("scroll",function(){var e=document.getElementById("menu");window.scrollY<120?e.classList.remove("scrolled"):e.classList.add("scrolled")}),window.addEventListener("keydown",function(e){if(e.altKey)return;if(document.activeElement.tagName=="INPUT")return;e.key=="ArrowLeft"?document.getElementById("prev-article").click():e.key=="ArrowRight"&&document.getElementById("next-article").click()})</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})'></script><title>The Cost of Branching - Algorithmica</title></head><body><nav id=sidebar><div class=title><a href=/>Algorithmica</a>
<span class=slash>/</span>
<a href=/hugo-page/hpc/ class=divisionAbbr>HPC</a></div><ul><li class=part>Performance Engineering</li><li><a href=/hugo-page/hpc/complexity/>Complexity Models</a></li><ol><li><a href=/hugo-page/hpc/complexity/hardware/>Modern Hardware</a></li><li><a href=/hugo-page/hpc/complexity/languages/>Programming Languages</a></li></ol><li><a href=/hugo-page/hpc/architecture/>Computer Architecture</a></li><ol><li><a href=/hugo-page/hpc/architecture/isa/>Instruction Set Architectures</a></li><li><a href=/hugo-page/hpc/architecture/assembly/>Assembly Language</a></li><li><a href=/hugo-page/hpc/architecture/loops/>Loops and Conditionals</a></li><li><a href=/hugo-page/hpc/architecture/functions/>Functions and Recursion</a></li><li><a href=/hugo-page/hpc/architecture/indirect/>Indirect Branching</a></li><li><a href=/hugo-page/hpc/architecture/layout/>Machine Code Layout</a></li></ol><li><a href=/hugo-page/hpc/pipelining/>Instruction-Level Parallelism</a></li><ol><li><a href=/hugo-page/hpc/pipelining/hazards/>Pipeline Hazards</a></li><li><a href=/hugo-page/hpc/pipelining/branching/ id=active-element>The Cost of Branching</a></li><li><a href=/hugo-page/hpc/pipelining/branchless/>Branchless Programming</a></li><li><a href=/hugo-page/hpc/pipelining/tables/>Instruction Tables</a></li><li><a href=/hugo-page/hpc/pipelining/throughput/>Throughput Computing</a></li></ol><li><a href=/hugo-page/hpc/compilation/>Compilation</a></li><ol><li><a href=/hugo-page/hpc/compilation/stages/>Stages of Compilation</a></li><li><a href=/hugo-page/hpc/compilation/flags/>Flags and Targets</a></li><li><a href=/hugo-page/hpc/compilation/situational/>Situational Optimizations</a></li><li><a href=/hugo-page/hpc/compilation/contracts/>Contract Programming</a></li><li><a href=/hugo-page/hpc/compilation/precalc/>Precomputation</a></li></ol><li><a href=/hugo-page/hpc/profiling/>Profiling</a></li><ol><li><a href=/hugo-page/hpc/profiling/instrumentation/>Instrumentation</a></li><li><a href=/hugo-page/hpc/profiling/events/>Statistical Profiling</a></li><li><a href=/hugo-page/hpc/profiling/simulation/>Program Simulation</a></li><li><a href=/hugo-page/hpc/profiling/mca/>Machine Code Analyzers</a></li><li><a href=/hugo-page/hpc/profiling/benchmarking/>Benchmarking</a></li><li><a href=/hugo-page/hpc/profiling/noise/>Getting Accurate Results</a></li></ol><li><a href=/hugo-page/hpc/arithmetic/>Arithmetic</a></li><ol><li><a href=/hugo-page/hpc/arithmetic/float/>Floating-Point Numbers</a></li><li><a href=/hugo-page/hpc/arithmetic/ieee-754/>IEEE 754 Floats</a></li><li><a href=/hugo-page/hpc/arithmetic/errors/>Rounding Errors</a></li><li><a href=/hugo-page/hpc/arithmetic/newton/>Newton's Method</a></li><li><a href=/hugo-page/hpc/arithmetic/rsqrt/>Fast Inverse Square Root</a></li><li><a href=/hugo-page/hpc/arithmetic/integer/>Integer Numbers</a></li><li><a href=/hugo-page/hpc/arithmetic/division/>Integer Division</a></li></ol><li><a href=/hugo-page/hpc/number-theory/>Number Theory</a></li><ol><li><a href=/hugo-page/hpc/number-theory/modular/>Modular Arithmetic</a></li><li><a href=/hugo-page/hpc/number-theory/exponentiation/>Binary Exponentiation</a></li><li><a href=/hugo-page/hpc/number-theory/euclid-extended/>Extended Euclidean Algorithm</a></li><li><a href=/hugo-page/hpc/number-theory/montgomery/>Montgomery Multiplication</a></li></ol><li><a href=/hugo-page/hpc/external-memory/>External Memory</a></li><ol><li><a href=/hugo-page/hpc/external-memory/hierarchy/>Memory Hierarchy</a></li><li><a href=/hugo-page/hpc/external-memory/virtual/>Virtual Memory</a></li><li><a href=/hugo-page/hpc/external-memory/model/>External Memory Model</a></li><li><a href=/hugo-page/hpc/external-memory/sorting/>External Sorting</a></li><li><a href=/hugo-page/hpc/external-memory/list-ranking/>List Ranking</a></li><li><a href=/hugo-page/hpc/external-memory/policies/>Eviction Policies</a></li><li><a href=/hugo-page/hpc/external-memory/oblivious/>Cache-Oblivious Algorithms</a></li><li><a href=/hugo-page/hpc/external-memory/locality/>Spatial and Temporal Locality</a></li></ol><li><a href=/hugo-page/hpc/cpu-cache/>RAM & CPU Caches</a></li><ol><li><a href=/hugo-page/hpc/cpu-cache/bandwidth/>Memory Bandwidth</a></li><li><a href=/hugo-page/hpc/cpu-cache/latency/>Memory Latency</a></li><li><a href=/hugo-page/hpc/cpu-cache/cache-lines/>Cache Lines</a></li><li><a href=/hugo-page/hpc/cpu-cache/sharing/>Memory Sharing</a></li><li><a href=/hugo-page/hpc/cpu-cache/mlp/>Memory-Level Parallelism</a></li><li><a href=/hugo-page/hpc/cpu-cache/prefetching/>Prefetching</a></li><li><a href=/hugo-page/hpc/cpu-cache/alignment/>Alignment and Packing</a></li><li><a href=/hugo-page/hpc/cpu-cache/pointers/>Pointer Alternatives</a></li><li><a href=/hugo-page/hpc/cpu-cache/associativity/>Cache Associativity</a></li><li><a href=/hugo-page/hpc/cpu-cache/paging/>Memory Paging</a></li><li><a href=/hugo-page/hpc/cpu-cache/aos-soa/>AoS and SoA</a></li></ol><li><a href=/hugo-page/hpc/simd/>SIMD Parallelism</a></li><ol><li><a href=/hugo-page/hpc/simd/intrinsics/>Intrinsics and Vector Types</a></li><li><a href=/hugo-page/hpc/simd/moving/>Moving Data</a></li><li><a href=/hugo-page/hpc/simd/reduction/>Reductions</a></li><li><a href=/hugo-page/hpc/simd/masking/>Masking and Blending</a></li><li><a href=/hugo-page/hpc/simd/shuffling/>In-Register Shuffles</a></li><li><a href=/hugo-page/hpc/simd/auto-vectorization/>Auto-Vectorization and SPMD</a></li></ol><li><a href=/hugo-page/hpc/algorithms/>Algorithms Case Studies</a></li><ol><li><a href=/hugo-page/hpc/algorithms/gcd/>Binary GCD</a></li><li><a href=/hugo-page/hpc/algorithms/factorization/>Integer Factorization</a></li><li><a href=/hugo-page/hpc/algorithms/argmin/>Argmin with SIMD</a></li><li><a href=/hugo-page/hpc/algorithms/prefix/>Prefix Sum with SIMD</a></li><li><a href=/hugo-page/hpc/algorithms/matmul/>Matrix Multiplication</a></li></ol><li><a href=/hugo-page/hpc/data-structures/>Data Structures Case Studies</a></li><ol><li><a href=/hugo-page/hpc/data-structures/binary-search/>Binary Search</a></li><li><a href=/hugo-page/hpc/data-structures/s-tree/>Static B-Trees</a></li><li><a href=/hugo-page/hpc/data-structures/b-tree/>Search Trees</a></li><li><a href=/hugo-page/hpc/data-structures/segment-trees/>Segment Trees</a></li></ol></ul></nav><div id=wrapper><menu id=menu><div class=left><a><img src=/icons/bars-solid.svg onclick=toggleSidebar() title='open table of contents'>
</a><a><img src=/icons/adjust-solid.svg style=position:relative;top:-1px onclick='switchTheme(localStorage.getItem("theme")=="dark"?"light":"dark")' title='dark theme'>
</a><a><img src=/icons/search-solid.svg onclick=toggleSearch() title=search></a></div><div class=title>The Cost of Branching</div><div class=right><a onclick=window.print()><img src=/icons/print-solid.svg title=print>
</a><a href=https://prose.io/#algorithmica-org/algorithmica/edit/master//hpc%2fpipelining%2fbranching.md><img src=/icons/edit-solid.svg title=edit style=width:18px;position:relative;right:-2px;top:-1px>
</a><a href=https://github.com/algorithmica-org/algorithmica/blob/master//hpc/pipelining/branching.md class=github-main><img src=/icons/github-brands.svg title='view on github'></a></div></menu><main><div id=search><input id=search-bar type=search placeholder='Search this book…' oninput=search()><div id=search-count></div><div id=search-results></div></div><header><h1>The Cost of Branching</h1><div class=info></div></header><article><p>When a CPU encounters a conditional jump or <a href=/hpc/architecture/indirect>any other type of branching</a>, it doesn&rsquo;t just sit idle until its condition is computed — instead, it starts <em>speculatively executing</em> the branch that seems more likely to be taken immediately. During execution, the CPU computes statistics about branches taken on each instruction, and after some time, they start to predict them by recognizing common patterns.</p><p>For this reason, the true &ldquo;cost&rdquo; of a branch largely depends on how well it can be predicted by the CPU. If it is a pure 50/50 coin toss, you have to suffer a <a href=../hazards>control hazard</a> and discard the entire pipeline, taking another 15-20 cycles to build up again. And if the branch is always or never taken, you pay almost nothing except checking the condition.</p><span class=anchor id=an-experiment></span><h2><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/pipelining/branching/#an-experiment>#</a>An Experiment</h2><p>As a case study, we are going to create an array of random integers between 0 and 99 inclusive:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>rand</span><span class=p>()</span> <span class=o>%</span> <span class=mi>100</span><span class=p>;</span>
</span></span></code></pre></div><p>Then we create a loop where we sum up all its elements under 50:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>volatile</span> <span class=kt>int</span> <span class=n>s</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>&lt;</span> <span class=mi>50</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>+=</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span></code></pre></div><p>We set $N = 10^6$ and run this loop many times over so that the <a href=/hpc/cpu-cache/bandwidth>cold cache</a> effect doesn&rsquo;t mess up our results. We mark our accumulator variable as <code>volatile</code> so that the compiler doesn&rsquo;t vectorize the loop, interleave its iterations, or &ldquo;cheat&rdquo; in any other way.</p><p>On Clang, this produces assembly that looks like this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-nasm data-lang=nasm><span class=line><span class=cl>    <span class=nf>mov</span>  <span class=nb>rcx</span><span class=p>,</span> <span class=o>-</span><span class=mi>4000000</span>
</span></span><span class=line><span class=cl>    <span class=nf>jmp</span>  <span class=nv>body</span>
</span></span><span class=line><span class=cl><span class=nl>counter:</span>
</span></span><span class=line><span class=cl>    <span class=nf>add</span>  <span class=nb>rcx</span><span class=p>,</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl>    <span class=nf>jz</span>   <span class=nv>finished</span>   <span class=c1>; &#34;jump if rcx became zero&#34;</span>
</span></span><span class=line><span class=cl><span class=nl>body:</span>
</span></span><span class=line><span class=cl>    <span class=nf>mov</span>  <span class=nb>edx</span><span class=p>,</span> <span class=kt>dword</span> <span class=nv>ptr</span> <span class=p>[</span><span class=nb>rcx</span> <span class=o>+</span> <span class=nv>a</span> <span class=o>+</span> <span class=mi>4000000</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=nf>cmp</span>  <span class=nb>edx</span><span class=p>,</span> <span class=mi>49</span>
</span></span><span class=line><span class=cl>    <span class=nf>jg</span>   <span class=nv>counter</span>
</span></span><span class=line><span class=cl>    <span class=nf>add</span>  <span class=kt>dword</span> <span class=nv>ptr</span> <span class=p>[</span><span class=nb>rsp</span> <span class=o>+</span> <span class=mi>12</span><span class=p>],</span> <span class=nb>edx</span>
</span></span><span class=line><span class=cl>    <span class=nf>jmp</span>  <span class=nv>counter</span>
</span></span></code></pre></div><p>Our goal is to simulate a completely unpredictable branch, and we successfully achieve it: the code takes ~14 CPU cycles per element. For a very rough estimate of what it is supposed to be, we can assume that the branches alternate between <code>&lt;</code> and <code>>=</code>, and the pipeline is mispredicted every other iteration. Then, every two iterations:</p><ul><li>We discard the pipeline, which is 19 cycles deep on Zen 2 (i.e., it has 19 stages, each taking one cycle).</li><li>We need a memory fetch and a comparison, which costs ~5 cycles. We can check the conditions of even and odd iterations concurrently, so let&rsquo;s assume we only pay it once per 2 iterations.</li><li>In the case of the <code>&lt;</code> branch, we need another ~4 cycles to add <code>a[i]</code> to a volatile (memory-stored) variable <code>s</code>.</li></ul><p>Therefore, on average, we need to spend $(4 + 5 + 19) / 2 = 14$ cycles per element, matching what we measured.</p><span class=anchor id=branch-prediction></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/pipelining/branching/#branch-prediction>#</a>Branch Prediction</h3><p>We can replace the hardcoded <code>50</code> with a tweakable parameter <code>P</code> that effectively sets the probability of the <code>&lt;</code> branch:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>&lt;</span> <span class=n>P</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>+=</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span></code></pre></div><p>Now, if we benchmark it for different values of <code>P</code>, we get an interesting-looking graph:</p><p><figure><img src=../img/probabilities.svg><figcaption></figcaption></figure></p><p>Its peak is at 50-55%, as expected: branch misprediction is the most expensive thing here. This graph is asymmetrical: it takes just ~1 cycle to only check conditions that are never satisfied (<code>P = 0</code>), and ~7 cycles for the sum if the branch is always taken (<code>P = 100</code>).</p><p>This graph is not unimodal: there is another local minimum at around 85-90%. We spend ~6.15 cycles per element there or about 10-15% faster than when we always take the branch, accounting for the fact that we need to perform fewer additions. Branch misprediction stops affecting the performance at this point because when it happens, not the whole instruction buffer is discarded, but only the operations that were speculatively scheduled. Essentially, that 10-15% mispredict rate is the equilibrium point where we can see far enough in the pipeline not to stall but still save 10-15% on taking the cheaper <code>>=</code> branch.</p><p>Note that it costs almost nothing to check for a condition that never or almost never occurs. This is why programmers use runtime exceptions and base case checks so profusely: if they are indeed rare, they don&rsquo;t really cost anything.</p><span class=anchor id=pattern-detection></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/pipelining/branching/#pattern-detection>#</a>Pattern Detection</h3><p>In our example, everything that was needed for efficient branch prediction is a hardware statistics counter. If we historically took branch A more often than branch B, then it makes sense to speculatively execute branch A. But branch predictors on modern CPUs are considerably more advanced than that and can detect much more complicated patterns.</p><p>Let&rsquo;s fix <code>P</code> back at 50, and then sort the array first before the main summation loop:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>rand</span><span class=p>()</span> <span class=o>%</span> <span class=mi>100</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>std</span><span class=o>::</span><span class=n>sort</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>a</span> <span class=o>+</span> <span class=n>n</span><span class=p>);</span>
</span></span></code></pre></div><p>We are still processing the same elements, but in a different order, and instead of 14 cycles, it now runs in a little bit more than 4, which is exactly the average of the cost of the pure <code>&lt;</code> and <code>>=</code> branches.</p><p>The branch predictor can pick up on much more complicated patterns than just &ldquo;always left, then always right&rdquo; or &ldquo;left-right-left-right.&rdquo; If we just decrease the size of the array $N$ to 1000 (without sorting it), then the branch predictor memorizes the entire sequence of comparisons, and the benchmark again measures at around 4 cycles — in fact, even slightly fewer than in the sorted array case, because in the former case branch predictor needs to spend some time flicking between the &ldquo;always yes&rdquo; and &ldquo;always no&rdquo; states.</p><span class=anchor id=hinting-likeliness-of-branches></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/pipelining/branching/#hinting-likeliness-of-branches>#</a>Hinting Likeliness of Branches</h3><p>If you know beforehand which branch is more likely, it may be beneficial to <a href=/hpc/compilation/situational>pass that information</a> to the compiler:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>&lt;</span> <span class=n>P</span><span class=p>)</span> <span class=na>[[likely]]</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>+=</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span></code></pre></div><p>When <code>P = 75</code>, it measures around ~7.3 cycles per element, while the original version without the hint needs ~8.3.</p><p>This hint does not eliminate the branch or communicate anything to the branch predictor, but it changes the <a href=/hpc/architecture/layout>machine code layout</a> in a way that lets the CPU front-end process the more likely branch slightly faster (although usually by no more than one cycle).</p><p>This optimization is only beneficial when you know which branch is more likely to be taken before the compilation stage. When the branch is fundamentally unpredictable, we can try to remove it completely using <em>predication</em> — a profoundly important technique that we are going to explore in <a href=../branchless>the next section</a>.</p><span class=anchor id=acknowledgements></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/pipelining/branching/#acknowledgements>#</a>Acknowledgements</h3><p>This case study is inspired by <a href=https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array>the most upvoted Stack Overflow question ever</a>.</p></article><div class=nextprev><div class=left><a href=http://jyang772.github.io/hugo-page/hpc/pipelining/hazards/ id=prev-article>← Pipeline Hazards</a></div><div class=right><a href=http://jyang772.github.io/hugo-page/hpc/pipelining/branchless/ id=next-article>Branchless Programming →</a></div></div></main><footer>Copyright 2021–2022 Sergey Slotin<br></footer></div></body></html>