<!doctype html><html lang=en-us><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-WBN59M8Y5S"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WBN59M8Y5S")</script><script type=text/javascript>(function(e,t,n,s,o,i,a){e[o]=e[o]||function(){(e[o].a=e[o].a||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym"),ym(53961409,"init",{clickmap:!0,trackLinks:!0,accurateTrackBounce:!0,webvisor:!0})</script><noscript><div><img src=https://mc.yandex.ru/watch/53961409 style=position:absolute;left:-9999px alt></div></noscript><meta charset=utf-8><link rel=stylesheet href=/hugo-page/style.min.a3a4a7a8e8602aaa85b7cb3d655edde028ac80d73f2a97389e2cbcf995dd672d.css integrity="sha256-o6SnqOhgKqqFt8s9ZV7d4CisgNc/Kpc4niy8+ZXdZy0="><link rel=stylesheet href=/syntax.css id=syntax-theme><link rel=stylesheet type=text/css href=https://tikzjax.com/v1/fonts.css><script src=https://tikzjax.com/v1/tikzjax.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js></script><script src=/hugo-page/scripts/lunr.stemmer.support.min.js></script><script src=/hugo-page/scripts/lunr.ru.min.js></script><script src=/hugo-page/scripts/lunr.multi.min.js></script><link rel=stylesheet id=theme><script>function toggleSidebar(){console.log("Toggling sidebar visibility");var e=document.getElementById("sidebar"),t=document.getElementById("wrapper");(e.classList.contains("sidebar-toggled")||window.getComputedStyle(e).display=="block")&&(e.classList.toggle("sidebar-hidden"),t.classList.toggle("sidebar-hidden")),e.classList.add("sidebar-toggled"),t.classList.add("sidebar-toggled")}function switchTheme(e){console.log("Changing theme:",e),document.getElementById("theme").href=e=="dark"?"/hugo-page/dark.min.b3ae1169831434b11b48de5b3e3210547eea6b7884c295ab0030cb973ea0dc49.css":"",document.getElementById("syntax-theme").href=e=="dark"?"/syntax-dark.css":"/syntax.css",localStorage.setItem("theme",e)}async function toggleSearch(){console.log("Toggling search");var e=document.getElementById("search");if(window.getComputedStyle(e).display=="none"?(e.style.display="block",window.scrollTo({top:0}),document.getElementById("search-bar").focus()):e.style.display="none",!index){console.log("Fetching index");const e=await fetch("/hugo-page/searchindex.json"),t=await e.json();index=lunr(function(){this.use(lunr.multiLanguage("en","ru")),this.field("title",{boost:5}),this.field("content",{boost:1}),t.forEach(function(e){this.add(e),articles.push(e)},this)}),console.log("Ready to search")}}var articles=[],index=void 0;function search(){var n,e=document.getElementById("search-bar").value,s=document.getElementById("search-results"),o=document.getElementById("search-count");if(e==""){s.innerHTML="",o.innerHTML="";return}n=index.search(e),o.innerHTML="Found <b>"+n.length+"</b> pages";let t="";for(const a in n){const i=articles[n[a].ref];t+='<li><a href="'+i.path+'">'+i.title+"</a> <p>";const s=i.content,o=80;if(s.includes(e)){const n=s.indexOf(e);n>o&&(t+="…"),t+=s.substring(n-o,n)+"<b>"+e+"</b>"+s.substring(n+e.length,n+e.length+o)}else t+=s.substring(0,o*2);t+="…</p></li>"}s.innerHTML=t}localStorage.getItem("theme")=="dark"&&switchTheme("dark"),window.addEventListener("load",function(){var e=document.getElementById("active-element");e&&e.scrollIntoView({block:"center"})}),window.addEventListener("scroll",function(){var e=document.getElementById("menu");window.scrollY<120?e.classList.remove("scrolled"):e.classList.add("scrolled")}),window.addEventListener("keydown",function(e){if(e.altKey)return;if(document.activeElement.tagName=="INPUT")return;e.key=="ArrowLeft"?document.getElementById("prev-article").click():e.key=="ArrowRight"&&document.getElementById("next-article").click()})</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})'></script><title>Prefix Sum with SIMD - Algorithmica</title></head><body><nav id=sidebar><div class=title><a href=/>Algorithmica</a>
<span class=slash>/</span>
<a href=/hugo-page/hpc/ class=divisionAbbr>HPC</a></div><ul><li class=part>Performance Engineering</li><li><a href=/hugo-page/hpc/complexity/>Complexity Models</a></li><ol><li><a href=/hugo-page/hpc/complexity/hardware/>Modern Hardware</a></li><li><a href=/hugo-page/hpc/complexity/languages/>Programming Languages</a></li></ol><li><a href=/hugo-page/hpc/architecture/>Computer Architecture</a></li><ol><li><a href=/hugo-page/hpc/architecture/isa/>Instruction Set Architectures</a></li><li><a href=/hugo-page/hpc/architecture/assembly/>Assembly Language</a></li><li><a href=/hugo-page/hpc/architecture/loops/>Loops and Conditionals</a></li><li><a href=/hugo-page/hpc/architecture/functions/>Functions and Recursion</a></li><li><a href=/hugo-page/hpc/architecture/indirect/>Indirect Branching</a></li><li><a href=/hugo-page/hpc/architecture/layout/>Machine Code Layout</a></li></ol><li><a href=/hugo-page/hpc/pipelining/>Instruction-Level Parallelism</a></li><ol><li><a href=/hugo-page/hpc/pipelining/hazards/>Pipeline Hazards</a></li><li><a href=/hugo-page/hpc/pipelining/branching/>The Cost of Branching</a></li><li><a href=/hugo-page/hpc/pipelining/branchless/>Branchless Programming</a></li><li><a href=/hugo-page/hpc/pipelining/tables/>Instruction Tables</a></li><li><a href=/hugo-page/hpc/pipelining/throughput/>Throughput Computing</a></li></ol><li><a href=/hugo-page/hpc/compilation/>Compilation</a></li><ol><li><a href=/hugo-page/hpc/compilation/stages/>Stages of Compilation</a></li><li><a href=/hugo-page/hpc/compilation/flags/>Flags and Targets</a></li><li><a href=/hugo-page/hpc/compilation/situational/>Situational Optimizations</a></li><li><a href=/hugo-page/hpc/compilation/contracts/>Contract Programming</a></li><li><a href=/hugo-page/hpc/compilation/precalc/>Precomputation</a></li></ol><li><a href=/hugo-page/hpc/profiling/>Profiling</a></li><ol><li><a href=/hugo-page/hpc/profiling/instrumentation/>Instrumentation</a></li><li><a href=/hugo-page/hpc/profiling/events/>Statistical Profiling</a></li><li><a href=/hugo-page/hpc/profiling/simulation/>Program Simulation</a></li><li><a href=/hugo-page/hpc/profiling/mca/>Machine Code Analyzers</a></li><li><a href=/hugo-page/hpc/profiling/benchmarking/>Benchmarking</a></li><li><a href=/hugo-page/hpc/profiling/noise/>Getting Accurate Results</a></li></ol><li><a href=/hugo-page/hpc/arithmetic/>Arithmetic</a></li><ol><li><a href=/hugo-page/hpc/arithmetic/float/>Floating-Point Numbers</a></li><li><a href=/hugo-page/hpc/arithmetic/ieee-754/>IEEE 754 Floats</a></li><li><a href=/hugo-page/hpc/arithmetic/errors/>Rounding Errors</a></li><li><a href=/hugo-page/hpc/arithmetic/newton/>Newton's Method</a></li><li><a href=/hugo-page/hpc/arithmetic/rsqrt/>Fast Inverse Square Root</a></li><li><a href=/hugo-page/hpc/arithmetic/integer/>Integer Numbers</a></li><li><a href=/hugo-page/hpc/arithmetic/division/>Integer Division</a></li></ol><li><a href=/hugo-page/hpc/number-theory/>Number Theory</a></li><ol><li><a href=/hugo-page/hpc/number-theory/modular/>Modular Arithmetic</a></li><li><a href=/hugo-page/hpc/number-theory/exponentiation/>Binary Exponentiation</a></li><li><a href=/hugo-page/hpc/number-theory/euclid-extended/>Extended Euclidean Algorithm</a></li><li><a href=/hugo-page/hpc/number-theory/montgomery/>Montgomery Multiplication</a></li></ol><li><a href=/hugo-page/hpc/external-memory/>External Memory</a></li><ol><li><a href=/hugo-page/hpc/external-memory/hierarchy/>Memory Hierarchy</a></li><li><a href=/hugo-page/hpc/external-memory/virtual/>Virtual Memory</a></li><li><a href=/hugo-page/hpc/external-memory/model/>External Memory Model</a></li><li><a href=/hugo-page/hpc/external-memory/sorting/>External Sorting</a></li><li><a href=/hugo-page/hpc/external-memory/list-ranking/>List Ranking</a></li><li><a href=/hugo-page/hpc/external-memory/policies/>Eviction Policies</a></li><li><a href=/hugo-page/hpc/external-memory/oblivious/>Cache-Oblivious Algorithms</a></li><li><a href=/hugo-page/hpc/external-memory/locality/>Spatial and Temporal Locality</a></li></ol><li><a href=/hugo-page/hpc/cpu-cache/>RAM & CPU Caches</a></li><ol><li><a href=/hugo-page/hpc/cpu-cache/bandwidth/>Memory Bandwidth</a></li><li><a href=/hugo-page/hpc/cpu-cache/latency/>Memory Latency</a></li><li><a href=/hugo-page/hpc/cpu-cache/cache-lines/>Cache Lines</a></li><li><a href=/hugo-page/hpc/cpu-cache/sharing/>Memory Sharing</a></li><li><a href=/hugo-page/hpc/cpu-cache/mlp/>Memory-Level Parallelism</a></li><li><a href=/hugo-page/hpc/cpu-cache/prefetching/>Prefetching</a></li><li><a href=/hugo-page/hpc/cpu-cache/alignment/>Alignment and Packing</a></li><li><a href=/hugo-page/hpc/cpu-cache/pointers/>Pointer Alternatives</a></li><li><a href=/hugo-page/hpc/cpu-cache/associativity/>Cache Associativity</a></li><li><a href=/hugo-page/hpc/cpu-cache/paging/>Memory Paging</a></li><li><a href=/hugo-page/hpc/cpu-cache/aos-soa/>AoS and SoA</a></li></ol><li><a href=/hugo-page/hpc/simd/>SIMD Parallelism</a></li><ol><li><a href=/hugo-page/hpc/simd/intrinsics/>Intrinsics and Vector Types</a></li><li><a href=/hugo-page/hpc/simd/moving/>Moving Data</a></li><li><a href=/hugo-page/hpc/simd/reduction/>Reductions</a></li><li><a href=/hugo-page/hpc/simd/masking/>Masking and Blending</a></li><li><a href=/hugo-page/hpc/simd/shuffling/>In-Register Shuffles</a></li><li><a href=/hugo-page/hpc/simd/auto-vectorization/>Auto-Vectorization and SPMD</a></li></ol><li><a href=/hugo-page/hpc/algorithms/>Algorithms Case Studies</a></li><ol><li><a href=/hugo-page/hpc/algorithms/gcd/>Binary GCD</a></li><li><a href=/hugo-page/hpc/algorithms/factorization/>Integer Factorization</a></li><li><a href=/hugo-page/hpc/algorithms/argmin/>Argmin with SIMD</a></li><li><a href=/hugo-page/hpc/algorithms/prefix/ id=active-element>Prefix Sum with SIMD</a></li><li><a href=/hugo-page/hpc/algorithms/matmul/>Matrix Multiplication</a></li></ol><li><a href=/hugo-page/hpc/data-structures/>Data Structures Case Studies</a></li><ol><li><a href=/hugo-page/hpc/data-structures/binary-search/>Binary Search</a></li><li><a href=/hugo-page/hpc/data-structures/s-tree/>Static B-Trees</a></li><li><a href=/hugo-page/hpc/data-structures/b-tree/>Search Trees</a></li><li><a href=/hugo-page/hpc/data-structures/segment-trees/>Segment Trees</a></li></ol></ul></nav><div id=wrapper><menu id=menu><div class=left><a><img src=/icons/bars-solid.svg onclick=toggleSidebar() title='open table of contents'>
</a><a><img src=/icons/adjust-solid.svg style=position:relative;top:-1px onclick='switchTheme(localStorage.getItem("theme")=="dark"?"light":"dark")' title='dark theme'>
</a><a><img src=/icons/search-solid.svg onclick=toggleSearch() title=search></a></div><div class=title>Prefix Sum with SIMD</div><div class=right><a onclick=window.print()><img src=/icons/print-solid.svg title=print>
</a><a href=https://prose.io/#algorithmica-org/algorithmica/edit/master//hpc%2falgorithms%2fprefix.md><img src=/icons/edit-solid.svg title=edit style=width:18px;position:relative;right:-2px;top:-1px>
</a><a href=https://github.com/algorithmica-org/algorithmica/blob/master//hpc/algorithms/prefix.md class=github-main><img src=/icons/github-brands.svg title='view on github'></a></div></menu><main><div id=search><input id=search-bar type=search placeholder='Search this book…' oninput=search()><div id=search-count></div><div id=search-results></div></div><header><h1>Prefix Sum with SIMD</h1><div class=info></div></header><article>The <em>prefix sum</em>, also known as <em>cumulative sum</em>, <em>inclusive scan</em>, or simply <em>scan</em>, is a sequence of numbers $b_i$ generated from another sequence $a_i$ using the following rule:
$$
\begin{aligned}
b_0 &= a_0
\\ b_1 &= a_0 + a_1
\\ b_2 &= a_0 + a_1 + a_2
\\ &\ldots
\end{aligned}
$$<p>In other words, the $k$-th element of the output sequence is the sum of the first $k$ elements of the input sequence.</p><p>Prefix sum is a very important primitive in many algorithms, especially in the context of parallel algorithms, where its computation scales almost perfectly with the number of processors. Unfortunately, it is much harder to speed up with SIMD parallelism on a single CPU core, but we will try it nonetheless — and derive an algorithm that is ~2.5x faster than the baseline scalar implementation.</p><span class=anchor id=baseline></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/algorithms/prefix/#baseline>#</a>Baseline</h3><p>For our baseline, we could just invoke <code>std::partial_sum</code> from the STL, but for clarity, we will implement it manually. We create an array of integers and then sequentially add the previous element to the current one:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>void</span> <span class=nf>prefix</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+=</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>It seems like we need two reads, an add, and a write on each iteration, but of course, the compiler optimizes the extra read away and uses a register as the accumulator:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-nasm data-lang=nasm><span class=line><span class=cl><span class=nl>loop:</span>
</span></span><span class=line><span class=cl>    <span class=nf>add</span>     <span class=nb>edx</span><span class=p>,</span> <span class=kt>DWORD</span> <span class=nv>PTR</span> <span class=p>[</span><span class=nb>rax</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=nf>mov</span>     <span class=kt>DWORD</span> <span class=nv>PTR</span> <span class=p>[</span><span class=nb>rax</span><span class=o>-</span><span class=mi>4</span><span class=p>],</span> <span class=nb>edx</span>
</span></span><span class=line><span class=cl>    <span class=nf>add</span>     <span class=nb>rax</span><span class=p>,</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl>    <span class=nf>cmp</span>     <span class=nb>rax</span><span class=p>,</span> <span class=nb>rcx</span>
</span></span><span class=line><span class=cl>    <span class=nf>jne</span>     <span class=nv>loop</span>
</span></span></code></pre></div><p>After <a href=/hpc/architecture/loops>unrolling</a> the loop, just two instructions effectively remain: the fused read-add and the write-back of the result. Theoretically, these should work at 2 GFLOPS (1 element per CPU cycle, by the virtue of <a href=/hpc/pipelining>superscalar processing</a>), but since the memory system has to constantly <a href=/hpc/cpu-cache/bandwidth#directional-access>switch</a> between reading and writing, the actual performance is between 1.2 and 1.6 GFLOPS, depending on the array size.</p><span class=anchor id=vectorization></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/algorithms/prefix/#vectorization>#</a>Vectorization</h3><p>One way to implement a parallel prefix sum algorithm is to split the array into small blocks, independently calculate <em>local</em> prefix sums on them, and then do a second pass where we adjust the computed values in each block by adding the sum of all previous elements to them.</p><p><figure><img src=../img/prefix-outline.png><figcaption></figcaption></figure></p><p>This allows processing each block in parallel — both during the computation of the local prefix sums and the accumulation phase — so you usually split the array into as many blocks as you have processors. But since we are only allowed to use one CPU core, and <a href=/hpc/simd/moving#non-contiguous-load>non-sequential memory access</a> in SIMD doesn&rsquo;t work well, we are not going to do that. Instead, we will use a fixed block size equal to the size of a SIMD lane and calculate prefix sums within a register.</p><p>Now, to compute these prefix sums locally, we are going to use another parallel prefix sum method that is generally inefficient (the total work is $O(n \log n)$ instead of linear) but is good enough for the case when the data is already in a SIMD register. The idea is to perform $\log n$ iterations where on $k$-th iteration, we add $a_{i - 2^k}$ to $a_i$ for all applicable $i$:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>l</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>l</span> <span class=o>&lt;</span> <span class=n>logn</span><span class=p>;</span> <span class=n>l</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1>// (atomically and in parallel):
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=p>(</span><span class=mi>1</span> <span class=o>&lt;&lt;</span> <span class=n>l</span><span class=p>);</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+=</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span> <span class=o>-</span> <span class=p>(</span><span class=mi>1</span> <span class=o>&lt;&lt;</span> <span class=n>l</span><span class=p>)];</span>
</span></span></code></pre></div><p>We can prove that this algorithm works by induction: if on $k$-th iteration every element $a_i$ is equal to the sum of the $(i - 2^k, i]$ segment of the original array, then after adding $a_{i - 2^k}$ to it, it will be equal to the sum of $(i - 2^{k+1}, i]$. After $O(\log n)$ iterations, the array will turn into its prefix sum.</p><p>To implement it in SIMD, we could use <a href=/hpc/simd/shuffling>permutations</a> to place $i$-th element against $(i-2^k)$-th, but they are too slow. Instead, we will use the <code>sll</code> (&ldquo;shift lanes left&rdquo;) instruction that does exactly that and also replaces the unmatched elements with zeros:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>typedef</span> <span class=kr>__m128i</span> <span class=n>v4i</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>v4i</span> <span class=nf>prefix</span><span class=p>(</span><span class=n>v4i</span> <span class=n>x</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>// x = 1, 2, 3, 4
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>x</span> <span class=o>=</span> <span class=n>_mm_add_epi32</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>_mm_slli_si128</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=mi>4</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=c1>// x = 1, 2, 3, 4
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=c1>//   + 0, 1, 2, 3
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=c1>//   = 1, 3, 5, 7
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>x</span> <span class=o>=</span> <span class=n>_mm_add_epi32</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>_mm_slli_si128</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=mi>8</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=c1>// x = 1, 3, 5, 7
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=c1>//   + 0, 0, 1, 3
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=c1>//   = 1, 3, 6, 10
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>return</span> <span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Unfortunately, the 256-bit version of this instruction performs this byte shift independently within two 128-bit lanes, which is typical to AVX:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>typedef</span> <span class=n>__m256i</span> <span class=n>v8i</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>v8i</span> <span class=nf>prefix</span><span class=p>(</span><span class=n>v8i</span> <span class=n>x</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>// x = 1, 2, 3, 4, 5, 6, 7, 8
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>x</span> <span class=o>=</span> <span class=n>_mm256_add_epi32</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>_mm256_slli_si256</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=mi>4</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>_mm256_add_epi32</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>_mm256_slli_si256</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=mi>8</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>_mm256_add_epi32</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>_mm256_slli_si256</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=mi>16</span><span class=p>));</span> <span class=c1>// &lt;- this does nothing
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=c1>// x = 1, 3, 6, 10, 5, 11, 18, 26
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>return</span> <span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>We still can use it to compute 4-element prefix sums twice as fast, but we&rsquo;ll have to switch to 128-bit SSE when accumulating. Let&rsquo;s write a handy function that computes a local prefix sum end-to-end:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>void</span> <span class=nf>prefix</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>p</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>v8i</span> <span class=n>x</span> <span class=o>=</span> <span class=n>_mm256_load_si256</span><span class=p>((</span><span class=n>v8i</span><span class=o>*</span><span class=p>)</span> <span class=n>p</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>_mm256_add_epi32</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>_mm256_slli_si256</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=mi>4</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>_mm256_add_epi32</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>_mm256_slli_si256</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=mi>8</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=n>_mm256_store_si256</span><span class=p>((</span><span class=n>v8i</span><span class=o>*</span><span class=p>)</span> <span class=n>p</span><span class=p>,</span> <span class=n>x</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Now, for the accumulate phase, we will create another handy function that similarly takes the pointer to a 4-element block and also the 4-element vector of the previous prefix sum. The job of this function is to add this prefix sum vector to the block and update it so that it can be passed on to the next block (by broadcasting the last element of the block before the addition):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>v4i</span> <span class=nf>accumulate</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>p</span><span class=p>,</span> <span class=n>v4i</span> <span class=n>s</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>v4i</span> <span class=n>d</span> <span class=o>=</span> <span class=p>(</span><span class=n>v4i</span><span class=p>)</span> <span class=n>_mm_broadcast_ss</span><span class=p>((</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span> <span class=o>&amp;</span><span class=n>p</span><span class=p>[</span><span class=mi>3</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>    <span class=n>v4i</span> <span class=n>x</span> <span class=o>=</span> <span class=n>_mm_load_si128</span><span class=p>((</span><span class=n>v4i</span><span class=o>*</span><span class=p>)</span> <span class=n>p</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>_mm_add_epi32</span><span class=p>(</span><span class=n>s</span><span class=p>,</span> <span class=n>x</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>_mm_store_si128</span><span class=p>((</span><span class=n>v4i</span><span class=o>*</span><span class=p>)</span> <span class=n>p</span><span class=p>,</span> <span class=n>x</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>_mm_add_epi32</span><span class=p>(</span><span class=n>s</span><span class=p>,</span> <span class=n>d</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>With <code>prefix</code> and <code>accumulate</code> implemented, the only thing left is to glue together our two-pass algorithm:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>void</span> <span class=nf>prefix</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span> <span class=o>+=</span> <span class=mi>8</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>prefix</span><span class=p>(</span><span class=o>&amp;</span><span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>v4i</span> <span class=n>s</span> <span class=o>=</span> <span class=n>_mm_setzero_si128</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>4</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span> <span class=o>+=</span> <span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>=</span> <span class=n>accumulate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>s</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>The algorithm already performs slightly more than twice as fast as the scalar implementation but becomes slower for large arrays that fall out of the L3 cache — roughly at half the <a href=/hpc/cpu-cache/bandwidth>two-way RAM bandwidth</a> as we are reading the entire array twice.</p><p><figure><img src=../img/prefix-simd.svg><figcaption></figcaption></figure></p><p>Another interesting data point: if we only execute the <code>prefix</code> phase, the performance would be ~8.1 GFLOPS. The <code>accumulate</code> phase is slightly slower at ~5.8 GFLOPS. Sanity check: the total performance should be $\frac{1}{ \frac{1}{5.8} + \frac{1}{8.1} } \approx 3.4$.</p><span class=anchor id=blocking></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/algorithms/prefix/#blocking>#</a>Blocking</h3><p>So, we have a memory bandwidth problem for large arrays. We can avoid re-fetching the entire array from RAM if we split it into blocks that fit in the cache and process them separately. All we need to pass to the next block is the sum of the previous ones, so we can design a <code>local_prefix</code> function with an interface similar to <code>accumulate</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>B</span> <span class=o>=</span> <span class=mi>4096</span><span class=p>;</span> <span class=c1>// &lt;- ideally should be slightly less or equal to the L1 cache
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=n>v4i</span> <span class=nf>local_prefix</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=n>v4i</span> <span class=n>s</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>B</span><span class=p>;</span> <span class=n>i</span> <span class=o>+=</span> <span class=mi>8</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>prefix</span><span class=p>(</span><span class=o>&amp;</span><span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>B</span><span class=p>;</span> <span class=n>i</span> <span class=o>+=</span> <span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>=</span> <span class=n>accumulate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>s</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>s</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>prefix</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>v4i</span> <span class=n>s</span> <span class=o>=</span> <span class=n>_mm_setzero_si128</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span> <span class=o>+=</span> <span class=n>B</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>=</span> <span class=n>local_prefix</span><span class=p>(</span><span class=n>a</span> <span class=o>+</span> <span class=n>i</span><span class=p>,</span> <span class=n>s</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>(We have to make sure that $N$ is a multiple of $B$, but we are going to ignore such implementation details for now.)</p><p>The blocked version performs considerably better, and not just for when the array is in the RAM:</p><p><figure><img src=../img/prefix-blocked.svg><figcaption></figcaption></figure></p><p>The speedup in the RAM case compared to the non-blocked implementation is only ~1.5 and not 2. This is because the memory controller is sitting idle while we iterate over the cached block for the second time instead of fetching the next one — the <a href=/hpc/cpu-cache/prefetching>hardware prefetcher</a> isn&rsquo;t advanced enough to detect this pattern.</p><span class=anchor id=continuous-loads></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/algorithms/prefix/#continuous-loads>#</a>Continuous Loads</h3><p>There are several ways to solve this under-utilization problem. The obvious one is to use <a href=/hpc/cpu-cache/prefetching>software prefetching</a> to explicitly request the next block while we are still processing the current one.</p><p>It is better to add prefetching to the <code>accumulate</code> phase because it is slower and less memory-intensive than <code>prefix</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>v4i</span> <span class=nf>accumulate</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>p</span><span class=p>,</span> <span class=n>v4i</span> <span class=n>s</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>__builtin_prefetch</span><span class=p>(</span><span class=n>p</span> <span class=o>+</span> <span class=n>B</span><span class=p>);</span> <span class=c1>// &lt;-- prefetch the next block
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=c1>// ...
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>return</span> <span class=n>s</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>The performance slightly decreases for in-cache arrays, but approaches closer to 2 GFLOPS for the in-RAM ones:</p><p><figure><img src=../img/prefix-prefetch.svg><figcaption></figcaption></figure></p><p>Another approach is to do <em>interleaving</em> of the two phases. Instead of separating and alternating between them in large blocks, we can execute the two phases concurrently, with the <code>accumulate</code> phase lagging behind by a fixed number of iterations — similar to the <a href=/hpc/pipelining>CPU pipeline</a>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>B</span> <span class=o>=</span> <span class=mi>64</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=c1>//        ^ small sizes cause pipeline stalls
</span></span></span><span class=line><span class=cl><span class=c1>//          large sizes cause cache system inefficiencies
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>prefix</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>v4i</span> <span class=n>s</span> <span class=o>=</span> <span class=n>_mm_setzero_si128</span><span class=p>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>B</span><span class=p>;</span> <span class=n>i</span> <span class=o>+=</span> <span class=mi>8</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>prefix</span><span class=p>(</span><span class=o>&amp;</span><span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>B</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span> <span class=o>+=</span> <span class=mi>8</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>prefix</span><span class=p>(</span><span class=o>&amp;</span><span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>=</span> <span class=n>accumulate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>a</span><span class=p>[</span><span class=n>i</span> <span class=o>-</span> <span class=n>B</span><span class=p>],</span> <span class=n>s</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>=</span> <span class=n>accumulate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>a</span><span class=p>[</span><span class=n>i</span> <span class=o>-</span> <span class=n>B</span> <span class=o>+</span> <span class=mi>4</span><span class=p>],</span> <span class=n>s</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>n</span> <span class=o>-</span> <span class=n>B</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span> <span class=o>+=</span> <span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>=</span> <span class=n>accumulate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>s</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>This has more benefits: the loop progresses at a constant speed, reducing the pressure on the memory system, and the scheduler sees the instructions of both subroutines, allowing it to be more efficient at assigning instruction to execution ports — sort of like hyper-threading, but in code.</p><p>For these reasons, the performance improves even on small arrays:</p><p><figure><img src=../img/prefix-interleaved.svg><figcaption></figcaption></figure></p><p>And finally, it doesn&rsquo;t seem that we are bottlenecked by the <a href=/hpc/pipelining/tables/>memory read port</a> or the <a href=/hpc/architecture/layout/#cpu-front-end>decode width</a>, so we can add prefetching for free, which improves the performance even more:</p><p><figure><img src=../img/prefix-interleaved-prefetch.svg><figcaption></figcaption></figure></p><p>The total speedup we were able to achieve is between $\frac{4.2}{1.5} \approx 2.8$ for small arrays and $\frac{2.1}{1.2} \approx 1.75$ for large arrays.</p><p>The speedup may be higher for lower-precision data compared to the scalar code, as it is pretty much limited to executing one iteration per cycle regardless of the operand size, but it is still sort of &ldquo;meh&rdquo; when compared to some <a href=../argmin>other SIMD-based algorithms</a>. This is largely because there isn&rsquo;t a full-register byte shift in AVX that would allow the <code>accumulate</code> stage to proceed twice as fast, let alone a dedicated prefix sum instruction.</p><span class=anchor id=other-relevant-work></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/algorithms/prefix/#other-relevant-work>#</a>Other Relevant Work</h3><p>You can read <a href=http://www.adms-conf.org/2020-camera-ready/ADMS20_05.pdf>this paper from Columbia</a> that focuses on the multi-core setting and AVX-512 (which <a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#ig_expand=3037,4870,6715,4845,3853,90,7307,5993,2692,6946,6949,5456,6938,5456,1021,3007,514,518,7253,7183,3892,5135,5260,3915,4027,3873,7401,4376,4229,151,2324,2310,2324,591,4075,6130,4875,6385,5259,6385,6250,1395,7253,6452,7492,4669,4669,7253,1039,1029,4669,4707,7253,7242,848,879,848,7251,4275,879,874,849,833,6046,7250,4870,4872,4875,849,849,5144,4875,4787,4787,4787,3016,3018,5227,7359,7335,7392,4787,5259,5230,5230,5223,6438,488,483,6165,6570,6554,289,6792,6554,5230,6385,5260,5259,289,288,3037,3009,590,604,633,5230,5259,6554,6554,5259,6547,6554,3841,5214,5229,5260,5259,7335,5259,519,1029,515,3009,3009,3013,3011,515,6527,652,6527,6554,288&amp;text=_mm512_alignr_epi32&amp;techs=AVX_512">sort of</a> has a fast 512-bit register byte shift) and <a href=https://stackoverflow.com/questions/10587598/simd-prefix-sum-on-intel-cpu>this StackOverflow question</a> for a more general discussion.</p><p>Most of what I&rsquo;ve described in this article was already known. To the best of my knowledge, my contribution here is the interleaving technique, which is responsible for a modest ~20% performance increase. There probably are ways to improve it further, but not by a lot.</p><p>There is also this professor at CMU, <a href=https://www.cs.cmu.edu/~blelloch/>Guy Blelloch</a>, who <a href=https://www.cs.cmu.edu/~blelloch/papers/sc90.pdf>advocated</a> for a dedicated prefix sum hardware back in the 90s when <a href=https://en.wikipedia.org/wiki/Vector_processor>vector processors</a> were still a thing. Prefix sums are very important for parallel applications, and the hardware is becoming increasingly more parallel, so maybe, in the future, the CPU manufacturers will revitalize this idea and make prefix sum calculations slightly easier.</p></article><div class=nextprev><div class=left><a href=http://jyang772.github.io/hugo-page/hpc/algorithms/argmin/ id=prev-article>← Argmin with SIMD</a></div><div class=right><a href=http://jyang772.github.io/hugo-page/hpc/algorithms/matmul/ id=next-article>Matrix Multiplication →</a></div></div></main><footer>Copyright 2021–2022 Sergey Slotin<br></footer></div></body></html>