<!doctype html><html lang=en-us><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-WBN59M8Y5S"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WBN59M8Y5S")</script><script type=text/javascript>(function(e,t,n,s,o,i,a){e[o]=e[o]||function(){(e[o].a=e[o].a||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym"),ym(53961409,"init",{clickmap:!0,trackLinks:!0,accurateTrackBounce:!0,webvisor:!0})</script><noscript><div><img src=https://mc.yandex.ru/watch/53961409 style=position:absolute;left:-9999px alt></div></noscript><meta charset=utf-8><link rel=stylesheet href=/hugo-page/style.min.a3a4a7a8e8602aaa85b7cb3d655edde028ac80d73f2a97389e2cbcf995dd672d.css integrity="sha256-o6SnqOhgKqqFt8s9ZV7d4CisgNc/Kpc4niy8+ZXdZy0="><link rel=stylesheet href=/syntax.css id=syntax-theme><link rel=stylesheet type=text/css href=https://tikzjax.com/v1/fonts.css><script src=https://tikzjax.com/v1/tikzjax.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js></script><script src=/scripts/lunr.stemmer.support.min.js></script><script src=/scripts/lunr.ru.min.js></script><script src=/scripts/lunr.multi.min.js></script><link rel=stylesheet id=theme><script>function toggleSidebar(){console.log("Toggling sidebar visibility");var e=document.getElementById("sidebar"),t=document.getElementById("wrapper");(e.classList.contains("sidebar-toggled")||window.getComputedStyle(e).display=="block")&&(e.classList.toggle("sidebar-hidden"),t.classList.toggle("sidebar-hidden")),e.classList.add("sidebar-toggled"),t.classList.add("sidebar-toggled")}function switchTheme(e){console.log("Changing theme:",e),document.getElementById("theme").href=e=="dark"?"/hugo-page/dark.min.b3ae1169831434b11b48de5b3e3210547eea6b7884c295ab0030cb973ea0dc49.css":"",document.getElementById("syntax-theme").href=e=="dark"?"/syntax-dark.css":"/syntax.css",localStorage.setItem("theme",e)}async function toggleSearch(){console.log("Toggling search");var e=document.getElementById("search");if(window.getComputedStyle(e).display=="none"?(e.style.display="block",window.scrollTo({top:0}),document.getElementById("search-bar").focus()):e.style.display="none",!index){console.log("Fetching index");const e=await fetch("/hugo-page/searchindex.json"),t=await e.json();index=lunr(function(){this.use(lunr.multiLanguage("en","ru")),this.field("title",{boost:5}),this.field("content",{boost:1}),t.forEach(function(e){this.add(e),articles.push(e)},this)}),console.log("Ready to search")}}var articles=[],index=void 0;function search(){var n,e=document.getElementById("search-bar").value,s=document.getElementById("search-results"),o=document.getElementById("search-count");if(e==""){s.innerHTML="",o.innerHTML="";return}n=index.search(e),o.innerHTML="Found <b>"+n.length+"</b> pages";let t="";for(const a in n){const i=articles[n[a].ref];t+='<li><a href="'+i.path+'">'+i.title+"</a> <p>";const s=i.content,o=80;if(s.includes(e)){const n=s.indexOf(e);n>o&&(t+="…"),t+=s.substring(n-o,n)+"<b>"+e+"</b>"+s.substring(n+e.length,n+e.length+o)}else t+=s.substring(0,o*2);t+="…</p></li>"}s.innerHTML=t}localStorage.getItem("theme")=="dark"&&switchTheme("dark"),window.addEventListener("load",function(){var e=document.getElementById("active-element");e&&e.scrollIntoView({block:"center"})}),window.addEventListener("scroll",function(){var e=document.getElementById("menu");window.scrollY<120?e.classList.remove("scrolled"):e.classList.add("scrolled")}),window.addEventListener("keydown",function(e){if(e.altKey)return;if(document.activeElement.tagName=="INPUT")return;e.key=="ArrowLeft"?document.getElementById("prev-article").click():e.key=="ArrowRight"&&document.getElementById("next-article").click()})</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})'></script><title>Matrix Multiplication - Algorithmica</title></head><body><nav id=sidebar><div class=title><a href=/>Algorithmica</a>
<span class=slash>/</span>
<a href=/hugo-page/hpc/ class=divisionAbbr>HPC</a></div><ul><li class=part>Performance Engineering</li><li><a href=/hugo-page/hpc/complexity/>Complexity Models</a></li><ol><li><a href=/hugo-page/hpc/complexity/hardware/>Modern Hardware</a></li><li><a href=/hugo-page/hpc/complexity/languages/>Programming Languages</a></li></ol><li><a href=/hugo-page/hpc/architecture/>Computer Architecture</a></li><ol><li><a href=/hugo-page/hpc/architecture/isa/>Instruction Set Architectures</a></li><li><a href=/hugo-page/hpc/architecture/assembly/>Assembly Language</a></li><li><a href=/hugo-page/hpc/architecture/loops/>Loops and Conditionals</a></li><li><a href=/hugo-page/hpc/architecture/functions/>Functions and Recursion</a></li><li><a href=/hugo-page/hpc/architecture/indirect/>Indirect Branching</a></li><li><a href=/hugo-page/hpc/architecture/layout/>Machine Code Layout</a></li></ol><li><a href=/hugo-page/hpc/pipelining/>Instruction-Level Parallelism</a></li><ol><li><a href=/hugo-page/hpc/pipelining/hazards/>Pipeline Hazards</a></li><li><a href=/hugo-page/hpc/pipelining/branching/>The Cost of Branching</a></li><li><a href=/hugo-page/hpc/pipelining/branchless/>Branchless Programming</a></li><li><a href=/hugo-page/hpc/pipelining/tables/>Instruction Tables</a></li><li><a href=/hugo-page/hpc/pipelining/throughput/>Throughput Computing</a></li></ol><li><a href=/hugo-page/hpc/compilation/>Compilation</a></li><ol><li><a href=/hugo-page/hpc/compilation/stages/>Stages of Compilation</a></li><li><a href=/hugo-page/hpc/compilation/flags/>Flags and Targets</a></li><li><a href=/hugo-page/hpc/compilation/situational/>Situational Optimizations</a></li><li><a href=/hugo-page/hpc/compilation/contracts/>Contract Programming</a></li><li><a href=/hugo-page/hpc/compilation/precalc/>Precomputation</a></li></ol><li><a href=/hugo-page/hpc/profiling/>Profiling</a></li><ol><li><a href=/hugo-page/hpc/profiling/instrumentation/>Instrumentation</a></li><li><a href=/hugo-page/hpc/profiling/events/>Statistical Profiling</a></li><li><a href=/hugo-page/hpc/profiling/simulation/>Program Simulation</a></li><li><a href=/hugo-page/hpc/profiling/mca/>Machine Code Analyzers</a></li><li><a href=/hugo-page/hpc/profiling/benchmarking/>Benchmarking</a></li><li><a href=/hugo-page/hpc/profiling/noise/>Getting Accurate Results</a></li></ol><li><a href=/hugo-page/hpc/arithmetic/>Arithmetic</a></li><ol><li><a href=/hugo-page/hpc/arithmetic/float/>Floating-Point Numbers</a></li><li><a href=/hugo-page/hpc/arithmetic/ieee-754/>IEEE 754 Floats</a></li><li><a href=/hugo-page/hpc/arithmetic/errors/>Rounding Errors</a></li><li><a href=/hugo-page/hpc/arithmetic/newton/>Newton's Method</a></li><li><a href=/hugo-page/hpc/arithmetic/rsqrt/>Fast Inverse Square Root</a></li><li><a href=/hugo-page/hpc/arithmetic/integer/>Integer Numbers</a></li><li><a href=/hugo-page/hpc/arithmetic/division/>Integer Division</a></li></ol><li><a href=/hugo-page/hpc/number-theory/>Number Theory</a></li><ol><li><a href=/hugo-page/hpc/number-theory/modular/>Modular Arithmetic</a></li><li><a href=/hugo-page/hpc/number-theory/exponentiation/>Binary Exponentiation</a></li><li><a href=/hugo-page/hpc/number-theory/euclid-extended/>Extended Euclidean Algorithm</a></li><li><a href=/hugo-page/hpc/number-theory/montgomery/>Montgomery Multiplication</a></li></ol><li><a href=/hugo-page/hpc/external-memory/>External Memory</a></li><ol><li><a href=/hugo-page/hpc/external-memory/hierarchy/>Memory Hierarchy</a></li><li><a href=/hugo-page/hpc/external-memory/virtual/>Virtual Memory</a></li><li><a href=/hugo-page/hpc/external-memory/model/>External Memory Model</a></li><li><a href=/hugo-page/hpc/external-memory/sorting/>External Sorting</a></li><li><a href=/hugo-page/hpc/external-memory/list-ranking/>List Ranking</a></li><li><a href=/hugo-page/hpc/external-memory/policies/>Eviction Policies</a></li><li><a href=/hugo-page/hpc/external-memory/oblivious/>Cache-Oblivious Algorithms</a></li><li><a href=/hugo-page/hpc/external-memory/locality/>Spatial and Temporal Locality</a></li></ol><li><a href=/hugo-page/hpc/cpu-cache/>RAM & CPU Caches</a></li><ol><li><a href=/hugo-page/hpc/cpu-cache/bandwidth/>Memory Bandwidth</a></li><li><a href=/hugo-page/hpc/cpu-cache/latency/>Memory Latency</a></li><li><a href=/hugo-page/hpc/cpu-cache/cache-lines/>Cache Lines</a></li><li><a href=/hugo-page/hpc/cpu-cache/sharing/>Memory Sharing</a></li><li><a href=/hugo-page/hpc/cpu-cache/mlp/>Memory-Level Parallelism</a></li><li><a href=/hugo-page/hpc/cpu-cache/prefetching/>Prefetching</a></li><li><a href=/hugo-page/hpc/cpu-cache/alignment/>Alignment and Packing</a></li><li><a href=/hugo-page/hpc/cpu-cache/pointers/>Pointer Alternatives</a></li><li><a href=/hugo-page/hpc/cpu-cache/associativity/>Cache Associativity</a></li><li><a href=/hugo-page/hpc/cpu-cache/paging/>Memory Paging</a></li><li><a href=/hugo-page/hpc/cpu-cache/aos-soa/>AoS and SoA</a></li></ol><li><a href=/hugo-page/hpc/simd/>SIMD Parallelism</a></li><ol><li><a href=/hugo-page/hpc/simd/intrinsics/>Intrinsics and Vector Types</a></li><li><a href=/hugo-page/hpc/simd/moving/>Moving Data</a></li><li><a href=/hugo-page/hpc/simd/reduction/>Reductions</a></li><li><a href=/hugo-page/hpc/simd/masking/>Masking and Blending</a></li><li><a href=/hugo-page/hpc/simd/shuffling/>In-Register Shuffles</a></li><li><a href=/hugo-page/hpc/simd/auto-vectorization/>Auto-Vectorization and SPMD</a></li></ol><li><a href=/hugo-page/hpc/algorithms/>Algorithms Case Studies</a></li><ol><li><a href=/hugo-page/hpc/algorithms/gcd/>Binary GCD</a></li><li><a href=/hugo-page/hpc/algorithms/factorization/>Integer Factorization</a></li><li><a href=/hugo-page/hpc/algorithms/argmin/>Argmin with SIMD</a></li><li><a href=/hugo-page/hpc/algorithms/prefix/>Prefix Sum with SIMD</a></li><li><a href=/hugo-page/hpc/algorithms/matmul/ id=active-element>Matrix Multiplication</a></li></ol><li><a href=/hugo-page/hpc/data-structures/>Data Structures Case Studies</a></li><ol><li><a href=/hugo-page/hpc/data-structures/binary-search/>Binary Search</a></li><li><a href=/hugo-page/hpc/data-structures/s-tree/>Static B-Trees</a></li><li><a href=/hugo-page/hpc/data-structures/b-tree/>Search Trees</a></li><li><a href=/hugo-page/hpc/data-structures/segment-trees/>Segment Trees</a></li></ol></ul></nav><div id=wrapper><menu id=menu><div class=left><a><img src=/icons/bars-solid.svg onclick=toggleSidebar() title='open table of contents'>
</a><a><img src=/icons/adjust-solid.svg style=position:relative;top:-1px onclick='switchTheme(localStorage.getItem("theme")=="dark"?"light":"dark")' title='dark theme'>
</a><a><img src=/icons/search-solid.svg onclick=toggleSearch() title=search></a></div><div class=title>Matrix Multiplication</div><div class=right><a onclick=window.print()><img src=/icons/print-solid.svg title=print>
</a><a href=https://prose.io/#algorithmica-org/algorithmica/edit/master//hpc%2falgorithms%2fmatmul.md><img src=/icons/edit-solid.svg title=edit style=width:18px;position:relative;right:-2px;top:-1px>
</a><a href=https://github.com/algorithmica-org/algorithmica/blob/master//hpc/algorithms/matmul.md class=github-main><img src=/icons/github-brands.svg title='view on github'></a></div></menu><main><div id=search><input id=search-bar type=search placeholder='Search this book…' oninput=search()><div id=search-count></div><div id=search-results></div></div><header><h1>Matrix Multiplication</h1><div class=info></div></header><article><p>In this case study, we will design and implement several algorithms for matrix multiplication.</p><p>We start with the naive &ldquo;for-for-for&rdquo; algorithm and incrementally improve it, eventually arriving at a version that is 50 times faster and matches the performance of BLAS libraries while being under 40 lines of C.</p><p>All implementations are compiled with GCC 13 and run on a <a href=https://en.wikichip.org/wiki/amd/microarchitectures/zen_2>Zen 2</a> CPU clocked at 2GHz.</p><span class=anchor id=baseline></span><h2><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/algorithms/matmul/#baseline>#</a>Baseline</h2><p>The result of multiplying an $l \times n$ matrix $A$ by an $n \times m$ matrix $B$ is defined as an $l \times m$ matrix $C$ such that:</p>$$
C_{ij} = \sum_{k=1}^{n} A_{ik} \cdot B_{kj}
$$<p>For simplicity, we will only consider <em>square</em> matrices, where $l = m = n$.</p><p>To implement matrix multiplication, we can simply transfer this definition into code, but instead of two-dimensional arrays (aka matrices), we will be using one-dimensional arrays to be explicit about pointer arithmetic:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>void</span> <span class=nf>matmul</span><span class=p>(</span><span class=k>const</span> <span class=kt>float</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=k>const</span> <span class=kt>float</span> <span class=o>*</span><span class=n>b</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>c</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>k</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>k</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>c</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>j</span><span class=p>]</span> <span class=o>+=</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>k</span><span class=p>]</span> <span class=o>*</span> <span class=n>b</span><span class=p>[</span><span class=n>k</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>j</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>For reasons that will become apparent later, we will only use matrix sizes that are multiples of $48$ for benchmarking, but the implementations remain correct for all others. We also use <a href=/hpc/arithmetic/ieee-754>32-bit floats</a> specifically, although all implementations can be easily <a href=#generalizations>generalized</a> to other data types and operations.</p><p>Compiled with <code>g++ -O3 -march=native -ffast-math -funroll-loops</code>, the naive approach multiplies two matrices of size $n = 1920 = 48 \times 40$ in ~16.7 seconds. To put it in perspective, this is approximately $\frac{1920^3}{16.7 \times 10^9} \approx 0.42$ useful operations per nanosecond (GFLOPS), or roughly 5 CPU cycles per multiplication, which doesn&rsquo;t look that good yet.</p><span class=anchor id=transposition></span><h2><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/algorithms/matmul/#transposition>#</a>Transposition</h2><p>In general, when optimizing an algorithm that processes large quantities of data — and $1920^2 \times 3 \times 4 \approx 42$ MB clearly is a large quantity as it can&rsquo;t fit into any of the <a href=/hpc/cpu-cache>CPU caches</a> — one should always start with memory before optimizing arithmetic, as it is much more likely to be the bottleneck.</p><p>The field $C_{ij}$ can be thought of as the dot product of row $i$ of matrix $A$ and column $j$ of matrix $B$. As we increment <code>k</code> in the inner loop above, we are reading the matrix <code>a</code> sequentially, but we are jumping over $n$ elements as we iterate over a column of <code>b</code>, which is <a href=/hpc/cpu-cache/aos-soa>not as fast</a> as sequential iteration.</p><p>One <a href=/hpc/external-memory/oblivious/#matrix-multiplication>well-known</a> optimization that tackles this problem is to store matrix $B$ in <em>column-major</em> order — or, alternatively, to <em>transpose</em> it before the matrix multiplication. This requires $O(n^2)$ additional operations but ensures sequential reads in the innermost loop:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>void</span> <span class=nf>matmul</span><span class=p>(</span><span class=k>const</span> <span class=kt>float</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=k>const</span> <span class=kt>float</span> <span class=o>*</span><span class=n>_b</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>c</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>b</span> <span class=o>=</span> <span class=k>new</span> <span class=kt>float</span><span class=p>[</span><span class=n>n</span> <span class=o>*</span> <span class=n>n</span><span class=p>];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>b</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>j</span><span class=p>]</span> <span class=o>=</span> <span class=n>_b</span><span class=p>[</span><span class=n>j</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>k</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>k</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>c</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>j</span><span class=p>]</span> <span class=o>+=</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>k</span><span class=p>]</span> <span class=o>*</span> <span class=n>b</span><span class=p>[</span><span class=n>j</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>k</span><span class=p>];</span> <span class=c1>// &lt;- note the indices
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span>
</span></span></code></pre></div><p>This code runs in ~12.4s, or about 30% faster.</p><p>As we will see in a bit, there are more important benefits to transposing it than just the sequential memory reads.</p><span class=anchor id=vectorization></span><h2><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/algorithms/matmul/#vectorization>#</a>Vectorization</h2><p>Now that all we do is just sequentially read the elements of <code>a</code> and <code>b</code>, multiply them, and add the result to an accumulator variable, we can use <a href=/hpc/simd/>SIMD</a> instructions to speed it all up. It is pretty straightforward to implement using <a href=/hpc/simd/intrinsics/#gcc-vector-extensions>GCC vector types</a> — we can <a href=/hpc/cpu-cache/alignment/>memory-align</a> matrix rows, pad them with zeros, and then compute the multiply-sum as we would normally compute any other <a href=/hpc/simd/reduction/>reduction</a>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=c1>// a vector of 256 / 32 = 8 floats
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>typedef</span> <span class=kt>float</span> <span class=n>vec</span> <span class=nf>__attribute__</span> <span class=p>((</span> <span class=n>vector_size</span><span class=p>(</span><span class=mi>32</span><span class=p>)</span> <span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// a helper function that allocates n vectors and initializes them with zeros
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>vec</span><span class=o>*</span> <span class=nf>alloc</span><span class=p>(</span><span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>vec</span><span class=o>*</span> <span class=n>ptr</span> <span class=o>=</span> <span class=p>(</span><span class=n>vec</span><span class=o>*</span><span class=p>)</span> <span class=n>std</span><span class=o>::</span><span class=n>aligned_alloc</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=mi>32</span> <span class=o>*</span> <span class=n>n</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>memset</span><span class=p>(</span><span class=n>ptr</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>32</span> <span class=o>*</span> <span class=n>n</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>ptr</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>matmul</span><span class=p>(</span><span class=k>const</span> <span class=kt>float</span> <span class=o>*</span><span class=n>_a</span><span class=p>,</span> <span class=k>const</span> <span class=kt>float</span> <span class=o>*</span><span class=n>_b</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>c</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>nB</span> <span class=o>=</span> <span class=p>(</span><span class=n>n</span> <span class=o>+</span> <span class=mi>7</span><span class=p>)</span> <span class=o>/</span> <span class=mi>8</span><span class=p>;</span> <span class=c1>// number of 8-element vectors in a row (rounded up)
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl>    <span class=n>vec</span> <span class=o>*</span><span class=n>a</span> <span class=o>=</span> <span class=n>alloc</span><span class=p>(</span><span class=n>n</span> <span class=o>*</span> <span class=n>nB</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>vec</span> <span class=o>*</span><span class=n>b</span> <span class=o>=</span> <span class=n>alloc</span><span class=p>(</span><span class=n>n</span> <span class=o>*</span> <span class=n>nB</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// move both matrices to the aligned region
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>j</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=n>a</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>nB</span> <span class=o>+</span> <span class=n>j</span> <span class=o>/</span> <span class=mi>8</span><span class=p>][</span><span class=n>j</span> <span class=o>%</span> <span class=mi>8</span><span class=p>]</span> <span class=o>=</span> <span class=n>_a</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>j</span><span class=p>];</span>
</span></span><span class=line><span class=cl>            <span class=n>b</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>nB</span> <span class=o>+</span> <span class=n>j</span> <span class=o>/</span> <span class=mi>8</span><span class=p>][</span><span class=n>j</span> <span class=o>%</span> <span class=mi>8</span><span class=p>]</span> <span class=o>=</span> <span class=n>_b</span><span class=p>[</span><span class=n>j</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>i</span><span class=p>];</span> <span class=c1>// &lt;- b is still transposed
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>j</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=n>vec</span> <span class=n>s</span><span class=p>{};</span> <span class=c1>// initialize the accumulator with zeros
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl>            <span class=c1>// vertical summation
</span></span></span><span class=line><span class=cl><span class=c1></span>            <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>k</span> <span class=o>&lt;</span> <span class=n>nB</span><span class=p>;</span> <span class=n>k</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>s</span> <span class=o>+=</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>nB</span> <span class=o>+</span> <span class=n>k</span><span class=p>]</span> <span class=o>*</span> <span class=n>b</span><span class=p>[</span><span class=n>j</span> <span class=o>*</span> <span class=n>nB</span> <span class=o>+</span> <span class=n>k</span><span class=p>];</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1>// horizontal summation
</span></span></span><span class=line><span class=cl><span class=c1></span>            <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>k</span> <span class=o>&lt;</span> <span class=mi>8</span><span class=p>;</span> <span class=n>k</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>c</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>j</span><span class=p>]</span> <span class=o>+=</span> <span class=n>s</span><span class=p>[</span><span class=n>k</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>free</span><span class=p>(</span><span class=n>a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>free</span><span class=p>(</span><span class=n>b</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>The performance for $n = 1920$ is now around 2.3 GFLOPS — or another ~4 times higher compared to the transposed but not vectorized version.</p><p><figure><img src=../img/mm-vectorized-barplot.svg><figcaption></figcaption></figure></p><p>This optimization looks neither too complex nor specific to matrix multiplication. Why can&rsquo;t the compiler <a href=/hpc/simd/auto-vectorization/>auto-vectorizee</a> the inner loop by itself?</p><p>It actually can; the only thing preventing that is the possibility that <code>c</code> overlaps with either <code>a</code> or <code>b</code>. To rule it out, you can communicate to the compiler that you guarantee <code>c</code> is not <a href=/hpc/compilation/contracts/#memory-aliasing>aliased</a> with anything by adding the <code>__restrict__</code> keyword to it:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>void</span> <span class=nf>matmul</span><span class=p>(</span><span class=k>const</span> <span class=kt>float</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=k>const</span> <span class=kt>float</span> <span class=o>*</span><span class=n>_b</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span> <span class=n>__restrict__</span> <span class=n>c</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>// ...
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span>
</span></span></code></pre></div><p>Both manually and auto-vectorized implementations perform roughly the same.</p><span class=anchor id=memory-efficiency></span><h2><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/algorithms/matmul/#memory-efficiency>#</a>Memory efficiency</h2><p>What is interesting is that the implementation efficiency depends on the problem size.</p><p>At first, the performance (defined as the number of useful operations per second) increases as the overhead of the loop management and the horizontal reduction decreases. Then, at around $n=256$, it starts smoothly decreasing as the matrices stop fitting into the <a href=/hpc/cpu-cache/>cache</a> ($2 \times 256^2 \times 4 = 512$ KB is the size of the L2 cache), and the performance becomes bottlenecked by the <a href=/hpc/cpu-cache/bandwidth/>memory bandwidth</a>.</p><p><figure><img src=../img/mm-vectorized-plot.svg><figcaption></figcaption></figure></p><p>It is also interesting that the naive implementation is mostly on par with the non-vectorized transposed version — and even slightly better because it doesn&rsquo;t need to perform a transposition.</p><p>One might think that there would be some general performance gain from doing sequential reads since we are fetching fewer cache lines, but this is not the case: fetching the first column of <code>b</code> indeed takes more time, but the next 15 column reads will be in the same cache lines as the first one, so they will be cached anyway — unless the matrix is so large that it can&rsquo;t even fit <code>n * cache_line_size</code> bytes into the cache, which is not the case for any practical matrix sizes.</p><p>Instead, the performance deteriorates on only a few specific matrix sizes due to the effects of <a href=/hpc/cpu-cache/associativity/>cache associativity</a>: when $n$ is a multiple of a large power of two, we are fetching the addresses of <code>b</code> that all likely map to the same cache line, which reduces the effective cache size. This explains the 30% performance dip for $n = 1920 = 2^7 \times 3 \times 5$, and you can see an even more noticeable one for $1536 = 2^9 \times 3$: it is roughly 3 times slower than for $n=1535$.</p><p>So, counterintuitively, transposing the matrix doesn&rsquo;t help with caching — and in the naive scalar implementation, we are not really bottlenecked by the memory bandwidth anyway. But our vectorized implementation certainly is, so let&rsquo;s work on its I/O efficiency.</p><span class=anchor id=register-reuse></span><h2><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/algorithms/matmul/#register-reuse>#</a>Register reuse</h2><p>Using a Python-like notation to refer to submatrices, to compute the cell $C[x][y]$, we need to calculate the dot product of $A[x][:]$ and $B[:][y]$, which requires fetching $2n$ elements, even if we store $B$ in column-major order.</p><p>To compute $C[x:x+2][y:y+2]$, a $2 \times 2$ submatrix of $C$, we would need two rows from $A$ and two columns from $B$, namely $A[x:x+2][:]$ and $B[:][y:y+2]$, containing $4n$ elements in total, to update <em>four</em> elements instead of <em>one</em> — which is $\frac{2n / 1}{4n / 4} = 2$ times better in terms of I/O efficiency.</p><p>To avoid fetching data more than once, we need to iterate over these rows and columns in parallel and calculate all $2 \times 2$ possible combinations of products. Here is a proof of concept:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>void</span> <span class=nf>kernel_2x2</span><span class=p>(</span><span class=kt>int</span> <span class=n>x</span><span class=p>,</span> <span class=kt>int</span> <span class=n>y</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>c00</span> <span class=o>=</span> <span class=mi>0</span><span class=p>,</span> <span class=n>c01</span> <span class=o>=</span> <span class=mi>0</span><span class=p>,</span> <span class=n>c10</span> <span class=o>=</span> <span class=mi>0</span><span class=p>,</span> <span class=n>c11</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>k</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>k</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=c1>// read rows
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=kt>int</span> <span class=n>a0</span> <span class=o>=</span> <span class=n>a</span><span class=p>[</span><span class=n>x</span><span class=p>][</span><span class=n>k</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=kt>int</span> <span class=n>a1</span> <span class=o>=</span> <span class=n>a</span><span class=p>[</span><span class=n>x</span> <span class=o>+</span> <span class=mi>1</span><span class=p>][</span><span class=n>k</span><span class=p>];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1>// read columns
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=kt>int</span> <span class=n>b0</span> <span class=o>=</span> <span class=n>b</span><span class=p>[</span><span class=n>k</span><span class=p>][</span><span class=n>y</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=kt>int</span> <span class=n>b1</span> <span class=o>=</span> <span class=n>b</span><span class=p>[</span><span class=n>k</span><span class=p>][</span><span class=n>y</span> <span class=o>+</span> <span class=mi>1</span><span class=p>];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1>// update all combinations
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>c00</span> <span class=o>+=</span> <span class=n>a0</span> <span class=o>*</span> <span class=n>b0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>c01</span> <span class=o>+=</span> <span class=n>a0</span> <span class=o>*</span> <span class=n>b1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>c10</span> <span class=o>+=</span> <span class=n>a1</span> <span class=o>*</span> <span class=n>b0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>c11</span> <span class=o>+=</span> <span class=n>a1</span> <span class=o>*</span> <span class=n>b1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// write the results to C
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>c</span><span class=p>[</span><span class=n>x</span><span class=p>][</span><span class=n>y</span><span class=p>]</span>         <span class=o>=</span> <span class=n>c00</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>c</span><span class=p>[</span><span class=n>x</span><span class=p>][</span><span class=n>y</span> <span class=o>+</span> <span class=mi>1</span><span class=p>]</span>     <span class=o>=</span> <span class=n>c01</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>c</span><span class=p>[</span><span class=n>x</span> <span class=o>+</span> <span class=mi>1</span><span class=p>][</span><span class=n>y</span><span class=p>]</span>     <span class=o>=</span> <span class=n>c10</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>c</span><span class=p>[</span><span class=n>x</span> <span class=o>+</span> <span class=mi>1</span><span class=p>][</span><span class=n>y</span> <span class=o>+</span> <span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=n>c11</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>We can now simply call this kernel on all 2x2 submatrices of $C$, but we won&rsquo;t bother evaluating it: although this algorithm is better in terms of I/O operations, it would still not beat our SIMD-based implementation. Instead, we will extend this approach and develop a similar <em>vectorized</em> kernel right away.</p><span class=anchor id=designing-the-kernel></span><h2><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/algorithms/matmul/#designing-the-kernel>#</a>Designing the kernel</h2><p>Instead of designing a kernel that computes an $h \times w$ submatrix of $C$ from scratch, we will declare a function that <em>updates</em> it using columns from $l$ to $r$ of $A$ and rows from $l$ to $r$ of $B$. For now, this seems like an over-generalization, but this function interface will prove useful later.</p><p>To determine $h$ and $w$, we have several performance considerations:</p><ul><li>In general, to compute an $h \times w$ submatrix, we need to fetch $2 \cdot n \cdot (h + w)$ elements. To optimize the I/O efficiency, we want the $\frac{h \cdot w}{h + w}$ ratio to be high, which is achieved with large and square-ish submatrices.</li><li>We want to use the <a href=https://en.wikipedia.org/wiki/FMA_instruction_set>FMA</a> (&ldquo;fused multiply-add&rdquo;) instruction available on all modern x86 architectures. As you can guess from the name, it performs the <code>c += a * b</code> operation — which is the core of a dot product — on 8-element vectors in one go, which saves us from executing vector multiplication and addition separately.</li><li>To achieve better utilization of this instruction, we want to make use of <a href=/hpc/pipelining/>instruction-level parallelism</a>. On Zen 2, the <code>fma</code> instruction has a latency of 5 and a throughput of 2, meaning that we need to concurrently execute at least $5 \times 2 = 10$ of them to saturate its execution ports.</li><li>We want to avoid register spill (move data to and from registers more than necessary), and we only have $16$ logical vector registers that we can use as accumulators (minus those that we need to hold temporary values).</li></ul><p>For these reasons, we settle on a $6 \times 16$ kernel. This way, we process $96$ elements at once that are stored in $6 \times 2 = 12$ vector registers. To update them efficiently, we use the following procedure:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=c1>// update 6x16 submatrix C[x:x+6][y:y+16]
</span></span></span><span class=line><span class=cl><span class=c1>// using A[x:x+6][l:r] and B[l:r][y:y+16]
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>void</span> <span class=nf>kernel</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=n>vec</span> <span class=o>*</span><span class=n>b</span><span class=p>,</span> <span class=n>vec</span> <span class=o>*</span><span class=n>c</span><span class=p>,</span> <span class=kt>int</span> <span class=n>x</span><span class=p>,</span> <span class=kt>int</span> <span class=n>y</span><span class=p>,</span> <span class=kt>int</span> <span class=n>l</span><span class=p>,</span> <span class=kt>int</span> <span class=n>r</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>vec</span> <span class=n>t</span><span class=p>[</span><span class=mi>6</span><span class=p>][</span><span class=mi>2</span><span class=p>]{};</span> <span class=c1>// will be zero-filled and stored in ymm registers
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=n>l</span><span class=p>;</span> <span class=n>k</span> <span class=o>&lt;</span> <span class=n>r</span><span class=p>;</span> <span class=n>k</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=mi>6</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=c1>// broadcast a[x + i][k] into a register
</span></span></span><span class=line><span class=cl><span class=c1></span>            <span class=n>vec</span> <span class=n>alpha</span> <span class=o>=</span> <span class=n>vec</span><span class=p>{}</span> <span class=o>+</span> <span class=n>a</span><span class=p>[(</span><span class=n>x</span> <span class=o>+</span> <span class=n>i</span><span class=p>)</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>k</span><span class=p>];</span> <span class=c1>// converts to a broadcast
</span></span></span><span class=line><span class=cl><span class=c1></span>            <span class=c1>// multiply b[k][y:y+16] by it and update t[i][0] and t[i][1]
</span></span></span><span class=line><span class=cl><span class=c1></span>            <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=mi>2</span><span class=p>;</span> <span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>t</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>j</span><span class=p>]</span> <span class=o>+=</span> <span class=n>alpha</span> <span class=o>*</span> <span class=n>b</span><span class=p>[(</span><span class=n>k</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>y</span><span class=p>)</span> <span class=o>/</span> <span class=mi>8</span> <span class=o>+</span> <span class=n>j</span><span class=p>];</span> <span class=c1>// converts to an fma
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// write the results back to C
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=mi>6</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=mi>2</span><span class=p>;</span> <span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>c</span><span class=p>[((</span><span class=n>x</span> <span class=o>+</span> <span class=n>i</span><span class=p>)</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>y</span><span class=p>)</span> <span class=o>/</span> <span class=mi>8</span> <span class=o>+</span> <span class=n>j</span><span class=p>]</span> <span class=o>+=</span> <span class=n>t</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>j</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>We need <code>t</code> so that the compiler stores these elements in vector registers. We could just update their final destinations in <code>c</code>, but, unfortunately, the compiler re-writes them back to memory, causing a slowdown (wrapping everything in <code>__restrict__</code> keywords doesn&rsquo;t help).</p><p>After unrolling these loops and hoisting <code>b</code> out of the <code>i</code> loop (<code>b[(k * n + y) / 8 + j]</code> does not depend on <code>i</code> and can be loaded once and reused in all 6 iterations), the compiler generates something more similar to this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=n>l</span><span class=p>;</span> <span class=n>k</span> <span class=o>&lt;</span> <span class=n>r</span><span class=p>;</span> <span class=n>k</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>__m256</span> <span class=n>b0</span> <span class=o>=</span> <span class=n>_mm256_load_ps</span><span class=p>((</span><span class=n>__m256</span><span class=o>*</span><span class=p>)</span> <span class=o>&amp;</span><span class=n>b</span><span class=p>[</span><span class=n>k</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>y</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=n>__m256</span> <span class=n>b1</span> <span class=o>=</span> <span class=n>_mm256_load_ps</span><span class=p>((</span><span class=n>__m256</span><span class=o>*</span><span class=p>)</span> <span class=o>&amp;</span><span class=n>b</span><span class=p>[</span><span class=n>k</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>y</span> <span class=o>+</span> <span class=mi>8</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>__m256</span> <span class=n>a0</span> <span class=o>=</span> <span class=n>_mm256_broadcast_ps</span><span class=p>((</span><span class=kr>__m128</span><span class=o>*</span><span class=p>)</span> <span class=o>&amp;</span><span class=n>a</span><span class=p>[</span><span class=n>x</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>k</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>    <span class=n>t00</span> <span class=o>=</span> <span class=n>_mm256_fmadd_ps</span><span class=p>(</span><span class=n>a0</span><span class=p>,</span> <span class=n>b0</span><span class=p>,</span> <span class=n>t00</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>t01</span> <span class=o>=</span> <span class=n>_mm256_fmadd_ps</span><span class=p>(</span><span class=n>a0</span><span class=p>,</span> <span class=n>b1</span><span class=p>,</span> <span class=n>t01</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>__m256</span> <span class=n>a1</span> <span class=o>=</span> <span class=n>_mm256_broadcast_ps</span><span class=p>((</span><span class=kr>__m128</span><span class=o>*</span><span class=p>)</span> <span class=o>&amp;</span><span class=n>a</span><span class=p>[(</span><span class=n>x</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>k</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>    <span class=n>t10</span> <span class=o>=</span> <span class=n>_mm256_fmadd_ps</span><span class=p>(</span><span class=n>a1</span><span class=p>,</span> <span class=n>b0</span><span class=p>,</span> <span class=n>t10</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>t11</span> <span class=o>=</span> <span class=n>_mm256_fmadd_ps</span><span class=p>(</span><span class=n>a1</span><span class=p>,</span> <span class=n>b1</span><span class=p>,</span> <span class=n>t11</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// ...
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span>
</span></span></code></pre></div><p>We are using $12+3=15$ vector registers and a total of $6 \times 3 + 2 = 20$ instructions to perform $16 \times 6 = 96$ updates. Assuming that there are no other bottleneks, we should be hitting the throughput of <code>_mm256_fmadd_ps</code>.</p><p>Note that this kernel is architecture-specific. If we didn&rsquo;t have <code>fma</code>, or if its throughput/latency were different, or if the SIMD width was 128 or 512 bits, we would have made different design choices. Multi-platform BLAS implementations ship <a href=https://github.com/xianyi/OpenBLAS/tree/develop/kernel>many kernels</a>, each written in assembly by hand and optimized for a particular architecture.</p><p>The rest of the implementation is straightforward. Similar to the previous vectorized implementation, we just move the matrices to memory-aligned arrays and call the kernel instead of the innermost loop:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>void</span> <span class=nf>matmul</span><span class=p>(</span><span class=k>const</span> <span class=kt>float</span> <span class=o>*</span><span class=n>_a</span><span class=p>,</span> <span class=k>const</span> <span class=kt>float</span> <span class=o>*</span><span class=n>_b</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>_c</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>// to simplify the implementation, we pad the height and width
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=c1>// so that they are divisible by 6 and 16 respectively
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>int</span> <span class=n>nx</span> <span class=o>=</span> <span class=p>(</span><span class=n>n</span> <span class=o>+</span> <span class=mi>5</span><span class=p>)</span> <span class=o>/</span> <span class=mi>6</span> <span class=o>*</span> <span class=mi>6</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>ny</span> <span class=o>=</span> <span class=p>(</span><span class=n>n</span> <span class=o>+</span> <span class=mi>15</span><span class=p>)</span> <span class=o>/</span> <span class=mi>16</span> <span class=o>*</span> <span class=mi>16</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>a</span> <span class=o>=</span> <span class=n>alloc</span><span class=p>(</span><span class=n>nx</span> <span class=o>*</span> <span class=n>ny</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>b</span> <span class=o>=</span> <span class=n>alloc</span><span class=p>(</span><span class=n>nx</span> <span class=o>*</span> <span class=n>ny</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>c</span> <span class=o>=</span> <span class=n>alloc</span><span class=p>(</span><span class=n>nx</span> <span class=o>*</span> <span class=n>ny</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>memcpy</span><span class=p>(</span><span class=o>&amp;</span><span class=n>a</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>ny</span><span class=p>],</span> <span class=o>&amp;</span><span class=n>_a</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>n</span><span class=p>],</span> <span class=mi>4</span> <span class=o>*</span> <span class=n>n</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>memcpy</span><span class=p>(</span><span class=o>&amp;</span><span class=n>b</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>ny</span><span class=p>],</span> <span class=o>&amp;</span><span class=n>_b</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>n</span><span class=p>],</span> <span class=mi>4</span> <span class=o>*</span> <span class=n>n</span><span class=p>);</span> <span class=c1>// we don&#39;t need to transpose b this time
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>x</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>x</span> <span class=o>&lt;</span> <span class=n>nx</span><span class=p>;</span> <span class=n>x</span> <span class=o>+=</span> <span class=mi>6</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>y</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>y</span> <span class=o>&lt;</span> <span class=n>ny</span><span class=p>;</span> <span class=n>y</span> <span class=o>+=</span> <span class=mi>16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>kernel</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=p>(</span><span class=n>vec</span><span class=o>*</span><span class=p>)</span> <span class=n>b</span><span class=p>,</span> <span class=p>(</span><span class=n>vec</span><span class=o>*</span><span class=p>)</span> <span class=n>c</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>ny</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>memcpy</span><span class=p>(</span><span class=o>&amp;</span><span class=n>_c</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>n</span><span class=p>],</span> <span class=o>&amp;</span><span class=n>c</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>ny</span><span class=p>],</span> <span class=mi>4</span> <span class=o>*</span> <span class=n>n</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>free</span><span class=p>(</span><span class=n>a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>free</span><span class=p>(</span><span class=n>b</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span><span class=o>::</span><span class=n>free</span><span class=p>(</span><span class=n>c</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>This improves the benchmark performance, but only by ~40%:</p><p><figure><img src=../img/mm-kernel-barplot.svg><figcaption></figcaption></figure></p><p>The speedup is much higher (2-3x) on smaller arrays, indicating that there is still a memory bandwidth problem:</p><p><figure><img src=../img/mm-kernel-plot.svg><figcaption></figcaption></figure></p><p>Now, if you&rsquo;ve read the section on <a href=/hpc/external-memory/oblivious/>cache-oblivious algorithms</a>, you know that one universal solution to these types of things is to split all matrices into four parts, perform eight recursive block matrix multiplications, and carefully combine the results together. This solution is okay in practice, but there is some <a href=/hpc/architecture/functions/>overhead to recursion</a>, and it also doesn&rsquo;t allow us to fine-tune the algorithm, so instead, we will follow a different, simpler approach.</p><span class=anchor id=blocking></span><h2><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/algorithms/matmul/#blocking>#</a>Blocking</h2><p>The <em>cache-aware</em> alternative to the divide-and-conquer trick is <em>cache blocking</em>: splitting the data into blocks that can fit into the cache and processing them one by one. If we have more than one layer of cache, we can do hierarchical blocking: we first select a block of data that fits into the L3 cache, then we split it into blocks that fit into the L2 cache, and so on. This approach requires knowing the cache sizes in advance, but it is usually easier to implement and also faster in practice.</p><p>Cache blocking is less trivial to do with matrices than with arrays, but the general idea is this:</p><ul><li>Select a submatrix of $B$ that fits into the L3 cache (say, a subset of its columns).</li><li>Select a submatrix of $A$ that fits into the L2 cache (say, a subset of its rows).</li><li>Select a submatrix of the previously selected submatrix of $B$ (a subset of its rows) that fits into the L1 cache.</li><li>Update the relevant submatrix of $C$ using the kernel.</li></ul><p>Here is a good <a href=https://jukkasuomela.fi/cache-blocking-demo/>visualization</a> by Jukka Suomela (it features many different approaches; you are interested in the last one).</p><p>Note that the decision to start this process with matrix $B$ is not arbitrary. During the kernel execution, we are reading the elements of $A$ much slower than the elements of $B$: we fetch and broadcast just one element of $A$ and then multiply it with $16$ elements of $B$. Therefore, we want $B$ to be in the L1 cache while $A$ can stay in the L2 cache and not the other way around.</p><p>This sounds complicated, but we can implement it with just three more outer <code>for</code> loops, which are collectively called <em>macro-kernel</em> (and the highly optimized low-level function that updates a 6x16 submatrix is called <em>micro-kernel</em>):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>s3</span> <span class=o>=</span> <span class=mi>64</span><span class=p>;</span>  <span class=c1>// how many columns of B to select
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>const</span> <span class=kt>int</span> <span class=n>s2</span> <span class=o>=</span> <span class=mi>120</span><span class=p>;</span> <span class=c1>// how many rows of A to select 
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>const</span> <span class=kt>int</span> <span class=n>s1</span> <span class=o>=</span> <span class=mi>240</span><span class=p>;</span> <span class=c1>// how many rows of B to select
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i3</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i3</span> <span class=o>&lt;</span> <span class=n>ny</span><span class=p>;</span> <span class=n>i3</span> <span class=o>+=</span> <span class=n>s3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1>// now we are working with b[:][i3:i3+s3]
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i2</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i2</span> <span class=o>&lt;</span> <span class=n>nx</span><span class=p>;</span> <span class=n>i2</span> <span class=o>+=</span> <span class=n>s2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1>// now we are working with a[i2:i2+s2][:]
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i1</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i1</span> <span class=o>&lt;</span> <span class=n>ny</span><span class=p>;</span> <span class=n>i1</span> <span class=o>+=</span> <span class=n>s1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1>// now we are working with b[i1:i1+s1][i3:i3+s3]
</span></span></span><span class=line><span class=cl><span class=c1></span>            <span class=c1>// and we need to update c[i2:i2+s2][i3:i3+s3] with [l:r] = [i1:i1+s1]
</span></span></span><span class=line><span class=cl><span class=c1></span>            <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>x</span> <span class=o>=</span> <span class=n>i2</span><span class=p>;</span> <span class=n>x</span> <span class=o>&lt;</span> <span class=n>std</span><span class=o>::</span><span class=n>min</span><span class=p>(</span><span class=n>i2</span> <span class=o>+</span> <span class=n>s2</span><span class=p>,</span> <span class=n>nx</span><span class=p>);</span> <span class=n>x</span> <span class=o>+=</span> <span class=mi>6</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>y</span> <span class=o>=</span> <span class=n>i3</span><span class=p>;</span> <span class=n>y</span> <span class=o>&lt;</span> <span class=n>std</span><span class=o>::</span><span class=n>min</span><span class=p>(</span><span class=n>i3</span> <span class=o>+</span> <span class=n>s3</span><span class=p>,</span> <span class=n>ny</span><span class=p>);</span> <span class=n>y</span> <span class=o>+=</span> <span class=mi>16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>kernel</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=p>(</span><span class=n>vec</span><span class=o>*</span><span class=p>)</span> <span class=n>b</span><span class=p>,</span> <span class=p>(</span><span class=n>vec</span><span class=o>*</span><span class=p>)</span> <span class=n>c</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>i1</span><span class=p>,</span> <span class=n>std</span><span class=o>::</span><span class=n>min</span><span class=p>(</span><span class=n>i1</span> <span class=o>+</span> <span class=n>s1</span><span class=p>,</span> <span class=n>n</span><span class=p>),</span> <span class=n>ny</span><span class=p>);</span>
</span></span></code></pre></div><p>Cache blocking completely removes the memory bottleneck:</p><p><figure><img src=../img/mm-blocked-barplot.svg><figcaption></figcaption></figure></p><p>The performance is no longer (significantly) affected by the problem size:</p><p><figure><img src=../img/mm-blocked-plot.svg><figcaption></figcaption></figure></p><p>Notice that the dip at $1536$ is still there: cache associativity still affects the performance. To mitigate this, we can adjust the step constants or insert holes into the layout, but we will not bother doing that for now.</p><span class=anchor id=optimization></span><h2><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/algorithms/matmul/#optimization>#</a>Optimization</h2><p>To approach closer to the performance limit, we need a few more optimizations:</p><ul><li>Remove memory allocation and operate directly on the arrays that are passed to the function. Note that we don&rsquo;t need to do anything with <code>a</code> as we are reading just one element at a time, and we can use an <a href=/hpc/simd/moving/#aligned-loads-and-stores>unaligned</a> <code>store</code> for <code>c</code> as we only use it rarely, so our only concern is reading <code>b</code>.</li><li>Get rid of the <code>std::min</code> so that the size parameters are (mostly) constant and can be embedded into the machine code by the compiler (which also lets it <a href=/hpc/architecture/loops/>unroll</a> the micro-kernel loop more efficiently and avoid runtime checks).</li><li>Rewrite the micro-kernel by hand using 12 vector variables (the compiler seems to struggle with keeping them in registers and writes them first to a temporary memory location and only then to $C$).</li></ul><p>These optimizations are straightforward but quite tedious to implement, so we are not going to list <a href=https://github.com/sslotin/amh-code/blob/main/matmul/v5-unrolled.cc>the code</a> here in the article. It also requires some more work to effectively support &ldquo;weird&rdquo; matrix sizes, which is why we only run benchmarks for sizes that are multiple of $48 = \frac{6 \cdot 16}{\gcd(6, 16)}$.</p><p>These individually small improvements compound and result in another 50% improvement:</p><p><figure><img src=../img/mm-noalloc.svg><figcaption></figcaption></figure></p><p>We are actually not that far from the theoretical performance limit — which can be calculated as the SIMD width times the <code>fma</code> instruction throughput times the clock frequency:</p>$$
\underbrace{8}_{SIMD} \cdot \underbrace{2}_{thr.} \cdot \underbrace{2 \cdot 10^9}_{cycles/sec} = 32 \; GFLOPS \;\; (3.2 \cdot 10^{10})
$$<p>It is more representative to compare against some practical library, such as <a href=https://www.openblas.net/>OpenBLAS</a>. The laziest way to do it is to simply <a href=/hpc/complexity/languages/#blas>invoke matrix multiplication from NumPy</a>. There may be some minor overhead due to Python, but it ends up reaching 80% of the theoretical limit, which seems plausible (a 20% overhead is okay: matrix multiplication is not the only thing that CPUs are made for).</p><p><figure><img src=../img/mm-blas.svg><figcaption></figcaption></figure></p><p>We&rsquo;ve reached ~93% of BLAS performance and ~75% of the theoretical performance limit, which is really great for what is essentially just 40 lines of C.</p><p>Interestingly, the whole thing can be rolled into just one deeply nested <code>for</code> loop with a BLAS level of performance (assuming that we&rsquo;re in 2050 and using GCC version 35, which finally stopped screwing up with register spilling):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i3</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i3</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i3</span> <span class=o>+=</span> <span class=n>s3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i2</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i2</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i2</span> <span class=o>+=</span> <span class=n>s2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i1</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i1</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i1</span> <span class=o>+=</span> <span class=n>s1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>x</span> <span class=o>=</span> <span class=n>i2</span><span class=p>;</span> <span class=n>x</span> <span class=o>&lt;</span> <span class=n>i2</span> <span class=o>+</span> <span class=n>s2</span><span class=p>;</span> <span class=n>x</span> <span class=o>+=</span> <span class=mi>6</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>y</span> <span class=o>=</span> <span class=n>i3</span><span class=p>;</span> <span class=n>y</span> <span class=o>&lt;</span> <span class=n>i3</span> <span class=o>+</span> <span class=n>s3</span><span class=p>;</span> <span class=n>y</span> <span class=o>+=</span> <span class=mi>16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=n>i1</span><span class=p>;</span> <span class=n>k</span> <span class=o>&lt;</span> <span class=n>i1</span> <span class=o>+</span> <span class=n>s1</span><span class=p>;</span> <span class=n>k</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=mi>6</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                            <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=mi>2</span><span class=p>;</span> <span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                                <span class=n>c</span><span class=p>[</span><span class=n>x</span> <span class=o>*</span> <span class=n>n</span> <span class=o>/</span> <span class=mi>8</span> <span class=o>+</span> <span class=n>i</span> <span class=o>*</span> <span class=n>n</span> <span class=o>/</span> <span class=mi>8</span> <span class=o>+</span> <span class=n>y</span> <span class=o>/</span> <span class=mi>8</span> <span class=o>+</span> <span class=n>j</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                                <span class=o>+=</span> <span class=p>(</span><span class=n>vec</span><span class=p>{}</span> <span class=o>+</span> <span class=n>a</span><span class=p>[</span><span class=n>x</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>i</span> <span class=o>*</span> <span class=n>n</span> <span class=o>+</span> <span class=n>k</span><span class=p>])</span>
</span></span><span class=line><span class=cl>                                   <span class=o>*</span> <span class=n>b</span><span class=p>[</span><span class=n>n</span> <span class=o>/</span> <span class=mi>8</span> <span class=o>*</span> <span class=n>k</span> <span class=o>+</span> <span class=n>y</span> <span class=o>/</span> <span class=mi>8</span> <span class=o>+</span> <span class=n>j</span><span class=p>];</span>
</span></span></code></pre></div><p>There is also an approach that performs asymptotically fewer arithmetic operations — <a href=/hpc/external-memory/oblivious/#strassen-algorithm>the Strassen algorithm</a> — but it has a large constant factor, and it is only efficient for <a href=https://arxiv.org/pdf/1605.01078.pdf>very large matrices</a> ($n > 4000$), where we typically have to use either multiprocessing or some approximate dimensionality-reducing methods anyway.</p><span class=anchor id=generalizations></span><h2><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/algorithms/matmul/#generalizations>#</a>Generalizations</h2><p>FMA also supports 64-bit floating-point numbers, but it does not support integers: you need to perform addition and multiplication separately, which results in decreased performance. If you can guarantee that all intermediate results can be represented exactly as 32- or 64-bit floating-point numbers (which is <a href=/hpc/arithmetic/errors/>often the case</a>), it may be faster to just convert them to and from floats.</p><p>This approach can be also applied to some similar-looking computations. One example is the &ldquo;min-plus matrix multiplication&rdquo; defined as:</p>$$
(A \circ B)_{ij} = \min_{1 \le k \le n} (A_{ik} + B_{kj})
$$<p>It is also known as the &ldquo;distance product&rdquo; due to its graph interpretation: when applied to itself $(D \circ D)$, the result is the matrix of shortest paths of length two between all pairs of vertices in a fully-connected weighted graph specified by the edge weight matrix $D$.</p><p>A cool thing about the distance product is that if we iterate the process and calculate</p>$$
D_2 = D \circ D \\
D_4 = D_2 \circ D_2 \\
D_8 = D_4 \circ D_4 \\
\ldots
$$<p>…we can find all-pairs shortest paths in $O(\log n)$ steps:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>l</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>l</span> <span class=o>&lt;</span> <span class=n>logn</span><span class=p>;</span> <span class=n>l</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>k</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>k</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>d</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>j</span><span class=p>]</span> <span class=o>=</span> <span class=n>min</span><span class=p>(</span><span class=n>d</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>j</span><span class=p>],</span> <span class=n>d</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>k</span><span class=p>]</span> <span class=o>+</span> <span class=n>d</span><span class=p>[</span><span class=n>k</span><span class=p>][</span><span class=n>j</span><span class=p>]);</span>
</span></span></code></pre></div><p>This requires $O(n^3 \log n)$ operations. If we do these two-edge relaxations in a particular order, we can do it with just one pass, which is known as the <a href=https://en.wikipedia.org/wiki/Floyd%E2%80%93Warshall_algorithm>Floyd-Warshall algorithm</a>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>k</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>k</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>j</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>d</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>j</span><span class=p>]</span> <span class=o>=</span> <span class=n>min</span><span class=p>(</span><span class=n>d</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>j</span><span class=p>],</span> <span class=n>d</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>k</span><span class=p>]</span> <span class=o>+</span> <span class=n>d</span><span class=p>[</span><span class=n>k</span><span class=p>][</span><span class=n>j</span><span class=p>]);</span>
</span></span></code></pre></div><p>Interestingly, similarly vectorizing the distance product and executing it $O(\log n)$ times (<a href=https://arxiv.org/pdf/1904.01210.pdf>or possibly fewer</a>) in $O(n^3 \log n)$ total operations is faster than naively executing the Floyd-Warshall algorithm in $O(n^3)$ operations, although not by a lot.</p><p>As an exercise, try to speed up this &ldquo;for-for-for&rdquo; computation. It is harder to do than in the matrix multiplication case because now there is a logical dependency between the iterations, and you need to perform updates in a particular order, but it is still possible to design <a href=https://github.com/sslotin/amh-code/blob/main/floyd/blocked.cc>a similar kernel and a block iteration order</a> that achieves a 30-50x total speedup.</p><span class=anchor id=acknowledgements></span><h2><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/algorithms/matmul/#acknowledgements>#</a>Acknowledgements</h2><p>The final algorithm was originally designed by Kazushige Goto, and it is the basis of GotoBLAS and OpenBLAS. The author himself describes it in more detail in &ldquo;<a href=https://www.cs.utexas.edu/~flame/pubs/GotoTOMS_revision.pdf>Anatomy of High-Performance Matrix Multiplication</a>&rdquo;.</p><p>The exposition style is inspired by the &ldquo;<a href=http://ppc.cs.aalto.fi/>Programming Parallel Computers</a>&rdquo; course by Jukka Suomela, which features a <a href=http://ppc.cs.aalto.fi/ch2/>similar case study</a> on speeding up the distance product.</p></article><div class=nextprev><div class=left><a href=http://jyang772.github.io/hugo-page/hpc/algorithms/prefix/ id=prev-article>← Prefix Sum with SIMD</a></div><div class=right><a href=http://jyang772.github.io/hugo-page/hpc/data-structures/ id=next-article>../Data Structures Case Studies →</a></div></div></main><footer>Copyright 2021–2022 Sergey Slotin<br></footer></div></body></html>