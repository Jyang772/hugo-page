<!doctype html><html lang=en-us><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-WBN59M8Y5S"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WBN59M8Y5S")</script><script type=text/javascript>(function(e,t,n,s,o,i,a){e[o]=e[o]||function(){(e[o].a=e[o].a||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym"),ym(53961409,"init",{clickmap:!0,trackLinks:!0,accurateTrackBounce:!0,webvisor:!0})</script><noscript><div><img src=https://mc.yandex.ru/watch/53961409 style=position:absolute;left:-9999px alt></div></noscript><meta charset=utf-8><link rel=stylesheet href=/hugo-page/style.min.a3a4a7a8e8602aaa85b7cb3d655edde028ac80d73f2a97389e2cbcf995dd672d.css integrity="sha256-o6SnqOhgKqqFt8s9ZV7d4CisgNc/Kpc4niy8+ZXdZy0="><link rel=stylesheet href=/syntax.css id=syntax-theme><link rel=stylesheet type=text/css href=https://tikzjax.com/v1/fonts.css><script src=https://tikzjax.com/v1/tikzjax.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js></script><script src=/hugo-page/scripts/lunr.stemmer.support.min.js></script><script src=/hugo-page/scripts/lunr.ru.min.js></script><script src=/hugo-page/scripts/lunr.multi.min.js></script><link rel=stylesheet id=theme><script>function toggleSidebar(){console.log("Toggling sidebar visibility");var e=document.getElementById("sidebar"),t=document.getElementById("wrapper");(e.classList.contains("sidebar-toggled")||window.getComputedStyle(e).display=="block")&&(e.classList.toggle("sidebar-hidden"),t.classList.toggle("sidebar-hidden")),e.classList.add("sidebar-toggled"),t.classList.add("sidebar-toggled")}function switchTheme(e){console.log("Changing theme:",e),document.getElementById("theme").href=e=="dark"?"/hugo-page/dark.min.b3ae1169831434b11b48de5b3e3210547eea6b7884c295ab0030cb973ea0dc49.css":"",document.getElementById("syntax-theme").href=e=="dark"?"/syntax-dark.css":"/syntax.css",localStorage.setItem("theme",e)}async function toggleSearch(){console.log("Toggling search");var e=document.getElementById("search");if(window.getComputedStyle(e).display=="none"?(e.style.display="block",window.scrollTo({top:0}),document.getElementById("search-bar").focus()):e.style.display="none",!index){console.log("Fetching index");const e=await fetch("/hugo-page/searchindex.json"),t=await e.json();index=lunr(function(){this.use(lunr.multiLanguage("en","ru")),this.field("title",{boost:5}),this.field("content",{boost:1}),t.forEach(function(e){this.add(e),articles.push(e)},this)}),console.log("Ready to search")}}var articles=[],index=void 0;function search(){var n,e=document.getElementById("search-bar").value,s=document.getElementById("search-results"),o=document.getElementById("search-count");if(e==""){s.innerHTML="",o.innerHTML="";return}n=index.search(e),o.innerHTML="Found <b>"+n.length+"</b> pages";let t="";for(const a in n){const i=articles[n[a].ref];t+='<li><a href="'+i.path+'">'+i.title+"</a> <p>";const s=i.content,o=80;if(s.includes(e)){const n=s.indexOf(e);n>o&&(t+="…"),t+=s.substring(n-o,n)+"<b>"+e+"</b>"+s.substring(n+e.length,n+e.length+o)}else t+=s.substring(0,o*2);t+="…</p></li>"}s.innerHTML=t}localStorage.getItem("theme")=="dark"&&switchTheme("dark"),window.addEventListener("load",function(){var e=document.getElementById("active-element");e&&e.scrollIntoView({block:"center"})}),window.addEventListener("scroll",function(){var e=document.getElementById("menu");window.scrollY<120?e.classList.remove("scrolled"):e.classList.add("scrolled")}),window.addEventListener("keydown",function(e){if(e.altKey)return;if(document.activeElement.tagName=="INPUT")return;e.key=="ArrowLeft"?document.getElementById("prev-article").click():e.key=="ArrowRight"&&document.getElementById("next-article").click()})</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})'></script><title>Static B-Trees - Algorithmica</title></head><body><nav id=sidebar><div class=title><a href=/>Algorithmica</a>
<span class=slash>/</span>
<a href=/hugo-page/hpc/ class=divisionAbbr>HPC</a></div><ul><li class=part>Performance Engineering</li><li><a href=/hugo-page/hpc/complexity/>Complexity Models</a></li><ol><li><a href=/hugo-page/hpc/complexity/hardware/>Modern Hardware</a></li><li><a href=/hugo-page/hpc/complexity/languages/>Programming Languages</a></li></ol><li><a href=/hugo-page/hpc/architecture/>Computer Architecture</a></li><ol><li><a href=/hugo-page/hpc/architecture/isa/>Instruction Set Architectures</a></li><li><a href=/hugo-page/hpc/architecture/assembly/>Assembly Language</a></li><li><a href=/hugo-page/hpc/architecture/loops/>Loops and Conditionals</a></li><li><a href=/hugo-page/hpc/architecture/functions/>Functions and Recursion</a></li><li><a href=/hugo-page/hpc/architecture/indirect/>Indirect Branching</a></li><li><a href=/hugo-page/hpc/architecture/layout/>Machine Code Layout</a></li></ol><li><a href=/hugo-page/hpc/pipelining/>Instruction-Level Parallelism</a></li><ol><li><a href=/hugo-page/hpc/pipelining/hazards/>Pipeline Hazards</a></li><li><a href=/hugo-page/hpc/pipelining/branching/>The Cost of Branching</a></li><li><a href=/hugo-page/hpc/pipelining/branchless/>Branchless Programming</a></li><li><a href=/hugo-page/hpc/pipelining/tables/>Instruction Tables</a></li><li><a href=/hugo-page/hpc/pipelining/throughput/>Throughput Computing</a></li></ol><li><a href=/hugo-page/hpc/compilation/>Compilation</a></li><ol><li><a href=/hugo-page/hpc/compilation/stages/>Stages of Compilation</a></li><li><a href=/hugo-page/hpc/compilation/flags/>Flags and Targets</a></li><li><a href=/hugo-page/hpc/compilation/situational/>Situational Optimizations</a></li><li><a href=/hugo-page/hpc/compilation/contracts/>Contract Programming</a></li><li><a href=/hugo-page/hpc/compilation/precalc/>Precomputation</a></li></ol><li><a href=/hugo-page/hpc/profiling/>Profiling</a></li><ol><li><a href=/hugo-page/hpc/profiling/instrumentation/>Instrumentation</a></li><li><a href=/hugo-page/hpc/profiling/events/>Statistical Profiling</a></li><li><a href=/hugo-page/hpc/profiling/simulation/>Program Simulation</a></li><li><a href=/hugo-page/hpc/profiling/mca/>Machine Code Analyzers</a></li><li><a href=/hugo-page/hpc/profiling/benchmarking/>Benchmarking</a></li><li><a href=/hugo-page/hpc/profiling/noise/>Getting Accurate Results</a></li></ol><li><a href=/hugo-page/hpc/arithmetic/>Arithmetic</a></li><ol><li><a href=/hugo-page/hpc/arithmetic/float/>Floating-Point Numbers</a></li><li><a href=/hugo-page/hpc/arithmetic/ieee-754/>IEEE 754 Floats</a></li><li><a href=/hugo-page/hpc/arithmetic/errors/>Rounding Errors</a></li><li><a href=/hugo-page/hpc/arithmetic/newton/>Newton's Method</a></li><li><a href=/hugo-page/hpc/arithmetic/rsqrt/>Fast Inverse Square Root</a></li><li><a href=/hugo-page/hpc/arithmetic/integer/>Integer Numbers</a></li><li><a href=/hugo-page/hpc/arithmetic/division/>Integer Division</a></li></ol><li><a href=/hugo-page/hpc/number-theory/>Number Theory</a></li><ol><li><a href=/hugo-page/hpc/number-theory/modular/>Modular Arithmetic</a></li><li><a href=/hugo-page/hpc/number-theory/exponentiation/>Binary Exponentiation</a></li><li><a href=/hugo-page/hpc/number-theory/euclid-extended/>Extended Euclidean Algorithm</a></li><li><a href=/hugo-page/hpc/number-theory/montgomery/>Montgomery Multiplication</a></li></ol><li><a href=/hugo-page/hpc/external-memory/>External Memory</a></li><ol><li><a href=/hugo-page/hpc/external-memory/hierarchy/>Memory Hierarchy</a></li><li><a href=/hugo-page/hpc/external-memory/virtual/>Virtual Memory</a></li><li><a href=/hugo-page/hpc/external-memory/model/>External Memory Model</a></li><li><a href=/hugo-page/hpc/external-memory/sorting/>External Sorting</a></li><li><a href=/hugo-page/hpc/external-memory/list-ranking/>List Ranking</a></li><li><a href=/hugo-page/hpc/external-memory/policies/>Eviction Policies</a></li><li><a href=/hugo-page/hpc/external-memory/oblivious/>Cache-Oblivious Algorithms</a></li><li><a href=/hugo-page/hpc/external-memory/locality/>Spatial and Temporal Locality</a></li></ol><li><a href=/hugo-page/hpc/cpu-cache/>RAM & CPU Caches</a></li><ol><li><a href=/hugo-page/hpc/cpu-cache/bandwidth/>Memory Bandwidth</a></li><li><a href=/hugo-page/hpc/cpu-cache/latency/>Memory Latency</a></li><li><a href=/hugo-page/hpc/cpu-cache/cache-lines/>Cache Lines</a></li><li><a href=/hugo-page/hpc/cpu-cache/sharing/>Memory Sharing</a></li><li><a href=/hugo-page/hpc/cpu-cache/mlp/>Memory-Level Parallelism</a></li><li><a href=/hugo-page/hpc/cpu-cache/prefetching/>Prefetching</a></li><li><a href=/hugo-page/hpc/cpu-cache/alignment/>Alignment and Packing</a></li><li><a href=/hugo-page/hpc/cpu-cache/pointers/>Pointer Alternatives</a></li><li><a href=/hugo-page/hpc/cpu-cache/associativity/>Cache Associativity</a></li><li><a href=/hugo-page/hpc/cpu-cache/paging/>Memory Paging</a></li><li><a href=/hugo-page/hpc/cpu-cache/aos-soa/>AoS and SoA</a></li></ol><li><a href=/hugo-page/hpc/simd/>SIMD Parallelism</a></li><ol><li><a href=/hugo-page/hpc/simd/intrinsics/>Intrinsics and Vector Types</a></li><li><a href=/hugo-page/hpc/simd/moving/>Moving Data</a></li><li><a href=/hugo-page/hpc/simd/reduction/>Reductions</a></li><li><a href=/hugo-page/hpc/simd/masking/>Masking and Blending</a></li><li><a href=/hugo-page/hpc/simd/shuffling/>In-Register Shuffles</a></li><li><a href=/hugo-page/hpc/simd/auto-vectorization/>Auto-Vectorization and SPMD</a></li></ol><li><a href=/hugo-page/hpc/algorithms/>Algorithms Case Studies</a></li><ol><li><a href=/hugo-page/hpc/algorithms/gcd/>Binary GCD</a></li><li><a href=/hugo-page/hpc/algorithms/factorization/>Integer Factorization</a></li><li><a href=/hugo-page/hpc/algorithms/argmin/>Argmin with SIMD</a></li><li><a href=/hugo-page/hpc/algorithms/prefix/>Prefix Sum with SIMD</a></li><li><a href=/hugo-page/hpc/algorithms/matmul/>Matrix Multiplication</a></li></ol><li><a href=/hugo-page/hpc/data-structures/>Data Structures Case Studies</a></li><ol><li><a href=/hugo-page/hpc/data-structures/binary-search/>Binary Search</a></li><li><a href=/hugo-page/hpc/data-structures/s-tree/ id=active-element>Static B-Trees</a></li><li><a href=/hugo-page/hpc/data-structures/b-tree/>Search Trees</a></li><li><a href=/hugo-page/hpc/data-structures/segment-trees/>Segment Trees</a></li></ol></ul></nav><div id=wrapper><menu id=menu><div class=left><a><img src=/icons/bars-solid.svg onclick=toggleSidebar() title='open table of contents'>
</a><a><img src=/icons/adjust-solid.svg style=position:relative;top:-1px onclick='switchTheme(localStorage.getItem("theme")=="dark"?"light":"dark")' title='dark theme'>
</a><a><img src=/icons/search-solid.svg onclick=toggleSearch() title=search></a></div><div class=title>Static B-Trees</div><div class=right><a onclick=window.print()><img src=/icons/print-solid.svg title=print>
</a><a href=https://prose.io/#algorithmica-org/algorithmica/edit/master//hpc%2fdata-structures%2fs-tree.md><img src=/icons/edit-solid.svg title=edit style=width:18px;position:relative;right:-2px;top:-1px>
</a><a href=https://github.com/algorithmica-org/algorithmica/blob/master//hpc/data-structures/s-tree.md class=github-main><img src=/icons/github-brands.svg title='view on github'></a></div></menu><main><div id=search><input id=search-bar type=search placeholder='Search this book…' oninput=search()><div id=search-count></div><div id=search-results></div></div><header><h1>Static B-Trees</h1><div class=info></div></header><article><p>This section is a follow-up to the <a href=../binary-search>previous one</a>, where we optimized binary search by the means of removing branching and improving the memory layout. Here, we will also be searching in sorted arrays, but this time we are not limited to fetching and comparing only one element at a time.</p><p>In this section, we generalize the techniques we developed for binary search to <em>static B-trees</em> and accelerate them further using <a href=/hpc/simd>SIMD instructions</a>. In particular, we develop two new implicit data structures:</p><ul><li>The <a href=#b-tree-layout>first</a> is based on the memory layout of a B-tree, and, depending on the array size, it is up to 8x faster than <code>std::lower_bound</code> while using the same space as the array and only requiring a permutation of its elements.</li><li>The <a href=#b-tree-layout-1>second</a> is based on the memory layout of a B+ tree, and it is up to 15x faster than <code>std::lower_bound</code> while using just 6-7% more memory — or 6-7% <strong>of</strong> the memory if we can keep the original sorted array.</li></ul><p>To distinguish them from B-trees — the structures with pointers, hundreds to thousands of keys per node, and empty spaces in them — we will use the names <em>S-tree</em> and <em>S+ tree</em> respectively to refer to these particular memory layouts<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>.</p><p>To the best of my knowledge, this is a significant improvement over the existing <a href=http://kaldewey.com/pubs/FAST__SIGMOD10.pdf>approaches</a>. As before, we are using Clang 10 targeting a Zen 2 CPU, but the performance improvements should approximately transfer to most other platforms, including Arm-based chips. Use <a href=https://github.com/sslotin/amh-code/blob/main/binsearch/standalone.cc>this single-source benchmark</a> of the final implementation if you want to test it on your machine.</p><p>This is a long article, and since it also serves as a <a href=/hpc/>textbook</a> case study, we will improve the algorithm incrementally for pedagogical goals. If you are already an expert and feel comfortable reading <a href=/hpc/simd/intrinsics>intrinsic</a>-heavy code with little to no context, you can jump straight to the <a href=#implicit-b-tree-1>final implementation</a>.</p><span class=anchor id=b-tree-layout></span><h2><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/data-structures/s-tree/#b-tree-layout>#</a>B-Tree Layout</h2><p>B-trees generalize the concept of binary search trees by allowing nodes to have more than two children. Instead of a single key, a node of a B-tree of order $k$ can contain up to $B = (k - 1)$ keys stored in sorted order and up to $k$ pointers to child nodes. Each child $i$ satisfies the property that all keys in its subtree are between keys $(i - 1)$ and $i$ of the parent node (if they exist).</p><p><figure><img src=../img/b-tree.jpg><figcaption>A B-tree of order 4</figcaption></figure></p><p>The main advantage of this approach is that it reduces the tree height by $\frac{\log_2 n}{\log_k n} = \frac{\log k}{\log 2} = \log_2 k$ times, while fetching each node still takes roughly the same time — as long it fits into a single <a href=/hpc/external-memory/hierarchy/>memory block</a>.</p><p>B-trees were primarily developed for the purpose of managing on-disk databases, where the latency of randomly fetching a single byte is comparable with the time it takes to read the next 1MB of data sequentially. For our use case, we will be using the block size of $B = 16$ elements — or $64$ bytes, the size of the cache line — which makes the tree height and the total number of cache line fetches per query $\log_2 17 \approx 4$ times smaller compared to the binary search.</p><span class=anchor id=implicit-b-tree></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/data-structures/s-tree/#implicit-b-tree>#</a>Implicit B-Tree</h3><p>Storing and fetching pointers in a B-tree node wastes precious cache space and decreases performance, but they are essential for changing the tree structure on inserts and deletions. But when there are no updates and the structure of a tree is <em>static</em>, we can get rid of the pointers, which makes the structure <em>implicit</em>.</p><p>One of the ways to achieve this is by generalizing the <a href=../binary-search#eytzinger-layout>Eytzinger numeration</a> to $(B + 1)$-ary trees:</p><ul><li>The root node is numbered $0$.</li><li>Node $k$ has $(B + 1)$ child nodes numbered $\{k \cdot (B + 1) + i + 1\}$ for $i \in [0, B]$.</li></ul><p>This way, we can only use $O(1)$ additional memory by allocating one large two-dimensional array of keys and relying on index arithmetic to locate children nodes in the tree:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>B</span> <span class=o>=</span> <span class=mi>16</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=n>nblocks</span> <span class=o>=</span> <span class=p>(</span><span class=n>n</span> <span class=o>+</span> <span class=n>B</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>B</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=n>btree</span><span class=p>[</span><span class=n>nblocks</span><span class=p>][</span><span class=n>B</span><span class=p>];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>go</span><span class=p>(</span><span class=kt>int</span> <span class=n>k</span><span class=p>,</span> <span class=kt>int</span> <span class=n>i</span><span class=p>)</span> <span class=p>{</span> <span class=k>return</span> <span class=n>k</span> <span class=o>*</span> <span class=p>(</span><span class=n>B</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>;</span> <span class=p>}</span>
</span></span></code></pre></div><p>This numeration automatically makes the B-tree complete or almost complete with the height of $\Theta(\log_{B + 1} n)$. If the length of the initial array is not a multiple of $B$, the last block is padded with the largest value of its data type.</p><span class=anchor id=construction></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/data-structures/s-tree/#construction>#</a>Construction</h3><p>We can construct the B-tree similar to how we constructed the Eytzinger array — by traversing the search tree:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>void</span> <span class=nf>build</span><span class=p>(</span><span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>0</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>static</span> <span class=kt>int</span> <span class=n>t</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>k</span> <span class=o>&lt;</span> <span class=n>nblocks</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>B</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=n>build</span><span class=p>(</span><span class=n>go</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>i</span><span class=p>));</span>
</span></span><span class=line><span class=cl>            <span class=n>btree</span><span class=p>[</span><span class=n>k</span><span class=p>][</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=n>t</span> <span class=o>&lt;</span> <span class=n>n</span> <span class=o>?</span> <span class=n>a</span><span class=p>[</span><span class=n>t</span><span class=o>++</span><span class=p>]</span> <span class=o>:</span> <span class=n>INT_MAX</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=n>build</span><span class=p>(</span><span class=n>go</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>B</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>It is correct because each value of the initial array will be copied to a unique position in the resulting array, and the tree height is $\Theta(\log_{B+1} n)$ because $k$ is multiplied by $(B + 1)$ each time we descend into a child node.</p><p>Note that this numeration causes a slight imbalance: left-er children may have larger subtrees, although this is only true for $O(\log_{B+1} n)$ parent nodes.</p><span class=anchor id=searches></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/data-structures/s-tree/#searches>#</a>Searches</h3><p>To find the lower bound, we need to fetch the $B$ keys in a node, find the first key $a_i$ not less than $x$, descend to the $i$-th child — and continue until we reach a leaf node. There is some variability in how to find that first key. For example, we could do a tiny internal binary search that makes $O(\log B)$ iterations, or maybe just compare each key sequentially in $O(B)$ time until we find the local lower bound, hopefully exiting from the loop a bit early.</p><p>But we are not going to do that — because we can use <a href=/hpc/simd>SIMD</a>. It doesn&rsquo;t work well with branching, so essentially what we want to do is to compare against all $B$ elements regardless, compute a bitmask out of these comparisons, and then use the <code>ffs</code> instruction to find the bit corresponding to the first non-lesser element:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=kt>int</span> <span class=n>mask</span> <span class=o>=</span> <span class=p>(</span><span class=mi>1</span> <span class=o>&lt;&lt;</span> <span class=n>B</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>B</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mask</span> <span class=o>|=</span> <span class=p>(</span><span class=n>btree</span><span class=p>[</span><span class=n>k</span><span class=p>][</span><span class=n>i</span><span class=p>]</span> <span class=o>&gt;=</span> <span class=n>x</span><span class=p>)</span> <span class=o>&lt;&lt;</span> <span class=n>i</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>__builtin_ffs</span><span class=p>(</span><span class=n>mask</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=c1>// now i is the number of the correct child node
</span></span></span></code></pre></div><p>Unfortunately, the compilers are not smart enough to <a href=/hpc/simd/auto-vectorization/>auto-vectorize</a> this code yet, so we have to optimize it manually. In AVX2, we can load 8 elements, compare them against the search key, producing a <a href=/hpc/simd/masking/>vector mask</a>, and then extract the scalar mask from it with <code>movemask</code>. Here is a minimized illustrated example of what we want to do:</p><pre class=center-pre>
       y = 4        17       65       103     
       x = 42       42       42       42      
   y ≥ x = 00000000 00000000 11111111 11111111
           ├┬┬┬─────┴────────┴────────┘       
movemask = 0011                               
           ┌─┘                                
     ffs = 3                                  
</pre><p>Since we are limited to processing 8 elements at a time (half our block / cache line size), we have to split the elements into two groups and then combine the two 8-bit masks. To do this, it will be slightly easier to swap the condition for <code>x > y</code> and compute the inverted mask instead:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>typedef</span> <span class=n>__m256i</span> <span class=n>reg</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>cmp</span><span class=p>(</span><span class=n>reg</span> <span class=n>x_vec</span><span class=p>,</span> <span class=kt>int</span><span class=o>*</span> <span class=n>y_ptr</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>reg</span> <span class=n>y_vec</span> <span class=o>=</span> <span class=n>_mm256_load_si256</span><span class=p>((</span><span class=n>reg</span><span class=o>*</span><span class=p>)</span> <span class=n>y_ptr</span><span class=p>);</span> <span class=c1>// load 8 sorted elements
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>reg</span> <span class=n>mask</span> <span class=o>=</span> <span class=n>_mm256_cmpgt_epi32</span><span class=p>(</span><span class=n>x_vec</span><span class=p>,</span> <span class=n>y_vec</span><span class=p>);</span> <span class=c1>// compare against the key
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>return</span> <span class=n>_mm256_movemask_ps</span><span class=p>((</span><span class=n>__m256</span><span class=p>)</span> <span class=n>mask</span><span class=p>);</span>    <span class=c1>// extract the 8-bit mask
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span>
</span></span></code></pre></div><p>Now, to process the entire block, we need to call it twice and combine the masks:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>int</span> <span class=n>mask</span> <span class=o>=</span> <span class=o>~</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>cmp</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>btree</span><span class=p>[</span><span class=n>k</span><span class=p>][</span><span class=mi>0</span><span class=p>])</span> <span class=o>+</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=n>cmp</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>btree</span><span class=p>[</span><span class=n>k</span><span class=p>][</span><span class=mi>8</span><span class=p>])</span> <span class=o>&lt;&lt;</span> <span class=mi>8</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>);</span>
</span></span></code></pre></div><p>To descend down the tree, we use <code>ffs</code> on that mask to get the correct child number and just call the <code>go</code> function we defined earlier:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>__builtin_ffs</span><span class=p>(</span><span class=n>mask</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>k</span> <span class=o>=</span> <span class=n>go</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>i</span><span class=p>);</span>
</span></span></code></pre></div><p>To actually return the result in the end, we&rsquo;d want to just fetch <code>btree[k][i]</code> in the last node we visited, but the problem is that sometimes the local lower bound doesn&rsquo;t exist ($i \ge B$) because $x$ happens to be greater than all the keys in the node. We could, in theory, do the same thing we did for the <a href=../binary-search/#search-implementation>Eytzinger binary search</a> and restore the correct element <em>after</em> we calculate the last index, but we don&rsquo;t have a nice bit trick this time and have to do a lot of <a href=/hpc/arithmetic/division>divisions by 17</a> to compute it, which will be slow and almost certainly not worth it.</p><p>Instead, we can just remember and return the last local lower bound we encountered when we descended the tree:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>int</span> <span class=nf>lower_bound</span><span class=p>(</span><span class=kt>int</span> <span class=n>_x</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>0</span><span class=p>,</span> <span class=n>res</span> <span class=o>=</span> <span class=n>INT_MAX</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>reg</span> <span class=n>x</span> <span class=o>=</span> <span class=n>_mm256_set1_epi32</span><span class=p>(</span><span class=n>_x</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=p>(</span><span class=n>k</span> <span class=o>&lt;</span> <span class=n>nblocks</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=kt>int</span> <span class=n>mask</span> <span class=o>=</span> <span class=o>~</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>cmp</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>btree</span><span class=p>[</span><span class=n>k</span><span class=p>][</span><span class=mi>0</span><span class=p>])</span> <span class=o>+</span>
</span></span><span class=line><span class=cl>            <span class=p>(</span><span class=n>cmp</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>btree</span><span class=p>[</span><span class=n>k</span><span class=p>][</span><span class=mi>8</span><span class=p>])</span> <span class=o>&lt;&lt;</span> <span class=mi>8</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>__builtin_ffs</span><span class=p>(</span><span class=n>mask</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>i</span> <span class=o>&lt;</span> <span class=n>B</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>res</span> <span class=o>=</span> <span class=n>btree</span><span class=p>[</span><span class=n>k</span><span class=p>][</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=n>k</span> <span class=o>=</span> <span class=n>go</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>i</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>res</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>This implementation outperforms all previous binary search implementations, and by a huge margin:</p><p><figure><img src=../img/search-btree.svg><figcaption></figcaption></figure></p><p>This is very good — but we can optimize it even further.</p><span class=anchor id=optimization></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/data-structures/s-tree/#optimization>#</a>Optimization</h3><p>Before everything else, let&rsquo;s allocate the memory for the array on a <a href=/hpc/cpu-cache/paging>hugepage</a>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>P</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>&lt;&lt;</span> <span class=mi>21</span><span class=p>;</span>                        <span class=c1>// page size in bytes (2MB)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>const</span> <span class=kt>int</span> <span class=n>T</span> <span class=o>=</span> <span class=p>(</span><span class=mi>64</span> <span class=o>*</span> <span class=n>nblocks</span> <span class=o>+</span> <span class=n>P</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>P</span> <span class=o>*</span> <span class=n>P</span><span class=p>;</span> <span class=c1>// can only allocate whole number of pages
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>btree</span> <span class=o>=</span> <span class=p>(</span><span class=kt>int</span><span class=p>(</span><span class=o>*</span><span class=p>)[</span><span class=mi>16</span><span class=p>])</span> <span class=n>std</span><span class=o>::</span><span class=n>aligned_alloc</span><span class=p>(</span><span class=n>P</span><span class=p>,</span> <span class=n>T</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>madvise</span><span class=p>(</span><span class=n>btree</span><span class=p>,</span> <span class=n>T</span><span class=p>,</span> <span class=n>MADV_HUGEPAGE</span><span class=p>);</span>
</span></span></code></pre></div><p>This slightly improves the performance on larger array sizes:</p><p><figure><img src=../img/search-btree-hugepages.svg><figcaption></figcaption></figure></p><p>Ideally, we&rsquo;d also need to enable hugepages for all <a href=../binary-search>previous implementations</a> to make the comparison fair, but it doesn&rsquo;t matter that much because they all have some form of prefetching that alleviates this problem.</p><p>With that settled, let&rsquo;s begin real optimization. First of all, we&rsquo;d want to use compile-time constants instead of variables as much as possible because it lets the compiler embed them in the machine code, unroll loops, optimize arithmetic, and do all sorts of other nice stuff for us for free. Specifically, we want to know the tree height in advance:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>constexpr</span> <span class=kt>int</span> <span class=nf>height</span><span class=p>(</span><span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>// grow the tree until its size exceeds n elements
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>int</span> <span class=n>s</span> <span class=o>=</span> <span class=mi>0</span><span class=p>,</span> <span class=c1>// total size so far
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>l</span> <span class=o>=</span> <span class=n>B</span><span class=p>,</span> <span class=c1>// size of the next layer
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>h</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=c1>// height so far
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>while</span> <span class=p>(</span><span class=n>s</span> <span class=o>+</span> <span class=n>l</span> <span class=o>-</span> <span class=n>B</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>+=</span> <span class=n>l</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>l</span> <span class=o>*=</span> <span class=p>(</span><span class=n>B</span> <span class=o>+</span> <span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>h</span><span class=o>++</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>h</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>H</span> <span class=o>=</span> <span class=n>height</span><span class=p>(</span><span class=n>N</span><span class=p>);</span>
</span></span></code></pre></div><p>Next, we can find the local lower bound in nodes faster. Instead of calculating it separately for two 8-element blocks and merging two 8-bit masks, we combine the vector masks using the <a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#ig_expand=3037,4870,6715,4845,3853,90,7307,5993,2692,6946,6949,5456,6938,5456,1021,3007,514,518,7253,7183,3892,5135,5260,3915,4027,3873,7401,4376,4229,151,2324,2310,2324,4075,6130,4875,6385,5259,6385,6250,1395,7253,6452,7492,4669,4669,7253,1039,1029,4669,4707,7253,7242,848,879,848,7251,4275,879,874,849,833,6046,7250,4870,4872,4875,849,849,5144,4875,4787,4787,4787,5227,7359,7335,7392,4787,5259,5230,5223,6438,488,483,6165,6570,6554,289,6792,6554,5230,6385,5260,5259,289,288,3037,3009,590,604,5230,5259,6554,6554,5259,6547,6554,3841,5214,5229,5260,5259,7335,5259,519,1029,515,3009,3009,3011,515,6527,652,6527,6554,288,3841,5230,5259,5230,5259,305,5259,591,633,633,5259,5230,5259,5259,3017,3018,3037,3018,3017,3016,3013,5144&amp;text=_mm256_packs_epi32&amp;techs=AVX,AVX2">packs</a> instruction and readily extract it using <code>movemask</code> just once:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>unsigned</span> <span class=nf>rank</span><span class=p>(</span><span class=n>reg</span> <span class=n>x</span><span class=p>,</span> <span class=kt>int</span><span class=o>*</span> <span class=n>y</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>reg</span> <span class=n>a</span> <span class=o>=</span> <span class=n>_mm256_load_si256</span><span class=p>((</span><span class=n>reg</span><span class=o>*</span><span class=p>)</span> <span class=n>y</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>reg</span> <span class=n>b</span> <span class=o>=</span> <span class=n>_mm256_load_si256</span><span class=p>((</span><span class=n>reg</span><span class=o>*</span><span class=p>)</span> <span class=p>(</span><span class=n>y</span> <span class=o>+</span> <span class=mi>8</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>reg</span> <span class=n>ca</span> <span class=o>=</span> <span class=n>_mm256_cmpgt_epi32</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>x</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>reg</span> <span class=n>cb</span> <span class=o>=</span> <span class=n>_mm256_cmpgt_epi32</span><span class=p>(</span><span class=n>b</span><span class=p>,</span> <span class=n>x</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>reg</span> <span class=n>c</span> <span class=o>=</span> <span class=n>_mm256_packs_epi32</span><span class=p>(</span><span class=n>ca</span><span class=p>,</span> <span class=n>cb</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>mask</span> <span class=o>=</span> <span class=n>_mm256_movemask_epi8</span><span class=p>(</span><span class=n>c</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// we need to divide the result by two because we call movemask_epi8 on 16-bit masks:
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>return</span> <span class=n>__tzcnt_u32</span><span class=p>(</span><span class=n>mask</span><span class=p>)</span> <span class=o>&gt;&gt;</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>This instruction converts 32-bit integers stored in two registers to 16-bit integers stored in one register — in our case, effectively joining the vector masks into one. Note that we&rsquo;ve swapped the order of comparison — this lets us not invert the mask in the end, but we have to subtract<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> one from the search key once in the beginning to make it correct (otherwise, it works as <code>upper_bound</code>).</p><p>The problem is, it does this weird interleaving where the result is written in the <code>a1 b1 a2 b2</code> order instead of <code>a1 a2 b1 b2</code> that we want — many AVX2 instructions tend to do that. To correct this, we need to <a href=/hpc/simd/shuffling>permute</a> the resulting vector, but instead of doing it during the query time, we can just permute every node during preprocessing:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>void</span> <span class=nf>permute</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>node</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>const</span> <span class=n>reg</span> <span class=n>perm</span> <span class=o>=</span> <span class=n>_mm256_setr_epi32</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>reg</span><span class=o>*</span> <span class=n>middle</span> <span class=o>=</span> <span class=p>(</span><span class=n>reg</span><span class=o>*</span><span class=p>)</span> <span class=p>(</span><span class=n>node</span> <span class=o>+</span> <span class=mi>4</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>reg</span> <span class=n>x</span> <span class=o>=</span> <span class=n>_mm256_loadu_si256</span><span class=p>(</span><span class=n>middle</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>_mm256_permutevar8x32_epi32</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>perm</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>_mm256_storeu_si256</span><span class=p>(</span><span class=n>middle</span><span class=p>,</span> <span class=n>x</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Now we just call <code>permute(&amp;btree[k])</code> right after we are done building the node. There are probably faster ways to swap the middle elements, but we will leave it here as the preprocessing time is not that important for now.</p><p>This new SIMD routine is significantly faster because the extra <code>movemask</code> is slow, and also blending the two masks takes quite a few instructions. Unfortunately, we now can&rsquo;t just do the <code>res = btree[k][i]</code> update anymore because the elements are permuted. We can solve this problem with some bit-level trickery in terms of <code>i</code>, but indexing a small lookup table turns out to be faster and also doesn&rsquo;t require a new branch:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>translate</span><span class=p>[</span><span class=mi>17</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=p>};</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>update</span><span class=p>(</span><span class=kt>int</span> <span class=o>&amp;</span><span class=n>res</span><span class=p>,</span> <span class=kt>int</span><span class=o>*</span> <span class=n>node</span><span class=p>,</span> <span class=kt>unsigned</span> <span class=n>i</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>val</span> <span class=o>=</span> <span class=n>node</span><span class=p>[</span><span class=n>translate</span><span class=p>[</span><span class=n>i</span><span class=p>]];</span>
</span></span><span class=line><span class=cl>    <span class=n>res</span> <span class=o>=</span> <span class=p>(</span><span class=n>i</span> <span class=o>&lt;</span> <span class=n>B</span> <span class=o>?</span> <span class=nl>val</span> <span class=p>:</span> <span class=n>res</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>This <code>update</code> procedure takes some time, but it&rsquo;s not on the critical path between the iterations, so it doesn&rsquo;t affect the actual performance that much.</p><p>Stitching it all together (and leaving out some other minor optimizations):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>int</span> <span class=nf>lower_bound</span><span class=p>(</span><span class=kt>int</span> <span class=n>_x</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>0</span><span class=p>,</span> <span class=n>res</span> <span class=o>=</span> <span class=n>INT_MAX</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>reg</span> <span class=n>x</span> <span class=o>=</span> <span class=n>_mm256_set1_epi32</span><span class=p>(</span><span class=n>_x</span> <span class=o>-</span> <span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>h</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>h</span> <span class=o>&lt;</span> <span class=n>H</span> <span class=o>-</span> <span class=mi>1</span><span class=p>;</span> <span class=n>h</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=kt>unsigned</span> <span class=n>i</span> <span class=o>=</span> <span class=n>rank</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>btree</span><span class=p>[</span><span class=n>k</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>        <span class=n>update</span><span class=p>(</span><span class=n>res</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>btree</span><span class=p>[</span><span class=n>k</span><span class=p>],</span> <span class=n>i</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>k</span> <span class=o>=</span> <span class=n>go</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>i</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=c1>// the last branch:
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>if</span> <span class=p>(</span><span class=n>k</span> <span class=o>&lt;</span> <span class=n>nblocks</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=kt>unsigned</span> <span class=n>i</span> <span class=o>=</span> <span class=n>rank</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>btree</span><span class=p>[</span><span class=n>k</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>        <span class=n>update</span><span class=p>(</span><span class=n>res</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>btree</span><span class=p>[</span><span class=n>k</span><span class=p>],</span> <span class=n>i</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>res</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>All this work saved us 15-20% or so:</p><p><figure><img src=../img/search-btree-optimized.svg><figcaption></figcaption></figure></p><p>It doesn&rsquo;t feel very satisfying so far, but we will reuse these optimization ideas later.</p><p>There are two main problems with the current implementation:</p><ul><li>The <code>update</code> procedure is quite costly, especially considering that it is very likely going to be useless: 16 out of 17 times, we can just fetch the result from the last block.</li><li>We do a non-constant number of iterations, causing branch prediction problems similar to how it did for the <a href=../binary-search/#removing-the-last-branch>Eytzinger binary search</a>; you can also see it on the graph this time, but the latency bumps have a period of $2^4$.</li></ul><p>To address these problems, we need to change the layout a little bit.</p><span class=anchor id=b-tree-layout-1></span><h2><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/data-structures/s-tree/#b-tree-layout-1>#</a>B+ Tree Layout</h2><p>Most of the time, when people talk about B-trees, they really mean <em>B+ trees</em>, which is a modification that distinguishes between the two types of nodes:</p><ul><li><em>Internal nodes</em> store up to $B$ keys and $(B + 1)$ pointers to child nodes. The key number $i$ is always equal to the smallest key in the subtree of the $(i + 1)$-th child node.</li><li><em>Data nodes</em> or <em>leaves</em> store up to $B$ keys, the pointer to the next leaf node, and, optionally, an associated value for each key — if the structure is used as a key-value map.</li></ul><p>The advantages of this approach include faster search time (as the internal nodes only store keys) and the ability to quickly iterate over a range of entries (by following next leaf node pointers), but this comes at the cost of some memory overhead: we have to store copies of keys in the internal nodes.</p><p><figure><img src=../img/bplus.png><figcaption>A B+ tree of order 4</figcaption></figure></p><p>Back to our use case, this layout can help us solve our two problems:</p><ul><li>Either the last node we descend into has the local lower bound, or it is the first key of the next leaf node, so we don&rsquo;t need to call <code>update</code> on each iteration.</li><li>The depth of all leaves is constant because B+ trees grow at the root and not at the leaves, which removes the need for branching.</li></ul><p>The disadvantage is that this layout is not <em>succinct</em>: we need some additional memory to store the internal nodes — about $\frac{1}{16}$-th of the original array size, to be exact — but the performance improvement will be more than worth it.</p><span class=anchor id=implicit-b-tree-1></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/data-structures/s-tree/#implicit-b-tree-1>#</a>Implicit B+ Tree</h3><p>To be more explicit with pointer arithmetic, we will store the entire tree in a single one-dimensional array. To minimize index computations during run time, we will store each layer sequentially in this array and use compile time computed offsets to address them: the keys of the node number <code>k</code> on layer <code>h</code> start with <code>btree[offset(h) + k * B]</code>, and its <code>i</code>-th child will at <code>btree[offset(h - 1) + (k * (B + 1) + i) * B]</code>.</p><p>To implement all that, we need slightly more <code>constexpr</code> functions:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=c1>// number of B-element blocks in a layer with n keys
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>constexpr</span> <span class=kt>int</span> <span class=nf>blocks</span><span class=p>(</span><span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span><span class=n>n</span> <span class=o>+</span> <span class=n>B</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>B</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// number of keys on the layer previous to one with n keys
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>constexpr</span> <span class=kt>int</span> <span class=nf>prev_keys</span><span class=p>(</span><span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span><span class=n>blocks</span><span class=p>(</span><span class=n>n</span><span class=p>)</span> <span class=o>+</span> <span class=n>B</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>B</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>B</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// height of a balanced n-key B+ tree
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>constexpr</span> <span class=kt>int</span> <span class=nf>height</span><span class=p>(</span><span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span><span class=n>n</span> <span class=o>&lt;=</span> <span class=n>B</span> <span class=o>?</span> <span class=mi>1</span> <span class=o>:</span> <span class=n>height</span><span class=p>(</span><span class=n>prev_keys</span><span class=p>(</span><span class=n>n</span><span class=p>))</span> <span class=o>+</span> <span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// where the layer h starts (layer 0 is the largest)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>constexpr</span> <span class=kt>int</span> <span class=nf>offset</span><span class=p>(</span><span class=kt>int</span> <span class=n>h</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>0</span><span class=p>,</span> <span class=n>n</span> <span class=o>=</span> <span class=n>N</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=p>(</span><span class=n>h</span><span class=o>--</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>k</span> <span class=o>+=</span> <span class=n>blocks</span><span class=p>(</span><span class=n>n</span><span class=p>)</span> <span class=o>*</span> <span class=n>B</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>n</span> <span class=o>=</span> <span class=n>prev_keys</span><span class=p>(</span><span class=n>n</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>k</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>H</span> <span class=o>=</span> <span class=n>height</span><span class=p>(</span><span class=n>N</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>S</span> <span class=o>=</span> <span class=n>offset</span><span class=p>(</span><span class=n>H</span><span class=p>);</span> <span class=c1>// the tree size is the offset of the (non-existent) layer H
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=o>*</span><span class=n>btree</span><span class=p>;</span> <span class=c1>// the tree itself is stored in a single hugepage-aligned array of size S
</span></span></span></code></pre></div><p>Note that we store the layers in reverse order, but the nodes within a layer and data in them are still left-to-right, and also the layers are numbered bottom-up: the leaves form the zeroth layer, and the root is the layer <code>H - 1</code>. These are just arbitrary decisions — it is just slightly easier to implement in code.</p><span class=anchor id=construction-1></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/data-structures/s-tree/#construction-1>#</a>Construction</h3><p>To construct the tree from a sorted array <code>a</code>, we first need to copy it into the zeroth layer and pad it with infinities:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>memcpy</span><span class=p>(</span><span class=n>btree</span><span class=p>,</span> <span class=n>a</span><span class=p>,</span> <span class=mi>4</span> <span class=o>*</span> <span class=n>N</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>N</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>S</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>btree</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>INT_MAX</span><span class=p>;</span>
</span></span></code></pre></div><p>Now we build the internal nodes, layer by layer. For each key, we need to descend to the right of it in, always go left until we reach a leaf node, and then take its first key — it will be the smallest on the subtree:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>h</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span> <span class=n>h</span> <span class=o>&lt;</span> <span class=n>H</span><span class=p>;</span> <span class=n>h</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>offset</span><span class=p>(</span><span class=n>h</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>-</span> <span class=n>offset</span><span class=p>(</span><span class=n>h</span><span class=p>);</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=c1>// i = k * B + j
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=n>i</span> <span class=o>/</span> <span class=n>B</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>j</span> <span class=o>=</span> <span class=n>i</span> <span class=o>-</span> <span class=n>k</span> <span class=o>*</span> <span class=n>B</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>k</span> <span class=o>=</span> <span class=n>k</span> <span class=o>*</span> <span class=p>(</span><span class=n>B</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=n>j</span> <span class=o>+</span> <span class=mi>1</span><span class=p>;</span> <span class=c1>// compare to the right of the key
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=c1>// and then always to the left
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>l</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>l</span> <span class=o>&lt;</span> <span class=n>h</span> <span class=o>-</span> <span class=mi>1</span><span class=p>;</span> <span class=n>l</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>k</span> <span class=o>*=</span> <span class=p>(</span><span class=n>B</span> <span class=o>+</span> <span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=c1>// pad the rest with infinities if the key doesn&#39;t exist 
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>btree</span><span class=p>[</span><span class=n>offset</span><span class=p>(</span><span class=n>h</span><span class=p>)</span> <span class=o>+</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=n>k</span> <span class=o>*</span> <span class=n>B</span> <span class=o>&lt;</span> <span class=n>N</span> <span class=o>?</span> <span class=n>btree</span><span class=p>[</span><span class=n>k</span> <span class=o>*</span> <span class=n>B</span><span class=p>]</span> <span class=o>:</span> <span class=n>INT_MAX</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>And just the finishing touch — we need to permute keys in internal nodes to search them faster:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>offset</span><span class=p>(</span><span class=mi>1</span><span class=p>);</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>S</span><span class=p>;</span> <span class=n>i</span> <span class=o>+=</span> <span class=n>B</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>permute</span><span class=p>(</span><span class=n>btree</span> <span class=o>+</span> <span class=n>i</span><span class=p>);</span>
</span></span></code></pre></div><p>We start from <code>offset(1)</code>, and we specifically don&rsquo;t permute leaf nodes and leave the array in the original sorted order. The motivation is that we&rsquo;d need to do this complex index translation we do in <code>update</code> if the keys were permuted, and it is on the critical path when this is the last operation. So, just for this layer, we switch to the original mask-blending local lower bound procedure.</p><span class=anchor id=searching></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/data-structures/s-tree/#searching>#</a>Searching</h3><p>The search procedure becomes simpler than for the B-tree layout: we don&rsquo;t need to do <code>update</code> and only execute a fixed number of iterations — although the last one with some special treatment:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>int</span> <span class=nf>lower_bound</span><span class=p>(</span><span class=kt>int</span> <span class=n>_x</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>unsigned</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=c1>// we assume k already multiplied by B to optimize pointer arithmetic
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>reg</span> <span class=n>x</span> <span class=o>=</span> <span class=n>_mm256_set1_epi32</span><span class=p>(</span><span class=n>_x</span> <span class=o>-</span> <span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>h</span> <span class=o>=</span> <span class=n>H</span> <span class=o>-</span> <span class=mi>1</span><span class=p>;</span> <span class=n>h</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>;</span> <span class=n>h</span><span class=o>--</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=kt>unsigned</span> <span class=n>i</span> <span class=o>=</span> <span class=n>permuted_rank</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>btree</span> <span class=o>+</span> <span class=n>offset</span><span class=p>(</span><span class=n>h</span><span class=p>)</span> <span class=o>+</span> <span class=n>k</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>k</span> <span class=o>=</span> <span class=n>k</span> <span class=o>*</span> <span class=p>(</span><span class=n>B</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=n>i</span> <span class=o>*</span> <span class=n>B</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=kt>unsigned</span> <span class=n>i</span> <span class=o>=</span> <span class=n>direct_rank</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>btree</span> <span class=o>+</span> <span class=n>k</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>btree</span><span class=p>[</span><span class=n>k</span> <span class=o>+</span> <span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Switching to the B+ layout more than paid off: the S+ tree is 1.5-3x faster compared to the optimized S-tree:</p><p><figure><img src=../img/search-bplus.svg><figcaption></figcaption></figure></p><p>The spikes at the high end of the graph are caused by the L1 TLB not being large enough: it has 64 entries, so it can handle at most 64 × 2 = 128MB of data, which is exactly what is required for storing <code>2^25</code> integers. The S+ tree hits this limit slightly sooner because of the ~7% memory overhead.</p><span class=anchor id=comparison-with-stdlower_bound></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/data-structures/s-tree/#comparison-with-stdlower_bound>#</a>Comparison with <code>std::lower_bound</code></h3><p>We&rsquo;ve come a long way from binary search:</p><p><figure><img src=../img/search-all.svg><figcaption></figcaption></figure></p><p>On these scales, it makes more sense to look at the relative speedup:</p><p><figure><img src=../img/search-relative.svg><figcaption></figcaption></figure></p><p>The cliffs at the beginning of the graph are because the running time of <code>std::lower_bound</code> grows smoothly with the array size, while for an S+ tree, it is locally flat and increases in discrete steps when a new layer needs to be added.</p><p>One important asterisk we haven&rsquo;t discussed is that what we are measuring is not real latency, but the <em>reciprocal throughput</em> — the total time it takes to execute a lot of queries divided by the number of queries:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>clock_t</span> <span class=n>start</span> <span class=o>=</span> <span class=n>clock</span><span class=p>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>m</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>checksum</span> <span class=o>^=</span> <span class=n>lower_bound</span><span class=p>(</span><span class=n>q</span><span class=p>[</span><span class=n>i</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>float</span> <span class=n>seconds</span> <span class=o>=</span> <span class=kt>float</span><span class=p>(</span><span class=n>clock</span><span class=p>()</span> <span class=o>-</span> <span class=n>start</span><span class=p>)</span> <span class=o>/</span> <span class=n>CLOCKS_PER_SEC</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>printf</span><span class=p>(</span><span class=s>&#34;%.2f ns per query</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=mf>1e9</span> <span class=o>*</span> <span class=n>seconds</span> <span class=o>/</span> <span class=n>m</span><span class=p>);</span>
</span></span></code></pre></div><p>To measure <em>actual</em> latency, we need to introduce a dependency between the loop iterations so that the next query can&rsquo;t start before the previous one finishes:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=kt>int</span> <span class=n>last</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>m</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>last</span> <span class=o>=</span> <span class=n>lower_bound</span><span class=p>(</span><span class=n>q</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>^</span> <span class=n>last</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>checksum</span> <span class=o>^=</span> <span class=n>last</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>In terms of real latency, the speedup is not that impressive:</p><p><figure><img src=../img/search-relative-latency.svg><figcaption></figcaption></figure></p><p>A lot of the performance boost of the S+ tree comes from removing branching and minimizing memory requests, which allows overlapping the execution of more adjacent queries — apparently, around three on average.</p><p>Although nobody except maybe the HFT people cares about real latency, and everybody actually measures throughput even when using the word &ldquo;latency,&rdquo; this nuance is still something to take into account when predicting the possible speedup in user applications.</p><span class=anchor id=modifications-and-further-optimizations></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/data-structures/s-tree/#modifications-and-further-optimizations>#</a>Modifications and Further Optimizations</h3><p>To minimize the number of memory accesses during a query, we can increase the block size. To find the local lower bound in a 32-element node (spanning two cache lines and four AVX2 registers), we can use a <a href=https://github.com/sslotin/amh-code/blob/a74495a2c19dddc697f94221629c38fee09fa5ee/binsearch/bplus32.cc#L94>similar trick</a> that uses two <code>packs_epi32</code> and one <code>packs_epi16</code> to combine masks.</p><p>We can also try to use the cache more efficiently by controlling where each tree layer is stored in the cache hierarchy. We can do that by prefetching nodes to a <a href=/hpc/cpu-cache/prefetching/#software-prefetching>specific level</a> and using <a href=/hpc/cpu-cache/bandwidth/#bypassing-the-cache>non-temporal reads</a> during queries.</p><p>I implemented two versions of these optimizations: the one with a block size of 32 and the one where the last read is non-temporal. They don&rsquo;t improve the throughput:</p><p><figure><img src=../img/search-bplus-other.svg><figcaption></figcaption></figure></p><p>…but they do make the latency lower:</p><p><figure><img src=../img/search-latency-bplus.svg><figcaption></figcaption></figure></p><p>Ideas that I have not yet managed to implement but consider highly perspective are:</p><ul><li><p>Make the block size non-uniform. The motivation is that the slowdown from having one 32-element layer is less than from having two separate layers. Also, the root is often not full, so perhaps sometimes it should have only 8 keys or even just one key. Picking the optimal layer configuration for a given array size should remove the spikes from the relative speedup graph and make it look more like its upper envelope.</p><p>I know how to do it with code generation, but I went for a generic solution and tried to <a href=https://github.com/sslotin/amh-code/blob/main/binsearch/bplus-adaptive.cc>implement</a> it with the facilities of modern C++, but the compiler can&rsquo;t produce optimal code this way.</p></li><li><p>Group nodes with one or two generations of its descendants (~300 nodes / ~5k keys) so that they are close in memory — in the spirit of what <a href=http://kaldewey.com/pubs/FAST__SIGMOD10.pdf>FAST</a> calls hierarchical blocking. This reduces the severity of TLB misses and also may improve the latency as the memory controller may choose to keep the <a href=/hpc/cpu-cache/aos-soa/#ram-specific-timings>RAM row buffer</a> open, anticipating local reads.</p></li><li><p>Optionally use prefetching on some specific layers. Aside from to the $\frac{1}{17}$-th chance of it fetching the node we need, the hardware prefetcher may also get some of its neighbors for us if the data bus is not busy. It also has the same TLB and row buffer effects as with blocking.</p></li></ul><p>Other possible minor optimizations include:</p><ul><li>Permuting the nodes of the last layer as well — if we only need the index and not the value.</li><li>Reversing the order in which the layers are stored to left-to-right so that the first few layers are on the same page.</li><li>Rewriting the whole thing in assembly, as the compiler seems to struggle with pointer arithmetic.</li><li>Using <a href=/hpc/simd/masking>blending</a> instead of <code>packs</code>: you can odd-even shuffle node keys (<code>[1 3 5 7] [2 4 6 8]</code>), compare against the search key, and then blend the low 16 bits of the first register mask with the high 16 bits of the second. Blending is slightly faster on many architectures, and it may also help to alternate between packing and blending as they use different subsets of ports. (Thanks to Const-me from HackerNews for <a href="https://news.ycombinator.com/item?id=30381912">suggesting</a> it.)</li><li>Using <a href=/hpc/simd/shuffling/#shuffles-and-popcount>popcount</a> instead of <code>tzcnt</code>: the index <code>i</code> is equal to the number of keys less than <code>x</code>, so we can compare <code>x</code> against all keys, combine the vector mask any way we want, call <code>maskmov</code>, and then calculate the number of set bits with <code>popcnt</code>. This removes the need to store the keys in any particular order, which lets us skip the permutation step and also use this procedure on the last layer as well.</li><li>Defining the key $i$ as the <em>maximum</em> key in the subtree of child $i$ instead of the <em>minimum</em> key in the subtree of child $(i + 1)$. The correctness doesn&rsquo;t change, but this guarantees that the result will be stored in the last node we access (and not in the first element of the next neighbor node), which lets us fetch slightly fewer cache lines.</li></ul><p>Note that the current implementation is specific to AVX2 and may require some non-trivial changes to adapt to other platforms. It would be interesting to port it for Intel CPUs with AVX-512 and Arm CPUs with 128-bit NEON, which may require some <a href=https://github.com/WebAssembly/simd/issues/131>trickery</a> to work.</p><p>With these optimizations implemented, I wouldn&rsquo;t be surprised to see another 10-30% improvement and over 10x speedup over <code>std::lower_bound</code> on large arrays for some platforms.</p><span class=anchor id=as-a-dynamic-tree></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/data-structures/s-tree/#as-a-dynamic-tree>#</a>As a Dynamic Tree</h3><p>The comparison is even more favorable against <code>std::set</code> and other pointer-based trees. In our benchmark, we add the same elements (without measuring the time it takes to add them) and use the same lower bound queries, and the S+ tree is up to 30x faster:</p><p><figure><img src=../img/search-set-relative.svg><figcaption></figcaption></figure></p><p>This suggests that we can probably use this approach to also improve on <em>dynamic</em> search trees by a large margin.</p><p>To validate this hypothesis, I added an array of 17 indices for each node that point to where their children should be and used this array to descend the tree instead of the usual implicit numbering. This array is separate from the tree, not aligned, and isn&rsquo;t even on a hugepage — the only optimization we do is prefetch the first and the last pointer of a node.</p><p>I also added <a href=https://abseil.io/blog/20190812-btree>B-tree from Abseil</a> to the comparison, which is the only widely-used B-tree implementation I know of. It performs just slightly better than <code>std::lower_bound</code>, while the S+ tree with pointers is ~15x faster for large arrays:</p><p><figure><img src=../img/search-set-relative-all.svg><figcaption></figcaption></figure></p><p>Of course, this comparison is not fair, as implementing a dynamic search tree is a more high-dimensional problem.</p><p>We&rsquo;d also need to implement the update operation, which will not be that efficient, and for which we&rsquo;d need to sacrifice the fanout factor. But it still seems possible to implement a 10-20x faster <code>std::set</code> and a 3-5x faster <code>absl::btree_set</code>, depending on how you define &ldquo;faster&rdquo; — and this is one of the things we&rsquo;ll <a href=../b-tree>attempt to do next</a>.</p><span class=anchor id=acknowledgements></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/data-structures/s-tree/#acknowledgements>#</a>Acknowledgements</h3><p>This <a href=https://stackoverflow.com/questions/20616605/using-simd-avx-sse-for-tree-traversal>StackOverflow answer</a> by Cory Nelson is where I took the permuted 16-element search trick from.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://en.wikipedia.org/wiki/B-tree#Origin>Similar to B-trees</a>, &ldquo;the more you think about what the S in S-trees means, the better you understand S-trees.&rdquo;&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>If you need to work with <a href=/hpc/arithmetic/float>floating-point</a> keys, consider whether <code>upper_bound</code> will suffice — because if you need <code>lower_bound</code> specifically, then subtracting one or the machine epsilon from the search key doesn&rsquo;t work: you need to <a href=https://stackoverflow.com/questions/10160079/how-to-find-nearest-next-previous-double-value-numeric-limitsepsilon-for-give>get the previous representable number</a> instead. Aside from some corner cases, this essentially means reinterpreting its bits as an integer, subtracting one, and reinterpreting it back as a float (which magically works because of how <a href=/hpc/arithmetic/ieee-754>IEEE-754 floating-point numbers</a> are stored in memory).&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></article><div class=nextprev><div class=left><a href=http://jyang772.github.io/hugo-page/hpc/data-structures/binary-search/ id=prev-article>← Binary Search</a></div><div class=right><a href=http://jyang772.github.io/hugo-page/hpc/data-structures/b-tree/ id=next-article>Search Trees →</a></div></div></main><footer>Copyright 2021–2022 Sergey Slotin<br></footer></div></body></html>