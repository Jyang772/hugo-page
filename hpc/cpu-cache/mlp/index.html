<!doctype html><html lang=en-us><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-WBN59M8Y5S"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WBN59M8Y5S")</script><script type=text/javascript>(function(e,t,n,s,o,i,a){e[o]=e[o]||function(){(e[o].a=e[o].a||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym"),ym(53961409,"init",{clickmap:!0,trackLinks:!0,accurateTrackBounce:!0,webvisor:!0})</script><noscript><div><img src=https://mc.yandex.ru/watch/53961409 style=position:absolute;left:-9999px alt></div></noscript><meta charset=utf-8><link rel=stylesheet href=/hugo-page/style.min.a3a4a7a8e8602aaa85b7cb3d655edde028ac80d73f2a97389e2cbcf995dd672d.css integrity="sha256-o6SnqOhgKqqFt8s9ZV7d4CisgNc/Kpc4niy8+ZXdZy0="><link rel=stylesheet href=/syntax.css id=syntax-theme><link rel=stylesheet type=text/css href=https://tikzjax.com/v1/fonts.css><script src=https://tikzjax.com/v1/tikzjax.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js></script><script src=/scripts/lunr.stemmer.support.min.js></script><script src=/scripts/lunr.ru.min.js></script><script src=/scripts/lunr.multi.min.js></script><link rel=stylesheet id=theme><script>function toggleSidebar(){console.log("Toggling sidebar visibility");var e=document.getElementById("sidebar"),t=document.getElementById("wrapper");(e.classList.contains("sidebar-toggled")||window.getComputedStyle(e).display=="block")&&(e.classList.toggle("sidebar-hidden"),t.classList.toggle("sidebar-hidden")),e.classList.add("sidebar-toggled"),t.classList.add("sidebar-toggled")}function switchTheme(e){console.log("Changing theme:",e),document.getElementById("theme").href=e=="dark"?"/hugo-page/dark.min.b3ae1169831434b11b48de5b3e3210547eea6b7884c295ab0030cb973ea0dc49.css":"",document.getElementById("syntax-theme").href=e=="dark"?"/syntax-dark.css":"/syntax.css",localStorage.setItem("theme",e)}async function toggleSearch(){console.log("Toggling search");var e=document.getElementById("search");if(window.getComputedStyle(e).display=="none"?(e.style.display="block",window.scrollTo({top:0}),document.getElementById("search-bar").focus()):e.style.display="none",!index){console.log("Fetching index");const e=await fetch("/hugo-page/searchindex.json"),t=await e.json();index=lunr(function(){this.use(lunr.multiLanguage("en","ru")),this.field("title",{boost:5}),this.field("content",{boost:1}),t.forEach(function(e){this.add(e),articles.push(e)},this)}),console.log("Ready to search")}}var articles=[],index=void 0;function search(){var n,e=document.getElementById("search-bar").value,s=document.getElementById("search-results"),o=document.getElementById("search-count");if(e==""){s.innerHTML="",o.innerHTML="";return}n=index.search(e),o.innerHTML="Found <b>"+n.length+"</b> pages";let t="";for(const a in n){const i=articles[n[a].ref];t+='<li><a href="'+i.path+'">'+i.title+"</a> <p>";const s=i.content,o=80;if(s.includes(e)){const n=s.indexOf(e);n>o&&(t+="…"),t+=s.substring(n-o,n)+"<b>"+e+"</b>"+s.substring(n+e.length,n+e.length+o)}else t+=s.substring(0,o*2);t+="…</p></li>"}s.innerHTML=t}localStorage.getItem("theme")=="dark"&&switchTheme("dark"),window.addEventListener("load",function(){var e=document.getElementById("active-element");e&&e.scrollIntoView({block:"center"})}),window.addEventListener("scroll",function(){var e=document.getElementById("menu");window.scrollY<120?e.classList.remove("scrolled"):e.classList.add("scrolled")}),window.addEventListener("keydown",function(e){if(e.altKey)return;if(document.activeElement.tagName=="INPUT")return;e.key=="ArrowLeft"?document.getElementById("prev-article").click():e.key=="ArrowRight"&&document.getElementById("next-article").click()})</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})'></script><title>Memory-Level Parallelism - Algorithmica</title></head><body><nav id=sidebar><div class=title><a href=/>Algorithmica</a>
<span class=slash>/</span>
<a href=/hugo-page/hpc/ class=divisionAbbr>HPC</a></div><ul><li class=part>Performance Engineering</li><li><a href=/hugo-page/hpc/complexity/>Complexity Models</a></li><ol><li><a href=/hugo-page/hpc/complexity/hardware/>Modern Hardware</a></li><li><a href=/hugo-page/hpc/complexity/languages/>Programming Languages</a></li></ol><li><a href=/hugo-page/hpc/architecture/>Computer Architecture</a></li><ol><li><a href=/hugo-page/hpc/architecture/isa/>Instruction Set Architectures</a></li><li><a href=/hugo-page/hpc/architecture/assembly/>Assembly Language</a></li><li><a href=/hugo-page/hpc/architecture/loops/>Loops and Conditionals</a></li><li><a href=/hugo-page/hpc/architecture/functions/>Functions and Recursion</a></li><li><a href=/hugo-page/hpc/architecture/indirect/>Indirect Branching</a></li><li><a href=/hugo-page/hpc/architecture/layout/>Machine Code Layout</a></li></ol><li><a href=/hugo-page/hpc/pipelining/>Instruction-Level Parallelism</a></li><ol><li><a href=/hugo-page/hpc/pipelining/hazards/>Pipeline Hazards</a></li><li><a href=/hugo-page/hpc/pipelining/branching/>The Cost of Branching</a></li><li><a href=/hugo-page/hpc/pipelining/branchless/>Branchless Programming</a></li><li><a href=/hugo-page/hpc/pipelining/tables/>Instruction Tables</a></li><li><a href=/hugo-page/hpc/pipelining/throughput/>Throughput Computing</a></li></ol><li><a href=/hugo-page/hpc/compilation/>Compilation</a></li><ol><li><a href=/hugo-page/hpc/compilation/stages/>Stages of Compilation</a></li><li><a href=/hugo-page/hpc/compilation/flags/>Flags and Targets</a></li><li><a href=/hugo-page/hpc/compilation/situational/>Situational Optimizations</a></li><li><a href=/hugo-page/hpc/compilation/contracts/>Contract Programming</a></li><li><a href=/hugo-page/hpc/compilation/precalc/>Precomputation</a></li></ol><li><a href=/hugo-page/hpc/profiling/>Profiling</a></li><ol><li><a href=/hugo-page/hpc/profiling/instrumentation/>Instrumentation</a></li><li><a href=/hugo-page/hpc/profiling/events/>Statistical Profiling</a></li><li><a href=/hugo-page/hpc/profiling/simulation/>Program Simulation</a></li><li><a href=/hugo-page/hpc/profiling/mca/>Machine Code Analyzers</a></li><li><a href=/hugo-page/hpc/profiling/benchmarking/>Benchmarking</a></li><li><a href=/hugo-page/hpc/profiling/noise/>Getting Accurate Results</a></li></ol><li><a href=/hugo-page/hpc/arithmetic/>Arithmetic</a></li><ol><li><a href=/hugo-page/hpc/arithmetic/float/>Floating-Point Numbers</a></li><li><a href=/hugo-page/hpc/arithmetic/ieee-754/>IEEE 754 Floats</a></li><li><a href=/hugo-page/hpc/arithmetic/errors/>Rounding Errors</a></li><li><a href=/hugo-page/hpc/arithmetic/newton/>Newton's Method</a></li><li><a href=/hugo-page/hpc/arithmetic/rsqrt/>Fast Inverse Square Root</a></li><li><a href=/hugo-page/hpc/arithmetic/integer/>Integer Numbers</a></li><li><a href=/hugo-page/hpc/arithmetic/division/>Integer Division</a></li></ol><li><a href=/hugo-page/hpc/number-theory/>Number Theory</a></li><ol><li><a href=/hugo-page/hpc/number-theory/modular/>Modular Arithmetic</a></li><li><a href=/hugo-page/hpc/number-theory/exponentiation/>Binary Exponentiation</a></li><li><a href=/hugo-page/hpc/number-theory/euclid-extended/>Extended Euclidean Algorithm</a></li><li><a href=/hugo-page/hpc/number-theory/montgomery/>Montgomery Multiplication</a></li></ol><li><a href=/hugo-page/hpc/external-memory/>External Memory</a></li><ol><li><a href=/hugo-page/hpc/external-memory/hierarchy/>Memory Hierarchy</a></li><li><a href=/hugo-page/hpc/external-memory/virtual/>Virtual Memory</a></li><li><a href=/hugo-page/hpc/external-memory/model/>External Memory Model</a></li><li><a href=/hugo-page/hpc/external-memory/sorting/>External Sorting</a></li><li><a href=/hugo-page/hpc/external-memory/list-ranking/>List Ranking</a></li><li><a href=/hugo-page/hpc/external-memory/policies/>Eviction Policies</a></li><li><a href=/hugo-page/hpc/external-memory/oblivious/>Cache-Oblivious Algorithms</a></li><li><a href=/hugo-page/hpc/external-memory/locality/>Spatial and Temporal Locality</a></li></ol><li><a href=/hugo-page/hpc/cpu-cache/>RAM & CPU Caches</a></li><ol><li><a href=/hugo-page/hpc/cpu-cache/bandwidth/>Memory Bandwidth</a></li><li><a href=/hugo-page/hpc/cpu-cache/latency/>Memory Latency</a></li><li><a href=/hugo-page/hpc/cpu-cache/cache-lines/>Cache Lines</a></li><li><a href=/hugo-page/hpc/cpu-cache/sharing/>Memory Sharing</a></li><li><a href=/hugo-page/hpc/cpu-cache/mlp/ id=active-element>Memory-Level Parallelism</a></li><li><a href=/hugo-page/hpc/cpu-cache/prefetching/>Prefetching</a></li><li><a href=/hugo-page/hpc/cpu-cache/alignment/>Alignment and Packing</a></li><li><a href=/hugo-page/hpc/cpu-cache/pointers/>Pointer Alternatives</a></li><li><a href=/hugo-page/hpc/cpu-cache/associativity/>Cache Associativity</a></li><li><a href=/hugo-page/hpc/cpu-cache/paging/>Memory Paging</a></li><li><a href=/hugo-page/hpc/cpu-cache/aos-soa/>AoS and SoA</a></li></ol><li><a href=/hugo-page/hpc/simd/>SIMD Parallelism</a></li><ol><li><a href=/hugo-page/hpc/simd/intrinsics/>Intrinsics and Vector Types</a></li><li><a href=/hugo-page/hpc/simd/moving/>Moving Data</a></li><li><a href=/hugo-page/hpc/simd/reduction/>Reductions</a></li><li><a href=/hugo-page/hpc/simd/masking/>Masking and Blending</a></li><li><a href=/hugo-page/hpc/simd/shuffling/>In-Register Shuffles</a></li><li><a href=/hugo-page/hpc/simd/auto-vectorization/>Auto-Vectorization and SPMD</a></li></ol><li><a href=/hugo-page/hpc/algorithms/>Algorithms Case Studies</a></li><ol><li><a href=/hugo-page/hpc/algorithms/gcd/>Binary GCD</a></li><li><a href=/hugo-page/hpc/algorithms/factorization/>Integer Factorization</a></li><li><a href=/hugo-page/hpc/algorithms/argmin/>Argmin with SIMD</a></li><li><a href=/hugo-page/hpc/algorithms/prefix/>Prefix Sum with SIMD</a></li><li><a href=/hugo-page/hpc/algorithms/matmul/>Matrix Multiplication</a></li></ol><li><a href=/hugo-page/hpc/data-structures/>Data Structures Case Studies</a></li><ol><li><a href=/hugo-page/hpc/data-structures/binary-search/>Binary Search</a></li><li><a href=/hugo-page/hpc/data-structures/s-tree/>Static B-Trees</a></li><li><a href=/hugo-page/hpc/data-structures/b-tree/>Search Trees</a></li><li><a href=/hugo-page/hpc/data-structures/segment-trees/>Segment Trees</a></li></ol></ul></nav><div id=wrapper><menu id=menu><div class=left><a><img src=/icons/bars-solid.svg onclick=toggleSidebar() title='open table of contents'>
</a><a><img src=/icons/adjust-solid.svg style=position:relative;top:-1px onclick='switchTheme(localStorage.getItem("theme")=="dark"?"light":"dark")' title='dark theme'>
</a><a><img src=/icons/search-solid.svg onclick=toggleSearch() title=search></a></div><div class=title>Memory-Level Parallelism</div><div class=right><a onclick=window.print()><img src=/icons/print-solid.svg title=print>
</a><a href=https://prose.io/#algorithmica-org/algorithmica/edit/master//hpc%2fcpu-cache%2fmlp.md><img src=/icons/edit-solid.svg title=edit style=width:18px;position:relative;right:-2px;top:-1px>
</a><a href=https://github.com/algorithmica-org/algorithmica/blob/master//hpc/cpu-cache/mlp.md class=github-main><img src=/icons/github-brands.svg title='view on github'></a></div></menu><main><div id=search><input id=search-bar type=search placeholder='Search this book…' oninput=search()><div id=search-count></div><div id=search-results></div></div><header><h1>Memory-Level Parallelism</h1><div class=info></div></header><article><p>Memory requests can overlap in time: while you wait for a read request to complete, you can send a few others, which will be executed concurrently with it. This is the main reason why <a href=../bandwidth>linear iteration</a> is so much faster than <a href=../latency>pointer jumping</a>: the CPU knows which memory locations it needs to fetch next and sends memory requests far ahead of time.</p><p>The number of concurrent memory operations is large but limited, and it is different for different types of memory. When designing algorithms and especially data structures, you may want to know this number, as it limits the amount of parallelism your computation can achieve.</p><p>To find this limit theoretically for a specific memory type, you can multiply its latency (time to fetch a cache line) by its bandwidth (number of cache lines fetched per second), which gives you the average number of memory operations in progress:</p><p><figure><img src=../img/latency-bandwidth.svg><figcaption></figcaption></figure></p><p>The latency of the L1/L2 caches is small, so there is no need for a long pipeline of pending requests, but larger memory types can sustain up to 25-40 concurrent read operations.</p><span class=anchor id=direct-experiment></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/cpu-cache/mlp/#direct-experiment>#</a>Direct Experiment</h3><p>Let&rsquo;s try to measure available memory parallelism more directly by modifying our pointer chasing benchmark so that we loop around $D$ separate cycles in parallel instead of just one:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>M</span> <span class=o>=</span> <span class=n>N</span> <span class=o>/</span> <span class=n>D</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=n>p</span><span class=p>[</span><span class=n>M</span><span class=p>],</span> <span class=n>q</span><span class=p>[</span><span class=n>D</span><span class=p>][</span><span class=n>M</span><span class=p>];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>d</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>d</span> <span class=o>&lt;</span> <span class=n>D</span><span class=p>;</span> <span class=n>d</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>iota</span><span class=p>(</span><span class=n>p</span><span class=p>,</span> <span class=n>p</span> <span class=o>+</span> <span class=n>M</span><span class=p>,</span> <span class=mi>0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>random_shuffle</span><span class=p>(</span><span class=n>p</span><span class=p>,</span> <span class=n>p</span> <span class=o>+</span> <span class=n>M</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>k</span><span class=p>[</span><span class=n>d</span><span class=p>]</span> <span class=o>=</span> <span class=n>p</span><span class=p>[</span><span class=n>M</span> <span class=o>-</span> <span class=mi>1</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>M</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>k</span><span class=p>[</span><span class=n>d</span><span class=p>]</span> <span class=o>=</span> <span class=n>q</span><span class=p>[</span><span class=n>d</span><span class=p>][</span><span class=n>k</span><span class=p>[</span><span class=n>d</span><span class=p>]]</span> <span class=o>=</span> <span class=n>p</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>M</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>d</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>d</span> <span class=o>&lt;</span> <span class=n>D</span><span class=p>;</span> <span class=n>d</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>k</span><span class=p>[</span><span class=n>d</span><span class=p>]</span> <span class=o>=</span> <span class=n>q</span><span class=p>[</span><span class=n>d</span><span class=p>][</span><span class=n>k</span><span class=p>[</span><span class=n>d</span><span class=p>]];</span>
</span></span></code></pre></div><p>Fixing the sum of the cycle lengths constant at a few select sizes and trying different $D$, we get slightly different results:</p><p><figure><img src=../img/permutation-mlp.svg><figcaption></figcaption></figure></p><p>The L2 cache run is limited by ~6 concurrent operations, as predicted, but larger memory types all max out between 13 and 17. You can&rsquo;t make use of more memory lanes as there is a conflict over logical registers. When the number of lanes is fewer than the number of registers, you can issue just one read instruction per lane:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-nasm data-lang=nasm><span class=line><span class=cl><span class=nf>dec</span>     <span class=nb>edx</span>
</span></span><span class=line><span class=cl><span class=nf>movsx</span>   <span class=nb>rdi</span><span class=p>,</span> <span class=kt>DWORD</span> <span class=nv>PTR</span> <span class=nv>q</span><span class=p>[</span><span class=mi>0</span><span class=o>+</span><span class=nb>rdi</span><span class=o>*</span><span class=mi>4</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nf>movsx</span>   <span class=nb>rsi</span><span class=p>,</span> <span class=kt>DWORD</span> <span class=nv>PTR</span> <span class=nv>q</span><span class=p>[</span><span class=mi>1048576</span><span class=o>+</span><span class=nb>rsi</span><span class=o>*</span><span class=mi>4</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nf>movsx</span>   <span class=nb>rcx</span><span class=p>,</span> <span class=kt>DWORD</span> <span class=nv>PTR</span> <span class=nv>q</span><span class=p>[</span><span class=mi>2097152</span><span class=o>+</span><span class=nb>rcx</span><span class=o>*</span><span class=mi>4</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nf>movsx</span>   <span class=nb>rax</span><span class=p>,</span> <span class=kt>DWORD</span> <span class=nv>PTR</span> <span class=nv>q</span><span class=p>[</span><span class=mi>3145728</span><span class=o>+</span><span class=nb>rax</span><span class=o>*</span><span class=mi>4</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nf>jne</span>     <span class=nv>.L9</span>
</span></span></code></pre></div><p>But when it is over ~15, you have to use temporary memory storage:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-nasm data-lang=nasm><span class=line><span class=cl><span class=nf>mov</span>     <span class=nb>edx</span><span class=p>,</span> <span class=kt>DWORD</span> <span class=nv>PTR</span> <span class=nv>q</span><span class=p>[</span><span class=mi>0</span><span class=o>+</span><span class=nb>rdx</span><span class=o>*</span><span class=mi>4</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nf>mov</span>     <span class=kt>DWORD</span> <span class=nv>PTR</span> <span class=p>[</span><span class=nb>rbp</span><span class=o>-</span><span class=mi>128</span><span class=o>+</span><span class=nb>rax</span><span class=o>*</span><span class=mi>4</span><span class=p>],</span> <span class=nb>edx</span>
</span></span></code></pre></div><p>You don&rsquo;t always get to the maximum possible level of memory parallelism, but for most applications, a dozen concurrent requests are more than enough.</p></article><div class=nextprev><div class=left><a href=http://jyang772.github.io/hugo-page/hpc/cpu-cache/sharing/ id=prev-article>← Memory Sharing</a></div><div class=right><a href=http://jyang772.github.io/hugo-page/hpc/cpu-cache/prefetching/ id=next-article>Prefetching →</a></div></div></main><footer>Copyright 2021–2022 Sergey Slotin<br></footer></div></body></html>