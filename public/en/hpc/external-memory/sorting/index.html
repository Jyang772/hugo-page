<!doctype html><html lang=en-us><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-WBN59M8Y5S"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WBN59M8Y5S")</script><script type=text/javascript>(function(e,t,n,s,o,i,a){e[o]=e[o]||function(){(e[o].a=e[o].a||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym"),ym(53961409,"init",{clickmap:!0,trackLinks:!0,accurateTrackBounce:!0,webvisor:!0})</script><noscript><div><img src=https://mc.yandex.ru/watch/53961409 style=position:absolute;left:-9999px alt></div></noscript><meta charset=utf-8><link rel=stylesheet href=/style.min.a3a4a7a8e8602aaa85b7cb3d655edde028ac80d73f2a97389e2cbcf995dd672d.css integrity="sha256-o6SnqOhgKqqFt8s9ZV7d4CisgNc/Kpc4niy8+ZXdZy0="><link rel=stylesheet href=/syntax.css id=syntax-theme><link rel=stylesheet type=text/css href=https://tikzjax.com/v1/fonts.css><script src=https://tikzjax.com/v1/tikzjax.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js></script><script src=/scripts/lunr.stemmer.support.min.js></script><script src=/scripts/lunr.ru.min.js></script><script src=/scripts/lunr.multi.min.js></script><link rel=stylesheet id=theme><script>function toggleSidebar(){console.log("Toggling sidebar visibility");var e=document.getElementById("sidebar"),t=document.getElementById("wrapper");(e.classList.contains("sidebar-toggled")||window.getComputedStyle(e).display=="block")&&(e.classList.toggle("sidebar-hidden"),t.classList.toggle("sidebar-hidden")),e.classList.add("sidebar-toggled"),t.classList.add("sidebar-toggled")}function switchTheme(e){console.log("Changing theme:",e),document.getElementById("theme").href=e=="dark"?"/dark.min.b3ae1169831434b11b48de5b3e3210547eea6b7884c295ab0030cb973ea0dc49.css":"",document.getElementById("syntax-theme").href=e=="dark"?"/syntax-dark.css":"/syntax.css",localStorage.setItem("theme",e)}async function toggleSearch(){console.log("Toggling search");var e=document.getElementById("search");if(window.getComputedStyle(e).display=="none"?(e.style.display="block",window.scrollTo({top:0}),document.getElementById("search-bar").focus()):e.style.display="none",!index){console.log("Fetching index");const e=await fetch("/searchindex.json"),t=await e.json();index=lunr(function(){this.use(lunr.multiLanguage("en","ru")),this.field("title",{boost:5}),this.field("content",{boost:1}),t.forEach(function(e){this.add(e),articles.push(e)},this)}),console.log("Ready to search")}}var articles=[],index=void 0;function search(){var n,e=document.getElementById("search-bar").value,s=document.getElementById("search-results"),o=document.getElementById("search-count");if(e==""){s.innerHTML="",o.innerHTML="";return}n=index.search(e),o.innerHTML="Found <b>"+n.length+"</b> pages";let t="";for(const a in n){const i=articles[n[a].ref];t+='<li><a href="'+i.path+'">'+i.title+"</a> <p>";const s=i.content,o=80;if(s.includes(e)){const n=s.indexOf(e);n>o&&(t+="…"),t+=s.substring(n-o,n)+"<b>"+e+"</b>"+s.substring(n+e.length,n+e.length+o)}else t+=s.substring(0,o*2);t+="…</p></li>"}s.innerHTML=t}localStorage.getItem("theme")=="dark"&&switchTheme("dark"),window.addEventListener("load",function(){var e=document.getElementById("active-element");e&&e.scrollIntoView({block:"center"})}),window.addEventListener("scroll",function(){var e=document.getElementById("menu");window.scrollY<120?e.classList.remove("scrolled"):e.classList.add("scrolled")}),window.addEventListener("keydown",function(e){if(e.altKey)return;if(document.activeElement.tagName=="INPUT")return;e.key=="ArrowLeft"?document.getElementById("prev-article").click():e.key=="ArrowRight"&&document.getElementById("next-article").click()})</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})'></script><title>External Sorting - Algorithmica</title></head><body><nav id=sidebar><div class=title><a href=/>Algorithmica</a>
<span class=slash>/</span>
<a href=/hpc/ class=divisionAbbr>HPC</a></div><ul><li class=part>Performance Engineering</li><li><a href=/hpc/complexity/>Complexity Models</a></li><ol><li><a href=/hpc/complexity/hardware/>Modern Hardware</a></li><li><a href=/hpc/complexity/languages/>Programming Languages</a></li></ol><li><a href=/hpc/architecture/>Computer Architecture</a></li><ol><li><a href=/hpc/architecture/isa/>Instruction Set Architectures</a></li><li><a href=/hpc/architecture/assembly/>Assembly Language</a></li><li><a href=/hpc/architecture/loops/>Loops and Conditionals</a></li><li><a href=/hpc/architecture/functions/>Functions and Recursion</a></li><li><a href=/hpc/architecture/indirect/>Indirect Branching</a></li><li><a href=/hpc/architecture/layout/>Machine Code Layout</a></li></ol><li><a href=/hpc/pipelining/>Instruction-Level Parallelism</a></li><ol><li><a href=/hpc/pipelining/hazards/>Pipeline Hazards</a></li><li><a href=/hpc/pipelining/branching/>The Cost of Branching</a></li><li><a href=/hpc/pipelining/branchless/>Branchless Programming</a></li><li><a href=/hpc/pipelining/tables/>Instruction Tables</a></li><li><a href=/hpc/pipelining/throughput/>Throughput Computing</a></li></ol><li><a href=/hpc/compilation/>Compilation</a></li><ol><li><a href=/hpc/compilation/stages/>Stages of Compilation</a></li><li><a href=/hpc/compilation/flags/>Flags and Targets</a></li><li><a href=/hpc/compilation/situational/>Situational Optimizations</a></li><li><a href=/hpc/compilation/contracts/>Contract Programming</a></li><li><a href=/hpc/compilation/precalc/>Precomputation</a></li></ol><li><a href=/hpc/profiling/>Profiling</a></li><ol><li><a href=/hpc/profiling/instrumentation/>Instrumentation</a></li><li><a href=/hpc/profiling/events/>Statistical Profiling</a></li><li><a href=/hpc/profiling/simulation/>Program Simulation</a></li><li><a href=/hpc/profiling/mca/>Machine Code Analyzers</a></li><li><a href=/hpc/profiling/benchmarking/>Benchmarking</a></li><li><a href=/hpc/profiling/noise/>Getting Accurate Results</a></li></ol><li><a href=/hpc/arithmetic/>Arithmetic</a></li><ol><li><a href=/hpc/arithmetic/float/>Floating-Point Numbers</a></li><li><a href=/hpc/arithmetic/ieee-754/>IEEE 754 Floats</a></li><li><a href=/hpc/arithmetic/errors/>Rounding Errors</a></li><li><a href=/hpc/arithmetic/newton/>Newton's Method</a></li><li><a href=/hpc/arithmetic/rsqrt/>Fast Inverse Square Root</a></li><li><a href=/hpc/arithmetic/integer/>Integer Numbers</a></li><li><a href=/hpc/arithmetic/division/>Integer Division</a></li></ol><li><a href=/hpc/number-theory/>Number Theory</a></li><ol><li><a href=/hpc/number-theory/modular/>Modular Arithmetic</a></li><li><a href=/hpc/number-theory/exponentiation/>Binary Exponentiation</a></li><li><a href=/hpc/number-theory/euclid-extended/>Extended Euclidean Algorithm</a></li><li><a href=/hpc/number-theory/montgomery/>Montgomery Multiplication</a></li></ol><li><a href=/hpc/external-memory/>External Memory</a></li><ol><li><a href=/hpc/external-memory/hierarchy/>Memory Hierarchy</a></li><li><a href=/hpc/external-memory/virtual/>Virtual Memory</a></li><li><a href=/hpc/external-memory/model/>External Memory Model</a></li><li><a href=/hpc/external-memory/sorting/ id=active-element>External Sorting</a></li><li><a href=/hpc/external-memory/list-ranking/>List Ranking</a></li><li><a href=/hpc/external-memory/policies/>Eviction Policies</a></li><li><a href=/hpc/external-memory/oblivious/>Cache-Oblivious Algorithms</a></li><li><a href=/hpc/external-memory/locality/>Spatial and Temporal Locality</a></li></ol><li><a href=/hpc/cpu-cache/>RAM & CPU Caches</a></li><ol><li><a href=/hpc/cpu-cache/bandwidth/>Memory Bandwidth</a></li><li><a href=/hpc/cpu-cache/latency/>Memory Latency</a></li><li><a href=/hpc/cpu-cache/cache-lines/>Cache Lines</a></li><li><a href=/hpc/cpu-cache/sharing/>Memory Sharing</a></li><li><a href=/hpc/cpu-cache/mlp/>Memory-Level Parallelism</a></li><li><a href=/hpc/cpu-cache/prefetching/>Prefetching</a></li><li><a href=/hpc/cpu-cache/alignment/>Alignment and Packing</a></li><li><a href=/hpc/cpu-cache/pointers/>Pointer Alternatives</a></li><li><a href=/hpc/cpu-cache/associativity/>Cache Associativity</a></li><li><a href=/hpc/cpu-cache/paging/>Memory Paging</a></li><li><a href=/hpc/cpu-cache/aos-soa/>AoS and SoA</a></li></ol><li><a href=/hpc/simd/>SIMD Parallelism</a></li><ol><li><a href=/hpc/simd/intrinsics/>Intrinsics and Vector Types</a></li><li><a href=/hpc/simd/moving/>Moving Data</a></li><li><a href=/hpc/simd/reduction/>Reductions</a></li><li><a href=/hpc/simd/masking/>Masking and Blending</a></li><li><a href=/hpc/simd/shuffling/>In-Register Shuffles</a></li><li><a href=/hpc/simd/auto-vectorization/>Auto-Vectorization and SPMD</a></li></ol><li><a href=/hpc/algorithms/>Algorithms Case Studies</a></li><ol><li><a href=/hpc/algorithms/gcd/>Binary GCD</a></li><li><a href=/hpc/algorithms/factorization/>Integer Factorization</a></li><li><a href=/hpc/algorithms/argmin/>Argmin with SIMD</a></li><li><a href=/hpc/algorithms/prefix/>Prefix Sum with SIMD</a></li><li><a href=/hpc/algorithms/matmul/>Matrix Multiplication</a></li></ol><li><a href=/hpc/data-structures/>Data Structures Case Studies</a></li><ol><li><a href=/hpc/data-structures/binary-search/>Binary Search</a></li><li><a href=/hpc/data-structures/s-tree/>Static B-Trees</a></li><li><a href=/hpc/data-structures/b-tree/>Search Trees</a></li><li><a href=/hpc/data-structures/segment-trees/>Segment Trees</a></li></ol></ul></nav><div id=wrapper><menu id=menu><div class=left><a><img src=/icons/bars-solid.svg onclick=toggleSidebar() title='open table of contents'>
</a><a><img src=/icons/adjust-solid.svg style=position:relative;top:-1px onclick='switchTheme(localStorage.getItem("theme")=="dark"?"light":"dark")' title='dark theme'>
</a><a><img src=/icons/search-solid.svg onclick=toggleSearch() title=search></a></div><div class=title>External Sorting</div><div class=right><a onclick=window.print()><img src=/icons/print-solid.svg title=print>
</a><a href=https://prose.io/#algorithmica-org/algorithmica/edit/master//hpc%2fexternal-memory%2fsorting.md><img src=/icons/edit-solid.svg title=edit style=width:18px;position:relative;right:-2px;top:-1px>
</a><a href=https://github.com/algorithmica-org/algorithmica/blob/master//hpc/external-memory/sorting.md class=github-main><img src=/icons/github-brands.svg title='view on github'></a></div></menu><main><div id=search><input id=search-bar type=search placeholder='Search this book…' oninput=search()><div id=search-count></div><div id=search-results></div></div><header><h1>External Sorting</h1><div class=info></div></header><article><p>Now, let&rsquo;s try to design some actually useful algorithms for the new <a href=../model>external memory model</a>. Our goal in this section is to slowly build up more complex things and eventually get to <em>external sorting</em> and its interesting applications.</p><p>The algorithm will be based on the standard merge sorting algorithm, so we need to derive its main primitive first.</p><span class=anchor id=merge></span><h3><a class=anchor-link href=https://en.algorithmica.org/hpc/external-memory/sorting/#merge>#</a>Merge</h3><p><strong>Problem.</strong> Given two sorted arrays $a$ and $b$ of lengths $N$ and $M$, produce a single sorted array $c$ of length $N + M$ containing all of their elements.</p><p>The standard two-pointer technique for merging sorted arrays looks like this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=kt>void</span> <span class=nf>merge</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=kt>int</span> <span class=o>*</span><span class=n>b</span><span class=p>,</span> <span class=kt>int</span> <span class=o>*</span><span class=n>c</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>,</span> <span class=kt>int</span> <span class=n>m</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>,</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>k</span> <span class=o>&lt;</span> <span class=n>n</span> <span class=o>+</span> <span class=n>m</span><span class=p>;</span> <span class=n>k</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span> <span class=o>&amp;&amp;</span> <span class=p>(</span><span class=n>j</span> <span class=o>==</span> <span class=n>m</span> <span class=o>||</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>&lt;</span> <span class=n>b</span><span class=p>[</span><span class=n>j</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>            <span class=n>c</span><span class=p>[</span><span class=n>k</span><span class=p>]</span> <span class=o>=</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=o>++</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span>
</span></span><span class=line><span class=cl>            <span class=n>c</span><span class=p>[</span><span class=n>k</span><span class=p>]</span> <span class=o>=</span> <span class=n>b</span><span class=p>[</span><span class=n>j</span><span class=o>++</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>In terms of memory operations, we just linearly read all elements of $a$ and $b$ and linearly write all elements of $c$. Since these reads and writes can be buffered, it works in $SCAN(N+M)$ I/O operations.</p><p>So far the examples have been simple, and their analysis doesn&rsquo;t differ too much from the RAM model, except that we divide the final answer by the block size $B$. But here is a case where this is not so.</p><p><strong>$k$-way merging.</strong> Consider the modification of this algorithm where we need to merge not just two arrays, but $k$ arrays of total size $N$ — by likewise looking at $k$ values, choosing the minimum between them, writing it into $c$, and incrementing one of the iterators.</p><p>In the standard RAM model, the asymptotic complexity would be multiplied $k$, since we would need to perform $O(k)$ comparisons to fill each next element. But in the external memory model, since everything we do in-memory doesn&rsquo;t cost us anything, its asymptotic complexity would not change as long as we can fit $(k+1)$ full blocks in memory, that is, if $k = O(\frac{M}{B})$.</p><p>Remember <a href=../model>the $M \gg B$ assumption</a> when we introduced the computational model? If we have $M \geq B^{1+ε}$ for $\epsilon > 0$, then we can fit any sub-polynomial number of blocks in memory, certainly including $O(\frac{M}{B})$. This condition is called <em>tall cache assumption</em>, and it is usually required in many other external memory algorithms.</p><span class=anchor id=merge-sorting></span><h3><a class=anchor-link href=https://en.algorithmica.org/hpc/external-memory/sorting/#merge-sorting>#</a>Merge Sorting</h3><p>The &ldquo;normal&rdquo; complexity of the standard mergesort algorithm is $O(N \log_2 N)$: on each of its $O(\log_2 N)$ &ldquo;layers,&rdquo; the algorithms need to go through all $N$ elements in total and merge them in linear time.</p><p>In the external memory model, when we read a block of size $M$, we can sort its elements &ldquo;for free,&rdquo; since they are already in memory. This way we can split the arrays into $O(\frac{N}{M})$ blocks of consecutive elements and sort them separately as the base step, and only then merge them.</p><p><figure><img src=../img/k-way.png><figcaption></figcaption></figure></p><p>This effectively means that, in terms of I/O operations, the first $O(\log M)$ layers of mergesort are free, and there are only $O(\log_2 \frac{N}{M})$ non-zero-cost layers, each mergeable in $O(\frac{N}{B})$ IOPS in total. This brings total I/O complexity to</p>$$
O\left(\frac{N}{B} \log_2 \frac{N}{M}\right)
$$<p>This is quite fast. If we have 1GB of memory and 10GB of data, this essentially means that we need a little bit more than 3 times the effort than just reading the data to sort it. Interestingly enough, we can do better.</p><span class=anchor id=k-way-mergesort></span><h3><a class=anchor-link href=https://en.algorithmica.org/hpc/external-memory/sorting/#k-way-mergesort>#</a>$k$-way Mergesort</h3><p>Half of a page ago we have learned that in the external memory model, we can merge $k$ arrays just as easily as two arrays — at the cost of reading them. Why don&rsquo;t we apply this fact here?</p><p>Let&rsquo;s sort each block of size $M$ in-memory just as we did before, but during each merge stage, we will split sorted blocks not just in pairs to be merged, but take as many blocks we can fit into our memory during a $k$-way merge. This way the height of the merge tree would be greatly reduced, while each layer would still be done in $O(\frac{N}{B})$ IOPS.</p><p>How many sorted arrays can we merge at once? Exactly $k = \frac{M}{B}$, since we need memory for one block for each array. Since the total number of layers will be reduced to $\log_{\frac{M}{B}} \frac{N}{M}$, the total complexity will be reduced to</p>$$
SORT(N) \stackrel{\text{def}}{=} O\left(\frac{N}{B} \log_{\frac{M}{B}} \frac{N}{M} \right)
$$<p>Note that, in our example, we have 10GB of data, 1GB of memory, and the block size is around 1MB for HDD. This makes $\frac{M}{B} = 1000$ and $\frac{N}{M} = 10$, and so the logarithm is less than one (namely, $\log_{1000} 10 = \frac{1}{3}$). Of course, we can&rsquo;t sort an array faster than reading it, so this analysis applies to the cases when we have a very large dataset, small memory, and/or large block sizes, which rarely happens in real life these days.</p><span class=anchor id=practical-implementation></span><h3><a class=anchor-link href=https://en.algorithmica.org/hpc/external-memory/sorting/#practical-implementation>#</a>Practical Implementation</h3><p>Under more realistic constraints, instead of using $\log_{\frac{M}{B}} \frac{N}{M}$ layers, we can use just two: one for sorting data in blocks of $M$ elements, and another one for merging all of them at once. This way, from the I/O operations perspective, we just loop around our dataset twice. And with a gigabyte of RAM and a block size of 1MB, this way can sort arrays up to a terabyte in size.</p><p>Here is how the first phase looks in C++. This program opens a multi-gigabyte binary file with unsorted integers, reads it in blocks of 256MB, sorts them in memory, and then writes them back in files named <code>part-000.bin</code>, <code>part-001.bin</code>, <code>part-002.bin</code>, and so on:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>B</span> <span class=o>=</span> <span class=p>(</span><span class=mi>1</span><span class=o>&lt;&lt;</span><span class=mi>20</span><span class=p>)</span> <span class=o>/</span> <span class=mi>4</span><span class=p>;</span> <span class=c1>// 1 MB blocks of integers
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>const</span> <span class=kt>int</span> <span class=n>M</span> <span class=o>=</span> <span class=p>(</span><span class=mi>1</span><span class=o>&lt;&lt;</span><span class=mi>28</span><span class=p>)</span> <span class=o>/</span> <span class=mi>4</span><span class=p>;</span> <span class=c1>// available memory
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=n>FILE</span> <span class=o>*</span><span class=n>input</span> <span class=o>=</span> <span class=n>fopen</span><span class=p>(</span><span class=s>&#34;input.bin&#34;</span><span class=p>,</span> <span class=s>&#34;rb&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>FILE</span><span class=o>*&gt;</span> <span class=n>parts</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>while</span> <span class=p>(</span><span class=nb>true</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>static</span> <span class=kt>int</span> <span class=n>part</span><span class=p>[</span><span class=n>M</span><span class=p>];</span> <span class=c1>// better delete it right after
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>int</span> <span class=n>n</span> <span class=o>=</span> <span class=n>fread</span><span class=p>(</span><span class=n>part</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=n>M</span><span class=p>,</span> <span class=n>input</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>n</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// sort a block in-memory
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>std</span><span class=o>::</span><span class=n>sort</span><span class=p>(</span><span class=n>part</span><span class=p>,</span> <span class=n>part</span> <span class=o>+</span> <span class=n>n</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=kt>char</span> <span class=n>fpart</span><span class=p>[</span><span class=k>sizeof</span> <span class=s>&#34;part-999.bin&#34;</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=n>sprintf</span><span class=p>(</span><span class=n>fpart</span><span class=p>,</span> <span class=s>&#34;part-%03d.bin&#34;</span><span class=p>,</span> <span class=n>parts</span><span class=p>.</span><span class=n>size</span><span class=p>());</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Writing %d elements into %s...</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>fpart</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>FILE</span> <span class=o>*</span><span class=n>file</span> <span class=o>=</span> <span class=n>fopen</span><span class=p>(</span><span class=n>fpart</span><span class=p>,</span> <span class=s>&#34;wb&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>fwrite</span><span class=p>(</span><span class=n>part</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>file</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>fclose</span><span class=p>(</span><span class=n>file</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>file</span> <span class=o>=</span> <span class=n>fopen</span><span class=p>(</span><span class=n>fpart</span><span class=p>,</span> <span class=s>&#34;rb&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>parts</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>file</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fclose</span><span class=p>(</span><span class=n>input</span><span class=p>);</span>
</span></span></code></pre></div><p>What is left now is to merge them together. The bandwidth of modern HDDs can be quite high, and there may be a lot of parts to merge, so the I/O efficiency of this stage is not our only concern: we also need a faster way to merge $k$ arrays than by finding minima with $O(k)$ comparisons. We can do that in $O(\log k)$ time per element if we maintain a min-heap for these $k$ elements, in a manner almost identical to heapsort.</p><p>Here is how to implement it. First, we are going to need a heap (<code>priority_queue</code> in C++):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>struct</span> <span class=nc>Pointer</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>key</span><span class=p>,</span> <span class=n>part</span><span class=p>;</span> <span class=c1>// the element itself and the number of its part
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl>    <span class=kt>bool</span> <span class=k>operator</span><span class=o>&lt;</span><span class=p>(</span><span class=k>const</span> <span class=n>Pointer</span><span class=o>&amp;</span> <span class=n>other</span><span class=p>)</span> <span class=k>const</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>key</span> <span class=o>&gt;</span> <span class=n>other</span><span class=p>.</span><span class=n>key</span><span class=p>;</span> <span class=c1>// std::priority_queue is a max-heap by default
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>};</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>std</span><span class=o>::</span><span class=n>priority_queue</span><span class=o>&lt;</span><span class=n>Pointer</span><span class=o>&gt;</span> <span class=n>q</span><span class=p>;</span>
</span></span></code></pre></div><p>Then, we need to allocate and fill the buffers:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>nparts</span> <span class=o>=</span> <span class=n>parts</span><span class=p>.</span><span class=n>size</span><span class=p>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>auto</span> <span class=n>buffers</span> <span class=o>=</span> <span class=k>new</span> <span class=kt>int</span><span class=p>[</span><span class=n>nparts</span><span class=p>][</span><span class=n>B</span><span class=p>];</span> <span class=c1>// buffers for each part
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>int</span> <span class=o>*</span><span class=n>l</span> <span class=o>=</span> <span class=k>new</span> <span class=kt>int</span><span class=p>[</span><span class=n>nparts</span><span class=p>],</span>          <span class=c1>// # of already processed buffer elements
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=o>*</span><span class=n>r</span> <span class=o>=</span> <span class=k>new</span> <span class=kt>int</span><span class=p>[</span><span class=n>nparts</span><span class=p>];</span>          <span class=c1>// buffer size (in case it isn&#39;t full)
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=c1>// now we add fill the buffer for each part and add their elements to the heap
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>part</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>part</span> <span class=o>&lt;</span> <span class=n>nparts</span><span class=p>;</span> <span class=n>part</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>l</span><span class=p>[</span><span class=n>part</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span> <span class=c1>// if the element is in the heap, we also consider it &#34;processed&#34;
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>r</span><span class=p>[</span><span class=n>part</span><span class=p>]</span> <span class=o>=</span> <span class=n>fread</span><span class=p>(</span><span class=n>buffers</span><span class=p>[</span><span class=n>part</span><span class=p>],</span> <span class=mi>4</span><span class=p>,</span> <span class=n>B</span><span class=p>,</span> <span class=n>parts</span><span class=p>[</span><span class=n>part</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>    <span class=n>q</span><span class=p>.</span><span class=n>push</span><span class=p>({</span><span class=n>buffers</span><span class=p>[</span><span class=n>part</span><span class=p>][</span><span class=mi>0</span><span class=p>],</span> <span class=n>part</span><span class=p>});</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Now we just need to pop elements from the heap into the result file until it is empty, carefully writing and reading elements in batches:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>FILE</span> <span class=o>*</span><span class=n>output</span> <span class=o>=</span> <span class=n>fopen</span><span class=p>(</span><span class=s>&#34;output.bin&#34;</span><span class=p>,</span> <span class=s>&#34;w&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=n>outbuffer</span><span class=p>[</span><span class=n>B</span><span class=p>];</span> <span class=c1>// the output buffer
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>int</span> <span class=n>buffered</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=c1>// number of elements in it
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=k>while</span> <span class=p>(</span><span class=o>!</span><span class=n>q</span><span class=p>.</span><span class=n>empty</span><span class=p>())</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>auto</span> <span class=p>[</span><span class=n>key</span><span class=p>,</span> <span class=n>part</span><span class=p>]</span> <span class=o>=</span> <span class=n>q</span><span class=p>.</span><span class=n>top</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=n>q</span><span class=p>.</span><span class=n>pop</span><span class=p>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// write the minimum to the output buffer
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>outbuffer</span><span class=p>[</span><span class=n>buffered</span><span class=o>++</span><span class=p>]</span> <span class=o>=</span> <span class=n>key</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=c1>// check if it needs to be committed to the file
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>if</span> <span class=p>(</span><span class=n>buffered</span> <span class=o>==</span> <span class=n>B</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>fwrite</span><span class=p>(</span><span class=n>outbuffer</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=n>B</span><span class=p>,</span> <span class=n>output</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>buffered</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// fetch a new block of that part if needed
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>if</span> <span class=p>(</span><span class=n>l</span><span class=p>[</span><span class=n>part</span><span class=p>]</span> <span class=o>==</span> <span class=n>r</span><span class=p>[</span><span class=n>part</span><span class=p>])</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>r</span><span class=p>[</span><span class=n>part</span><span class=p>]</span> <span class=o>=</span> <span class=n>fread</span><span class=p>(</span><span class=n>buffers</span><span class=p>[</span><span class=n>part</span><span class=p>],</span> <span class=mi>4</span><span class=p>,</span> <span class=n>B</span><span class=p>,</span> <span class=n>parts</span><span class=p>[</span><span class=n>part</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>        <span class=n>l</span><span class=p>[</span><span class=n>part</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// read a new element from that part unless we&#39;ve already processed all of it
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>if</span> <span class=p>(</span><span class=n>l</span><span class=p>[</span><span class=n>part</span><span class=p>]</span> <span class=o>&lt;</span> <span class=n>r</span><span class=p>[</span><span class=n>part</span><span class=p>])</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>q</span><span class=p>.</span><span class=n>push</span><span class=p>({</span><span class=n>buffers</span><span class=p>[</span><span class=n>part</span><span class=p>][</span><span class=n>l</span><span class=p>[</span><span class=n>part</span><span class=p>]],</span> <span class=n>part</span><span class=p>});</span>
</span></span><span class=line><span class=cl>        <span class=n>l</span><span class=p>[</span><span class=n>part</span><span class=p>]</span><span class=o>++</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// write what&#39;s left of the output buffer
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>fwrite</span><span class=p>(</span><span class=n>outbuffer</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=n>buffered</span><span class=p>,</span> <span class=n>output</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>//clean up
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>delete</span><span class=p>[]</span> <span class=n>buffers</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=n>FILE</span> <span class=o>*</span><span class=nl>file</span> <span class=p>:</span> <span class=n>parts</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>fclose</span><span class=p>(</span><span class=n>file</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>fclose</span><span class=p>(</span><span class=n>output</span><span class=p>);</span>
</span></span></code></pre></div><p>This implementation is not particularly effective or safe-looking (well, this is basically plain C), but is a good educational example of how to work with low-level memory APIs.</p><span class=anchor id=joining></span><h3><a class=anchor-link href=https://en.algorithmica.org/hpc/external-memory/sorting/#joining>#</a>Joining</h3><p>Sorting is mainly used not by itself, but as an intermediate step for other operations. One important real-world use case of external sorting is joining (as in &ldquo;SQL join&rdquo;), used in databases and other data processing applications.</p><p><strong>Problem.</strong> Given two lists of tuples $(x_i, a_{x_i})$ and $(y_i, b_{y_i})$, output a list $(k, a_{x_k}, b_{y_k})$ such that $x_k = y_k$</p><p>The optimal solution would be to sort the two lists and then use the standard two-pointer technique to merge them. The I/O complexity here would be the same as sorting, and just $O(\frac{N}{B})$ if the arrays are already sorted. This is why most data processing applications (databases, MapReduce systems) like to keep their tables at least partially sorted.</p><p><strong>Other approaches.</strong> Note that this analysis is only applicable in the external memory setting — that is, if you don&rsquo;t have the memory to read the entire dataset. In the real world, alternative methods may be faster.</p><p>The simplest of them is probably <em>hash join</em>, which goes something like this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>join</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>d</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>(</span><span class=n>a</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span> <span class=ow>in</span> <span class=n>b</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>d</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>yield</span> <span class=n>d</span><span class=p>[</span><span class=n>x</span><span class=p>]</span>
</span></span></code></pre></div><p>In external memory, joining two lists with a hash table would be unfeasible, as it would involve doing $O(M)$ block reads, even though only one element is used in each of them.</p><p>Another method is to use alternative sorting algorithms such as radix sort. In particular, radix sort would work in $O(\frac{N}{B} \cdot w)$ block reads if enough memory is available to maintain buffers for all possible keys, and it could be faster in the case of small keys and large datasets.</p></article><div class=nextprev><div class=left><a href=https://en.algorithmica.org/hpc/external-memory/model/ id=prev-article>← External Memory Model</a></div><div class=right><a href=https://en.algorithmica.org/hpc/external-memory/list-ranking/ id=next-article>List Ranking →</a></div></div></main><footer>Copyright 2021–2022 Sergey Slotin<br></footer></div></body></html>