<!doctype html><html lang=en-us><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-WBN59M8Y5S"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WBN59M8Y5S")</script><script type=text/javascript>(function(e,t,n,s,o,i,a){e[o]=e[o]||function(){(e[o].a=e[o].a||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym"),ym(53961409,"init",{clickmap:!0,trackLinks:!0,accurateTrackBounce:!0,webvisor:!0})</script><noscript><div><img src=https://mc.yandex.ru/watch/53961409 style=position:absolute;left:-9999px alt></div></noscript><meta charset=utf-8><link rel=stylesheet href=/hugo-page/style.min.a3a4a7a8e8602aaa85b7cb3d655edde028ac80d73f2a97389e2cbcf995dd672d.css integrity="sha256-o6SnqOhgKqqFt8s9ZV7d4CisgNc/Kpc4niy8+ZXdZy0="><link rel=stylesheet href=/syntax.css id=syntax-theme><link rel=stylesheet type=text/css href=https://tikzjax.com/v1/fonts.css><script src=https://tikzjax.com/v1/tikzjax.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js></script><script src=/scripts/lunr.stemmer.support.min.js></script><script src=/scripts/lunr.ru.min.js></script><script src=/scripts/lunr.multi.min.js></script><link rel=stylesheet id=theme><script>function toggleSidebar(){console.log("Toggling sidebar visibility");var e=document.getElementById("sidebar"),t=document.getElementById("wrapper");(e.classList.contains("sidebar-toggled")||window.getComputedStyle(e).display=="block")&&(e.classList.toggle("sidebar-hidden"),t.classList.toggle("sidebar-hidden")),e.classList.add("sidebar-toggled"),t.classList.add("sidebar-toggled")}function switchTheme(e){console.log("Changing theme:",e),document.getElementById("theme").href=e=="dark"?"/hugo-page/dark.min.b3ae1169831434b11b48de5b3e3210547eea6b7884c295ab0030cb973ea0dc49.css":"",document.getElementById("syntax-theme").href=e=="dark"?"/syntax-dark.css":"/syntax.css",localStorage.setItem("theme",e)}async function toggleSearch(){console.log("Toggling search");var e=document.getElementById("search");if(window.getComputedStyle(e).display=="none"?(e.style.display="block",window.scrollTo({top:0}),document.getElementById("search-bar").focus()):e.style.display="none",!index){console.log("Fetching index");const e=await fetch("/searchindex.json"),t=await e.json();index=lunr(function(){this.use(lunr.multiLanguage("en","ru")),this.field("title",{boost:5}),this.field("content",{boost:1}),t.forEach(function(e){this.add(e),articles.push(e)},this)}),console.log("Ready to search")}}var articles=[],index=void 0;function search(){var n,e=document.getElementById("search-bar").value,s=document.getElementById("search-results"),o=document.getElementById("search-count");if(e==""){s.innerHTML="",o.innerHTML="";return}n=index.search(e),o.innerHTML="Found <b>"+n.length+"</b> pages";let t="";for(const a in n){const i=articles[n[a].ref];t+='<li><a href="'+i.path+'">'+i.title+"</a> <p>";const s=i.content,o=80;if(s.includes(e)){const n=s.indexOf(e);n>o&&(t+="…"),t+=s.substring(n-o,n)+"<b>"+e+"</b>"+s.substring(n+e.length,n+e.length+o)}else t+=s.substring(0,o*2);t+="…</p></li>"}s.innerHTML=t}localStorage.getItem("theme")=="dark"&&switchTheme("dark"),window.addEventListener("load",function(){var e=document.getElementById("active-element");e&&e.scrollIntoView({block:"center"})}),window.addEventListener("scroll",function(){var e=document.getElementById("menu");window.scrollY<120?e.classList.remove("scrolled"):e.classList.add("scrolled")}),window.addEventListener("keydown",function(e){if(e.altKey)return;if(document.activeElement.tagName=="INPUT")return;e.key=="ArrowLeft"?document.getElementById("prev-article").click():e.key=="ArrowRight"&&document.getElementById("next-article").click()})</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})'></script><title>Montgomery Multiplication - Algorithmica</title></head><body><nav id=sidebar><div class=title><a href=/>Algorithmica</a>
<span class=slash>/</span>
<a href=/hugo-page/hpc/ class=divisionAbbr>HPC</a></div><ul><li class=part>Performance Engineering</li><li><a href=/hugo-page/hpc/complexity/>Complexity Models</a></li><ol><li><a href=/hugo-page/hpc/complexity/hardware/>Modern Hardware</a></li><li><a href=/hugo-page/hpc/complexity/languages/>Programming Languages</a></li></ol><li><a href=/hugo-page/hpc/architecture/>Computer Architecture</a></li><ol><li><a href=/hugo-page/hpc/architecture/isa/>Instruction Set Architectures</a></li><li><a href=/hugo-page/hpc/architecture/assembly/>Assembly Language</a></li><li><a href=/hugo-page/hpc/architecture/loops/>Loops and Conditionals</a></li><li><a href=/hugo-page/hpc/architecture/functions/>Functions and Recursion</a></li><li><a href=/hugo-page/hpc/architecture/indirect/>Indirect Branching</a></li><li><a href=/hugo-page/hpc/architecture/layout/>Machine Code Layout</a></li></ol><li><a href=/hugo-page/hpc/pipelining/>Instruction-Level Parallelism</a></li><ol><li><a href=/hugo-page/hpc/pipelining/hazards/>Pipeline Hazards</a></li><li><a href=/hugo-page/hpc/pipelining/branching/>The Cost of Branching</a></li><li><a href=/hugo-page/hpc/pipelining/branchless/>Branchless Programming</a></li><li><a href=/hugo-page/hpc/pipelining/tables/>Instruction Tables</a></li><li><a href=/hugo-page/hpc/pipelining/throughput/>Throughput Computing</a></li></ol><li><a href=/hugo-page/hpc/compilation/>Compilation</a></li><ol><li><a href=/hugo-page/hpc/compilation/stages/>Stages of Compilation</a></li><li><a href=/hugo-page/hpc/compilation/flags/>Flags and Targets</a></li><li><a href=/hugo-page/hpc/compilation/situational/>Situational Optimizations</a></li><li><a href=/hugo-page/hpc/compilation/contracts/>Contract Programming</a></li><li><a href=/hugo-page/hpc/compilation/precalc/>Precomputation</a></li></ol><li><a href=/hugo-page/hpc/profiling/>Profiling</a></li><ol><li><a href=/hugo-page/hpc/profiling/instrumentation/>Instrumentation</a></li><li><a href=/hugo-page/hpc/profiling/events/>Statistical Profiling</a></li><li><a href=/hugo-page/hpc/profiling/simulation/>Program Simulation</a></li><li><a href=/hugo-page/hpc/profiling/mca/>Machine Code Analyzers</a></li><li><a href=/hugo-page/hpc/profiling/benchmarking/>Benchmarking</a></li><li><a href=/hugo-page/hpc/profiling/noise/>Getting Accurate Results</a></li></ol><li><a href=/hugo-page/hpc/arithmetic/>Arithmetic</a></li><ol><li><a href=/hugo-page/hpc/arithmetic/float/>Floating-Point Numbers</a></li><li><a href=/hugo-page/hpc/arithmetic/ieee-754/>IEEE 754 Floats</a></li><li><a href=/hugo-page/hpc/arithmetic/errors/>Rounding Errors</a></li><li><a href=/hugo-page/hpc/arithmetic/newton/>Newton's Method</a></li><li><a href=/hugo-page/hpc/arithmetic/rsqrt/>Fast Inverse Square Root</a></li><li><a href=/hugo-page/hpc/arithmetic/integer/>Integer Numbers</a></li><li><a href=/hugo-page/hpc/arithmetic/division/>Integer Division</a></li></ol><li><a href=/hugo-page/hpc/number-theory/>Number Theory</a></li><ol><li><a href=/hugo-page/hpc/number-theory/modular/>Modular Arithmetic</a></li><li><a href=/hugo-page/hpc/number-theory/exponentiation/>Binary Exponentiation</a></li><li><a href=/hugo-page/hpc/number-theory/euclid-extended/>Extended Euclidean Algorithm</a></li><li><a href=/hugo-page/hpc/number-theory/montgomery/ id=active-element>Montgomery Multiplication</a></li></ol><li><a href=/hugo-page/hpc/external-memory/>External Memory</a></li><ol><li><a href=/hugo-page/hpc/external-memory/hierarchy/>Memory Hierarchy</a></li><li><a href=/hugo-page/hpc/external-memory/virtual/>Virtual Memory</a></li><li><a href=/hugo-page/hpc/external-memory/model/>External Memory Model</a></li><li><a href=/hugo-page/hpc/external-memory/sorting/>External Sorting</a></li><li><a href=/hugo-page/hpc/external-memory/list-ranking/>List Ranking</a></li><li><a href=/hugo-page/hpc/external-memory/policies/>Eviction Policies</a></li><li><a href=/hugo-page/hpc/external-memory/oblivious/>Cache-Oblivious Algorithms</a></li><li><a href=/hugo-page/hpc/external-memory/locality/>Spatial and Temporal Locality</a></li></ol><li><a href=/hugo-page/hpc/cpu-cache/>RAM & CPU Caches</a></li><ol><li><a href=/hugo-page/hpc/cpu-cache/bandwidth/>Memory Bandwidth</a></li><li><a href=/hugo-page/hpc/cpu-cache/latency/>Memory Latency</a></li><li><a href=/hugo-page/hpc/cpu-cache/cache-lines/>Cache Lines</a></li><li><a href=/hugo-page/hpc/cpu-cache/sharing/>Memory Sharing</a></li><li><a href=/hugo-page/hpc/cpu-cache/mlp/>Memory-Level Parallelism</a></li><li><a href=/hugo-page/hpc/cpu-cache/prefetching/>Prefetching</a></li><li><a href=/hugo-page/hpc/cpu-cache/alignment/>Alignment and Packing</a></li><li><a href=/hugo-page/hpc/cpu-cache/pointers/>Pointer Alternatives</a></li><li><a href=/hugo-page/hpc/cpu-cache/associativity/>Cache Associativity</a></li><li><a href=/hugo-page/hpc/cpu-cache/paging/>Memory Paging</a></li><li><a href=/hugo-page/hpc/cpu-cache/aos-soa/>AoS and SoA</a></li></ol><li><a href=/hugo-page/hpc/simd/>SIMD Parallelism</a></li><ol><li><a href=/hugo-page/hpc/simd/intrinsics/>Intrinsics and Vector Types</a></li><li><a href=/hugo-page/hpc/simd/moving/>Moving Data</a></li><li><a href=/hugo-page/hpc/simd/reduction/>Reductions</a></li><li><a href=/hugo-page/hpc/simd/masking/>Masking and Blending</a></li><li><a href=/hugo-page/hpc/simd/shuffling/>In-Register Shuffles</a></li><li><a href=/hugo-page/hpc/simd/auto-vectorization/>Auto-Vectorization and SPMD</a></li></ol><li><a href=/hugo-page/hpc/algorithms/>Algorithms Case Studies</a></li><ol><li><a href=/hugo-page/hpc/algorithms/gcd/>Binary GCD</a></li><li><a href=/hugo-page/hpc/algorithms/factorization/>Integer Factorization</a></li><li><a href=/hugo-page/hpc/algorithms/argmin/>Argmin with SIMD</a></li><li><a href=/hugo-page/hpc/algorithms/prefix/>Prefix Sum with SIMD</a></li><li><a href=/hugo-page/hpc/algorithms/matmul/>Matrix Multiplication</a></li></ol><li><a href=/hugo-page/hpc/data-structures/>Data Structures Case Studies</a></li><ol><li><a href=/hugo-page/hpc/data-structures/binary-search/>Binary Search</a></li><li><a href=/hugo-page/hpc/data-structures/s-tree/>Static B-Trees</a></li><li><a href=/hugo-page/hpc/data-structures/b-tree/>Search Trees</a></li><li><a href=/hugo-page/hpc/data-structures/segment-trees/>Segment Trees</a></li></ol></ul></nav><div id=wrapper><menu id=menu><div class=left><a><img src=/icons/bars-solid.svg onclick=toggleSidebar() title='open table of contents'>
</a><a><img src=/icons/adjust-solid.svg style=position:relative;top:-1px onclick='switchTheme(localStorage.getItem("theme")=="dark"?"light":"dark")' title='dark theme'>
</a><a><img src=/icons/search-solid.svg onclick=toggleSearch() title=search></a></div><div class=title>Montgomery Multiplication</div><div class=right><a onclick=window.print()><img src=/icons/print-solid.svg title=print>
</a><a href=https://prose.io/#algorithmica-org/algorithmica/edit/master//hpc%2fnumber-theory%2fmontgomery.md><img src=/icons/edit-solid.svg title=edit style=width:18px;position:relative;right:-2px;top:-1px>
</a><a href=https://github.com/algorithmica-org/algorithmica/blob/master//hpc/number-theory/montgomery.md class=github-main><img src=/icons/github-brands.svg title='view on github'></a></div></menu><main><div id=search><input id=search-bar type=search placeholder='Search this book…' oninput=search()><div id=search-count></div><div id=search-results></div></div><header><h1>Montgomery Multiplication</h1><div class=info></div></header><article><p>Unsurprisingly, a large fraction of computation in <a href=../modular>modular arithmetic</a> is often spent on calculating the modulo operation, which is as slow as <a href=/hpc/arithmetic/division/>general integer division</a> and typically takes 15-20 cycles, depending on the operand size.</p><p>The best way to deal this nuisance is to avoid modulo operation altogether, delaying or replacing it with <a href=/hpc/pipelining/branchless>predication</a>, which can be done, for example, when calculating modular sums:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>M</span> <span class=o>=</span> <span class=mf>1e9</span> <span class=o>+</span> <span class=mi>7</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// input: array of n integers in the [0, M) range
</span></span></span><span class=line><span class=cl><span class=c1>// output: sum modulo M
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>int</span> <span class=nf>slow_sum</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>s</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>=</span> <span class=p>(</span><span class=n>s</span> <span class=o>+</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>])</span> <span class=o>%</span> <span class=n>M</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>s</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>fast_sum</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>s</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>+=</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>];</span> <span class=c1>// s &lt; 2 * M
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>s</span> <span class=o>=</span> <span class=p>(</span><span class=n>s</span> <span class=o>&gt;=</span> <span class=n>M</span> <span class=o>?</span> <span class=n>s</span> <span class=o>-</span> <span class=nl>M</span> <span class=p>:</span> <span class=n>s</span><span class=p>);</span> <span class=c1>// will be replaced with cmov
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>s</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>faster_sum</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>long</span> <span class=kt>long</span> <span class=n>s</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=c1>// 64-bit integer to handle overflow
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>+=</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>];</span> <span class=c1>// will be vectorized
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>return</span> <span class=n>s</span> <span class=o>%</span> <span class=n>M</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>However, sometimes you only have a chain of modular multiplications, and there is no good way to eel out of computing the remainder of the division — other than with the <a href=../hpc/arithmetic/division/>integer division tricks</a> requiring a constant modulo and some precomputation.</p><p>But there is another technique designed specifically for modular arithmetic, called <em>Montgomery multiplication</em>.</p><span class=anchor id=montgomery-space></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/number-theory/montgomery/#montgomery-space>#</a>Montgomery Space</h3><p>Montgomery multiplication works by first transforming the multipliers into <em>Montgomery space</em>, where modular multiplication can be performed cheaply, and then transforming them back when their actual values are needed. Unlike general integer division methods, Montgomery multiplication is not efficient for performing just one modular reduction and only becomes worthwhile when there is a chain of modular operations.</p><p>The space is defined by the modulo $n$ and a positive integer $r \ge n$ coprime to $n$. The algorithm involves modulo and division by $r$, so in practice, $r$ is chosen to be $2^{32}$ or $2^{64}$, so that these operations can be done with a right-shift and a bitwise AND respectively.</p><p><strong>Definition.</strong> The <em>representative</em> $\bar x$ of a number $x$ in the Montgomery space is defined as</p>$$
\bar{x} = x \cdot r \bmod n
$$<p>Computing this transformation involves a multiplication and a modulo — an expensive operation that we wanted to optimize away in the first place — which is why we only use this method when the overhead of transforming numbers to and from the Montgomery space is worth it and not for general modular multiplication.</p><p>Inside the Montgomery space, addition, substraction, and checking for equality is performed as usual:</p>$$
x \cdot r + y \cdot r \equiv (x + y) \cdot r \bmod n
$$
However, this is not the case for multiplication. Denoting multiplication in the Montgomery space as $*$ and the &ldquo;normal&rdquo; multiplication as $\cdot$, we expect the result to be:
$$
\bar{x} * \bar{y} = \overline{x \cdot y} = (x \cdot y) \cdot r \bmod n
$$
But the normal multiplication in the Montgomery space yields:
$$
\bar{x} \cdot \bar{y} = (x \cdot y) \cdot r \cdot r \bmod n
$$
Therefore, the multiplication in the Montgomery space is defined as
$$
\bar{x} * \bar{y} = \bar{x} \cdot \bar{y} \cdot r^{-1} \bmod n
$$<p>This means that, after we normally multiply two numbers in the Montgomery space, we need to <em>reduce</em> the result by multiplying it by $r^{-1}$ and taking the modulo — and there is an efficent way to do this particular operation.</p><span class=anchor id=montgomery-reduction></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/number-theory/montgomery/#montgomery-reduction>#</a>Montgomery reduction</h3><p>Assume that $r=2^{32}$, the modulo $n$ is 32-bit, and the number $x$ we need to reduce is 64-bit (the product of two 32-bit numbers). Our goal is to calculate $y = x \cdot r^{-1} \bmod n$.</p><p>Since $r$ is coprime with $n$, we know that there are two numbers $r^{-1}$ and $n^\prime$ in the $[0, n)$ range such that</p>$$
r \cdot r^{-1} + n \cdot n^\prime = 1
$$<p>and both $r^{-1}$ and $n^\prime$ can be computed, e.g., using the <a href=../euclid-extended>extended Euclidean algorithm</a>.</p><p>Using this identity, we can express $r \cdot r^{-1}$ as $(1 - n \cdot n^\prime)$ and write $x \cdot r^{-1}$ as</p>$$
\begin{aligned}
x \cdot r^{-1} &= x \cdot r \cdot r^{-1} / r
\\   &= x \cdot (1 - n \cdot n^{\prime}) / r
\\ &= (x - x \cdot n \cdot n^{\prime} ) / r
\\ &\equiv (x - x \cdot n \cdot n^{\prime} + k \cdot r \cdot n) / r &\pmod n &\;\;\text{(for any integer $k$)}
\\ &\equiv (x - (x \cdot n^{\prime} - k \cdot r) \cdot n) / r &\pmod n
\end{aligned}

    $$
  

Now, if we choose $k$ to be $\lfloor x \cdot n^\prime / r \rfloor$ (the upper 64 bits of the $x \cdot n^\prime$ product), it will cancel out, and $(k \cdot r - x \cdot n^{\prime})$ will simply be equal to $x \cdot n^{\prime} \bmod r$ (the lower 32 bits of $x \cdot n^\prime$), implying:
$$
x \cdot r^{-1} \equiv (x - x \cdot n^{\prime} \bmod r \cdot n) / r
$$<p>The algorithm itself just evaluates this formula, performing two multiplications to calculate $q = x \cdot n^{\prime} \bmod r$ and $m = q \cdot n$, and then subtracts it from $x$ and right-shifts the result to divide it by $r$.</p><p>The only remaining thing to handle is that the result may not be in the $[0, n)$ range; but since</p>$$
x < n \cdot n < r \cdot n \implies x / r < n
$$
and
$$
m = q \cdot n < r \cdot n \implies m / r < n
$$
it is guaranteed that
$$
-n < (x - m) / r < n
$$<p>Therefore, we can simply check if the result is negative and in that case, add $n$ to it, giving the following algorithm:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>typedef</span> <span class=n>__uint32_t</span> <span class=n>u32</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>typedef</span> <span class=n>__uint64_t</span> <span class=n>u64</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=n>u32</span> <span class=n>n</span> <span class=o>=</span> <span class=mf>1e9</span> <span class=o>+</span> <span class=mi>7</span><span class=p>,</span> <span class=n>nr</span> <span class=o>=</span> <span class=n>inverse</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=mi>1ull</span> <span class=o>&lt;&lt;</span> <span class=mi>32</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>u32</span> <span class=nf>reduce</span><span class=p>(</span><span class=n>u64</span> <span class=n>x</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>u32</span> <span class=n>q</span> <span class=o>=</span> <span class=n>u32</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=o>*</span> <span class=n>nr</span><span class=p>;</span>      <span class=c1>// q = x * n&#39; mod r
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>u64</span> <span class=n>m</span> <span class=o>=</span> <span class=p>(</span><span class=n>u64</span><span class=p>)</span> <span class=n>q</span> <span class=o>*</span> <span class=n>n</span><span class=p>;</span>      <span class=c1>// m = q * n
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>u32</span> <span class=n>y</span> <span class=o>=</span> <span class=p>(</span><span class=n>x</span> <span class=o>-</span> <span class=n>m</span><span class=p>)</span> <span class=o>&gt;&gt;</span> <span class=mi>32</span><span class=p>;</span>    <span class=c1>// y = (x - m) / r
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>return</span> <span class=n>x</span> <span class=o>&lt;</span> <span class=n>m</span> <span class=o>?</span> <span class=n>y</span> <span class=o>+</span> <span class=nl>n</span> <span class=p>:</span> <span class=n>y</span><span class=p>;</span> <span class=c1>// if y &lt; 0, add n to make it be in the [0, n) range
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span>
</span></span></code></pre></div><p>This last check is relatively cheap, but it is still on the critical path. If we are fine with the result being in the $[0, 2 \cdot n - 2]$ range instead of $[0, n)$, we can remove it and add $n$ to the result unconditionally:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>u32</span> <span class=nf>reduce</span><span class=p>(</span><span class=n>u64</span> <span class=n>x</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>u32</span> <span class=n>q</span> <span class=o>=</span> <span class=n>u32</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=o>*</span> <span class=n>nr</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>u64</span> <span class=n>m</span> <span class=o>=</span> <span class=p>(</span><span class=n>u64</span><span class=p>)</span> <span class=n>q</span> <span class=o>*</span> <span class=n>n</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>u32</span> <span class=n>y</span> <span class=o>=</span> <span class=p>(</span><span class=n>x</span> <span class=o>-</span> <span class=n>m</span><span class=p>)</span> <span class=o>&gt;&gt;</span> <span class=mi>32</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>y</span> <span class=o>+</span> <span class=n>n</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>We can also move the <code>>> 32</code> operation one step earlier in the computation graph and compute $\lfloor x / r \rfloor - \lfloor m / r \rfloor$ instead of $(x - m) / r$. This is correct because the lower 32 bits of $x$ and $m$ are equal anyway since</p>$$
m = x \cdot n^\prime \cdot n \equiv x \pmod r
$$<p>But why would we voluntarily choose to perfom two right-shifts instead of just one? This is beneficial because for <code>((u64) q * n) >> 32</code> we need to do a 32-by-32 multiplication and take the upper 32 bits of the result (which the x86 <code>mul</code> instruction <a href=../hpc/arithmetic/integer/#128-bit-integers>already writes</a> in a separate register, so it doesn&rsquo;t cost anything), and the other right-shift <code>x >> 32</code> is not on the critical path.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>u32</span> <span class=nf>reduce</span><span class=p>(</span><span class=n>u64</span> <span class=n>x</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>u32</span> <span class=n>q</span> <span class=o>=</span> <span class=n>u32</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=o>*</span> <span class=n>nr</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>u32</span> <span class=n>m</span> <span class=o>=</span> <span class=p>((</span><span class=n>u64</span><span class=p>)</span> <span class=n>q</span> <span class=o>*</span> <span class=n>n</span><span class=p>)</span> <span class=o>&gt;&gt;</span> <span class=mi>32</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span><span class=n>x</span> <span class=o>&gt;&gt;</span> <span class=mi>32</span><span class=p>)</span> <span class=o>+</span> <span class=n>n</span> <span class=o>-</span> <span class=n>m</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>One of the main advantages of Montgomery multiplication over other modular reduction methods is that it doesn&rsquo;t require very large data types: it only needs a $r \times r$ multiplication that extracts the lower and higher $r$ bits of the result, which <a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#ig_expand=7395,7392,7269,4868,7269,7269,1820,1835,6385,5051,4909,4918,5051,7269,6423,7410,150,2138,1829,1944,3009,1029,7077,519,5183,4462,4490,1944,5055,5012,5055&amp;techs=AVX,AVX2&amp;text=mul">has special support</a> on most hardware also makes it easily generalizable to <a href=../hpc/simd/>SIMD</a> and larger data types:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>typedef</span> <span class=n>__uint128_t</span> <span class=n>u128</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>u64</span> <span class=nf>reduce</span><span class=p>(</span><span class=n>u128</span> <span class=n>x</span><span class=p>)</span> <span class=k>const</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>u64</span> <span class=n>q</span> <span class=o>=</span> <span class=n>u64</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=o>*</span> <span class=n>nr</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>u64</span> <span class=n>m</span> <span class=o>=</span> <span class=p>((</span><span class=n>u128</span><span class=p>)</span> <span class=n>q</span> <span class=o>*</span> <span class=n>n</span><span class=p>)</span> <span class=o>&gt;&gt;</span> <span class=mi>64</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span><span class=n>x</span> <span class=o>&gt;&gt;</span> <span class=mi>64</span><span class=p>)</span> <span class=o>+</span> <span class=n>n</span> <span class=o>-</span> <span class=n>m</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Note that a 128-by-64 modulo is not possible with general integer division tricks: the compiler <a href=https://godbolt.org/z/fbEE4v4qr>falls back</a> to calling a slow <a href=https://github.com/llvm-mirror/compiler-rt/blob/69445f095c22aac2388f939bedebf224a6efcdaf/lib/builtins/udivmodti4.c#L22>long arithmetic library function</a> to support it.</p><span class=anchor id=faster-inverse-and-transform></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/number-theory/montgomery/#faster-inverse-and-transform>#</a>Faster Inverse and Transform</h3><p>Montgomery multiplication itself is fast, but it requires some precomputation:</p><ul><li>inverting $n$ modulo $r$ to compute $n^\prime$,</li><li>transforming a number <em>to</em> the Montgomery space,</li><li>transforming a number <em>from</em> the Montgomery space.</li></ul><p>The last operation is already efficiently performed with the <code>reduce</code> procedure we just implemented, but the first two can be slightly optimized.</p><p><strong>Computing the inverse</strong> $n^\prime = n^{-1} \bmod r$ can be done faster than with the extended Euclidean algorithm by taking advantage of the fact that $r$ is a power of two and using the following identity:</p>$$
a \cdot x \equiv 1 \bmod 2^k
\implies
a \cdot x \cdot (2 - a \cdot x)
\equiv
1 \bmod 2^{2k}
$$
Proof:
$$
\begin{aligned}
a \cdot x \cdot (2 - a \cdot x)
&= 2 \cdot a \cdot x - (a \cdot x)^2
\\ &= 2 \cdot (1 + m \cdot 2^k) - (1 + m \cdot 2^k)^2
\\ &= 2 + 2 \cdot m \cdot 2^k - 1 - 2 \cdot m \cdot 2^k - m^2 \cdot 2^{2k}
\\ &= 1 - m^2 \cdot 2^{2k}
\\ &\equiv 1 \bmod 2^{2k}.
\end{aligned}
$$<p>We can start with $x = 1$ as the inverse of $a$ modulo $2^1$ and apply this identity exactly $\log_2 r$ times, each time doubling the number of bits in the inverse — somewhat reminiscent of <a href=../hpc/arithmetic/newton/>the Newton&rsquo;s method</a>.</p><p><strong>Transforming</strong> a number into the Montgomery space can be done by multiplying it by $r$ and computing modulo <a href=../hpc/arithmetic/division/>the usual way</a>, but we can also take advantage of this relation:</p>$$
\bar{x} = x \cdot r \bmod n = x * r^2
$$<p>Transforming a number into the space is just a multiplication by $r^2$. Therefore, we can precompute $r^2 \bmod n$ and perform a multiplication and reduction instead — which may or may not be actually faster because multiplying a number by $r=2^{k}$ can be implemented with a left-shift, while multiplication by $r^2 \bmod n$ can not.</p><span class=anchor id=complete-implementation></span><h3><a class=anchor-link href=http://jyang772.github.io/hugo-page/hpc/number-theory/montgomery/#complete-implementation>#</a>Complete Implementation</h3><p>It is convenient to wrap everything into a single <code>constexpr</code> structure:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>struct</span> <span class=nc>Montgomery</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>u32</span> <span class=n>n</span><span class=p>,</span> <span class=n>nr</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>constexpr</span> <span class=nf>Montgomery</span><span class=p>(</span><span class=n>u32</span> <span class=n>n</span><span class=p>)</span> <span class=o>:</span> <span class=n>n</span><span class=p>(</span><span class=n>n</span><span class=p>),</span> <span class=n>nr</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=c1>// log(2^32) = 5
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=mi>5</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>nr</span> <span class=o>*=</span> <span class=mi>2</span> <span class=o>-</span> <span class=n>n</span> <span class=o>*</span> <span class=n>nr</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>u32</span> <span class=nf>reduce</span><span class=p>(</span><span class=n>u64</span> <span class=n>x</span><span class=p>)</span> <span class=k>const</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>u32</span> <span class=n>q</span> <span class=o>=</span> <span class=n>u32</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=o>*</span> <span class=n>nr</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>u32</span> <span class=n>m</span> <span class=o>=</span> <span class=p>((</span><span class=n>u64</span><span class=p>)</span> <span class=n>q</span> <span class=o>*</span> <span class=n>n</span><span class=p>)</span> <span class=o>&gt;&gt;</span> <span class=mi>32</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>(</span><span class=n>x</span> <span class=o>&gt;&gt;</span> <span class=mi>32</span><span class=p>)</span> <span class=o>+</span> <span class=n>n</span> <span class=o>-</span> <span class=n>m</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=c1>// returns a number in the [0, 2 * n - 2] range
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=c1>// (add a &#34;x &lt; n ? x : x - n&#34; type of check if you need a proper modulo)
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>u32</span> <span class=nf>multiply</span><span class=p>(</span><span class=n>u32</span> <span class=n>x</span><span class=p>,</span> <span class=n>u32</span> <span class=n>y</span><span class=p>)</span> <span class=k>const</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>reduce</span><span class=p>((</span><span class=n>u64</span><span class=p>)</span> <span class=n>x</span> <span class=o>*</span> <span class=n>y</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>u32</span> <span class=nf>transform</span><span class=p>(</span><span class=n>u32</span> <span class=n>x</span><span class=p>)</span> <span class=k>const</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>(</span><span class=n>u64</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=o>&lt;&lt;</span> <span class=mi>32</span><span class=p>)</span> <span class=o>%</span> <span class=n>n</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=c1>// can also be implemented as multiply(x, r^2 mod n)
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>};</span>
</span></span></code></pre></div><p>To test its performance, we can plug Montgomery multiplication into the <a href=../hpc/number-theory/exponentiation/>binary exponentiation</a>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>constexpr</span> <span class=n>Montgomery</span> <span class=nf>space</span><span class=p>(</span><span class=n>M</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>inverse</span><span class=p>(</span><span class=kt>int</span> <span class=n>_a</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>u64</span> <span class=n>a</span> <span class=o>=</span> <span class=n>space</span><span class=p>.</span><span class=n>transform</span><span class=p>(</span><span class=n>_a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>u64</span> <span class=n>r</span> <span class=o>=</span> <span class=n>space</span><span class=p>.</span><span class=n>transform</span><span class=p>(</span><span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=cp>#pragma GCC unroll(30)
</span></span></span><span class=line><span class=cl><span class=cp></span>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>l</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>l</span> <span class=o>&lt;</span> <span class=mi>30</span><span class=p>;</span> <span class=n>l</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span> <span class=p>(</span><span class=n>M</span> <span class=o>-</span> <span class=mi>2</span><span class=p>)</span> <span class=o>&gt;&gt;</span> <span class=n>l</span> <span class=o>&amp;</span> <span class=mi>1</span> <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>r</span> <span class=o>=</span> <span class=n>space</span><span class=p>.</span><span class=n>multiply</span><span class=p>(</span><span class=n>r</span><span class=p>,</span> <span class=n>a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>a</span> <span class=o>=</span> <span class=n>space</span><span class=p>.</span><span class=n>multiply</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>space</span><span class=p>.</span><span class=n>reduce</span><span class=p>(</span><span class=n>r</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>While vanilla binary exponentiation with a compiler-generated fast modulo trick requires ~170ns per <code>inverse</code> call, this implementation takes ~166ns, going down to ~158ns we omit <code>transform</code> and <code>reduce</code> (a reasonable use case is for <code>inverse</code> to be used as a subprocedure in a bigger modular computation). This is a small improvement, but Montgomery multiplication becomes much more advantageous for SIMD applications and larger data types.</p><p><strong>Exercise.</strong> Implement efficient <em>modular</em> <a href=/hpc/algorithms/matmul>matix multiplication</a>.</p></article><div class=nextprev><div class=left><a href=http://jyang772.github.io/hugo-page/hpc/number-theory/euclid-extended/ id=prev-article>← Extended Euclidean Algorithm</a></div><div class=right><a href=http://jyang772.github.io/hugo-page/hpc/external-memory/ id=next-article>../External Memory →</a></div></div></main><footer>Copyright 2021–2022 Sergey Slotin<br></footer></div></body></html>